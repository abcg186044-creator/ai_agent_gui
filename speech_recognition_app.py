#!/usr/bin/env python3
"""
Speech Recognition App - éŸ³å£°èªè­˜æ©Ÿèƒ½ä»˜ã
"""

import streamlit as st
import time
import sys
import os
import numpy as np
from datetime import datetime
import tempfile
import wave

def get_simulated_devices():
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    return [
        {
            'id': 0,
            'name': 'Simulated Microphone - Default',
            'channels': 1,
            'sample_rate': 16000,
            'type': 'simulated',
            'description': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯'
        },
        {
            'id': 1,
            'name': 'Simulated Microphone - High Quality',
            'channels': 1,
            'sample_rate': 16000,
            'type': 'simulated',
            'description': 'éŸ³å£°èªè­˜ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯'
        }
    ]

def simulate_speech_recording(duration=3, sample_rate=16000):
    """éŸ³å£°èªè­˜ç”¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    samples = int(duration * sample_rate)
    t = np.linspace(0, duration, samples)
    
    # éŸ³å£°ã‚‰ã—ã„ä¿¡å·ï¼ˆè¤‡æ•°ã®å‘¨æ³¢æ•°æˆåˆ†ï¼‰
    signal = (
        np.sin(2 * np.pi * 200 * t) * 0.3 +  # åŸºæœ¬å‘¨æ³¢æ•°
        np.sin(2 * np.pi * 400 * t) * 0.2 +  # ç¬¬2å€éŸ³
        np.sin(2 * np.pi * 800 * t) * 0.1 +  # ç¬¬3å€éŸ³
        np.random.normal(0, 0.05, samples)   # è»½ã„ãƒã‚¤ã‚º
    )
    
    # éŸ³å£°ã‚‰ã—ã„åŒ…çµ¡ç·š
    envelope = np.exp(-t * 0.5) * (1 - np.exp(-t * 10))
    signal = signal * envelope
    
    return signal.astype(np.float32)

def save_audio_to_wav(audio_data, sample_rate, filename):
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    try:
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(sample_rate)
            
            # float32ã‚’int16ã«å¤‰æ›
            audio_int16 = (audio_data * 32767).astype(np.int16)
            wav_file.writeframes(audio_int16.tobytes())
        
        return True
    except Exception as e:
        st.error(f"WAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def test_faster_whisper():
    """faster-whisperã®ãƒ†ã‚¹ãƒˆ"""
    try:
        from faster_whisper import WhisperModel
        st.success("âœ… faster-whisper: æ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ")
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        with st.spinner("Whisperãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­..."):
            model = WhisperModel("base", compute_type="float32")
        
        st.success("âœ… Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–æˆåŠŸ")
        return True, model
        
    except ImportError as e:
        st.error(f"âŒ faster-whisperã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.info("ğŸ’¡ faster-whisperãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False, None
    except Exception as e:
        st.error(f"âŒ Whisperãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False, None

def transcribe_audio(model, audio_file_path):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—"""
    try:
        with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
            segments, info = model.transcribe(
                audio_file_path, 
                language="ja",  # æ—¥æœ¬èª
                beam_size=5
            )
        
        transcription = ""
        confidence_scores = []
        
        for segment in segments:
            transcription += segment.text + " "
            confidence_scores.append(segment.avg_logprob)
        
        # çµæœã®è¡¨ç¤º
        st.success("âœ… éŸ³å£°èªè­˜å®Œäº†ï¼")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ:**")
            st.write(transcription.strip())
        
        with col2:
            st.write("**èªè­˜æƒ…å ±:**")
            st.write(f"æ¤œå‡ºè¨€èª: {info.language}")
            st.write(f"è¨€èªç¢ºç‡: {info.language_probability:.2f}")
            st.write(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(list(segments))}")
            
            if confidence_scores:
                avg_confidence = np.mean(confidence_scores)
                st.write(f"å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.2f}")
        
        return transcription.strip(), info
        
    except Exception as e:
        st.error(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None, None

def main():
    st.set_page_config(
        page_title="Speech Recognition",
        page_icon="ğŸ¤",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¤ Speech Recognition App")
    st.markdown("### éŸ³å£°èªè­˜æ©Ÿèƒ½ä»˜ã")
    
    # åŸºæœ¬æƒ…å ±è¡¨ç¤º
    st.success("âœ… Streamlit is running!")
    st.info("â„¹ï¸ ã“ã‚Œã¯éŸ³å£°èªè­˜æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆç‰ˆã§ã™ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    # faster-whisperãƒ†ã‚¹ãƒˆ
    st.markdown("### ğŸ¤– éŸ³å£°èªè­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ†ã‚¹ãƒˆ")
    
    whisper_available, whisper_model = test_faster_whisper()
    
    if not whisper_available:
        st.warning("âš ï¸ éŸ³å£°èªè­˜æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        st.info("ğŸ’¡ faster-whisperã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™")
        return
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    st.markdown("### ğŸ¤ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒã‚¤ã‚¹é¸æŠ")
    
    simulated_devices = get_simulated_devices()
    st.info(f"ğŸ¤ åˆ©ç”¨å¯èƒ½ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒã‚¤ã‚¹æ•°: {len(simulated_devices)}")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    st.sidebar.markdown("### ğŸ¤ ãƒ‡ãƒã‚¤ã‚¹é¸æŠ")
    
    device_options = [f"{dev['id']}: {dev['name']}" for dev in simulated_devices]
    selected_device_option = st.sidebar.selectbox(
        "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ã‚’é¸æŠ:",
        device_options,
        index=1  # éŸ³å£°èªè­˜ç”¨ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    )
    
    selected_device_id = int(selected_device_option.split(':')[0])
    selected_device = next((dev for dev in simulated_devices if dev['id'] == selected_device_id), None)
    
    st.sidebar.success(f"âœ… é¸æŠã•ã‚ŒãŸãƒ‡ãƒã‚¤ã‚¹: {selected_device['name']}")
    
    # ãƒ‡ãƒã‚¤ã‚¹è©³ç´°è¡¨ç¤º
    with st.expander("ğŸ¤ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒã‚¤ã‚¹è©³ç´°"):
        for dev in simulated_devices:
            if dev['id'] == selected_device_id:
                st.write(f"**ğŸ¯ é¸æŠä¸­**: {dev['name']}")
            else:
                st.write(f"**ãƒ‡ãƒã‚¤ã‚¹ {dev['id']}**: {dev['name']}")
            st.write(f"  - èª¬æ˜: {dev['description']}")
            st.write(f"  - ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {dev['sample_rate']}")
            st.write("---")
    
    # éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ
    st.markdown("### ğŸ™ï¸ éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        duration = st.slider("éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰:", 1, 10, 3)
        sample_rate = st.selectbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ:", [8000, 16000, 22050, 44100], index=1)
    
    with col2:
        speech_type = st.selectbox("éŸ³å£°ã‚¿ã‚¤ãƒ—:", ["æ—¥æœ¬èª", "è‹±èª", "æ•°å­—", "æ··åˆ"], index=0)
        noise_level = st.slider("ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«:", 0.0, 0.2, 0.05, 0.01)
    
    if st.button("ğŸ™ï¸ éŒ²éŸ³ã¨éŸ³å£°èªè­˜"):
        try:
            st.write(f"ğŸ™ï¸ {duration}ç§’é–“ã®éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™...")
            st.write(f"ğŸ¤ ãƒ‡ãƒã‚¤ã‚¹: {selected_device['name']}")
            st.write(f"ğŸ“Š è¨­å®š: {sample_rate}Hz, {speech_type}, ãƒã‚¤ã‚º: {noise_level}")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            for i in range(100):
                time.sleep(0.01)
                progress_bar.progress(i + 1)
            
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            audio_data = simulate_speech_recording(duration, sample_rate)
            
            # ãƒã‚¤ã‚ºã‚’è¿½åŠ 
            if noise_level > 0:
                noise = np.random.normal(0, noise_level, len(audio_data))
                audio_data = audio_data + noise
                audio_data = np.clip(audio_data, -1.0, 1.0)
            
            st.success("âœ… éŒ²éŸ³å®Œäº†ï¼")
            st.write(f"ğŸ“Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿: {len(audio_data)} ã‚µãƒ³ãƒ—ãƒ«")
            st.write(f"ğŸ“Š æœ€å¤§æŒ¯å¹…: {np.max(np.abs(audio_data)):.4f}")
            
            # æ³¢å½¢è¡¨ç¤º
            st.write("ğŸ“ˆ éŒ²éŸ³æ³¢å½¢:")
            st.line_chart(audio_data.flatten()[:1000])  # æœ€åˆã®1000ã‚µãƒ³ãƒ—ãƒ«ã®ã¿è¡¨ç¤º
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_filename = temp_file.name
            
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            if save_audio_to_wav(audio_data, sample_rate, temp_filename):
                st.write("ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")
                
                # éŸ³å£°èªè­˜å®Ÿè¡Œ
                transcription, info = transcribe_audio(whisper_model, temp_filename)
                
                if transcription:
                    # çµæœã®è©³ç´°è¡¨ç¤º
                    st.markdown("### ğŸ“ èªè­˜çµæœ")
                    
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.write("**èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ:**")
                        st.text_area("", transcription, height=100, key="transcription_result")
                    
                    with col2:
                        st.write("**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:**")
                        st.json({
                            "language": info.language if info else "unknown",
                            "language_probability": info.language_probability if info else 0.0,
                            "duration": duration,
                            "sample_rate": sample_rate,
                            "speech_type": speech_type,
                            "noise_level": noise_level
                        })
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    st.markdown("### ğŸ”§ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼"):
                            st.write("ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã•ã‚Œã¾ã—ãŸï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
                    
                    with col2:
                        if st.button("ğŸ”„ å†èªè­˜"):
                            st.write("å†èªè­˜ã‚’å®Ÿè¡Œã—ã¾ã™...")
                            transcription, info = transcribe_audio(whisper_model, temp_filename)
                            if transcription:
                                st.experimental_rerun()
                    
                    with col3:
                        if st.button("ğŸ’¾ ä¿å­˜"):
                            st.write("ãƒ†ã‚­ã‚¹ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    os.unlink(temp_filename)
                except:
                    pass
            
        except Exception as e:
            st.error(f"âŒ éŒ²éŸ³ãƒ»èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # TTSãƒ†ã‚¹ãƒˆ
    st.markdown("### ğŸ—£ï¸ TTSãƒ†ã‚¹ãƒˆ")
    
    try:
        import pyttsx3
        st.success("âœ… pyttsx3: æ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ")
        
        # TTSã‚¨ãƒ³ã‚¸ãƒ³æƒ…å ±
        try:
            engine = pyttsx3.init()
            voices = engine.getProperty('voices')
            st.info(f"ğŸ—£ï¸ æ¤œå‡ºã•ã‚ŒãŸTTSéŸ³å£°æ•°: {len(voices)}")
            
            # éŸ³å£°é¸æŠ
            if voices:
                voice_options = [f"{i}: {voice.name}" for i, voice in enumerate(voices)]
                selected_voice = st.selectbox("TTSéŸ³å£°ã‚’é¸æŠ:", voice_options, index=0)
                selected_voice_id = int(selected_voice.split(':')[0])
                
                tts_text = st.text_input("èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ:", "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯éŸ³å£°èªè­˜ã®ãƒ†ã‚¹ãƒˆã§ã™")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ—£ï¸ TTSãƒ†ã‚¹ãƒˆ"):
                        try:
                            import threading
                            
                            def speak_text():
                                engine = pyttsx3.init()
                                engine.setProperty('voice', voices[selected_voice_id].id)
                                engine.say(tts_text)
                                engine.runAndWait()
                            
                            st.write(f"ğŸ—£ï¸ èª­ã¿ä¸Šã’ä¸­: {tts_text}")
                            st.write(f"ğŸ¤ éŸ³å£°: {voices[selected_voice_id].name}")
                            
                            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                            thread = threading.Thread(target=speak_text)
                            thread.start()
                            
                            st.success("âœ… TTSé–‹å§‹ï¼")
                            
                        except Exception as e:
                            st.error(f"âŒ TTSã‚¨ãƒ©ãƒ¼: {str(e)}")
                
                with col2:
                    if st.button("ğŸ”„ éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ"):
                        st.write("TTSéŸ³å£°ã‚’èªè­˜ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿè£…ãŒå¿…è¦ï¼‰")
            
        except Exception as e:
            st.error(f"âŒ TTSã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
    except ImportError as e:
        st.error(f"âŒ pyttsx3ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.markdown("### ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    st.write(f"Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sys.version}")
    st.write(f"Streamlitãƒãƒ¼ã‚¸ãƒ§ãƒ³: {st.__version__}")
    st.write(f"å®Ÿè¡Œç’°å¢ƒ: Dockerã‚³ãƒ³ãƒ†ãƒŠ")
    st.write(f"éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    st.write(f"éŸ³å£°èªè­˜: faster-whisper")
    
    # ãƒ˜ãƒ«ãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("### ğŸ’¡ ãƒ˜ãƒ«ãƒ—")
    
    with st.expander("ğŸ”§ éŸ³å£°èªè­˜ã«ã¤ã„ã¦"):
        st.write("""
        **faster-whisperã«ã¤ã„ã¦:**
        - OpenAI Whisperã®é«˜é€Ÿå®Ÿè£…
        - å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªãƒ»è‹±èªãªã©ï¼‰
        - é«˜ç²¾åº¦ãªéŸ³å£°èªè­˜
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†å¯èƒ½
        
        **ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç‰¹å¾´:**
        - å®Ÿéš›ã®éŸ³å£°å…¥åŠ›ã¯ä½¿ç”¨ã—ãªã„
        - éŸ³å£°ã‚‰ã—ã„ä¿¡å·ã‚’ç”Ÿæˆ
        - éŸ³å£°èªè­˜ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
        - UIã¨å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®æ¤œè¨¼
        
        **èªè­˜ç²¾åº¦:**
        - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã§ã¯æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“
        - éŸ³å£°èªè­˜ãƒ—ãƒ­ã‚»ã‚¹ã®å‹•ä½œç¢ºèªãŒç›®çš„
        - å®Ÿéš›ã®éŸ³å£°èªè­˜ã¯å®Ÿæ©Ÿå…¥åŠ›ãŒå¿…è¦
        """)

if __name__ == "__main__":
    main()
