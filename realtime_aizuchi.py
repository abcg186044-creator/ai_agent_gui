#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œï¼ˆã‚ã„ã¥ã¡ï¼‰ã‚·ã‚¹ãƒ†ãƒ 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ä¸­ã«è‡ªç„¶ãªç›¸æ§Œã‚’æ‰“ã¤é«˜åº¦ãªãƒªã‚¹ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½
"""

import streamlit as st
import numpy as np
import librosa
import pyaudio
import threading
import time
import json
import random
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import webrtcvad
from collections import deque
import queue
import tempfile

class RealTimeAizuchiSystem:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.name = "realtime_aizuchi"
        self.description = "ç™ºè©±ä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ "
        
        # éŸ³å£°éŒ²éŸ³è¨­å®š
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.chunk = 256  # å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã§é«˜é »åº¦å‡¦ç†
        
        # VADè¨­å®š
        self.vad = webrtcvad.Vad(2)  # ä¸­ç¨‹åº¦ã®æ„Ÿåº¦
        
        # ç›¸æ§Œã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨­å®š
        self.aizuchi_min_duration = 1.5  # 1.5ç§’ã®ç™ºè©±ã§ç›¸æ§Œå¯èƒ½
        self.aizuchi_max_duration = 8.0  # 8ç§’ä»¥ä¸Šã®é•·è©±ã¯ç›¸æ§Œã‚’æ§ãˆã‚‹
        self.aizuchi_cooldown = 2.0  # ç›¸æ§Œå¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
        self.pause_threshold = 0.3  # 0.3ç§’ã®ç„¡éŸ³ã‚’æ–‡ã®åŒºåˆ‡ã‚Šã¨åˆ¤å®š
        
        # VOICEVOXè¨­å®š
        self.voicevox_url = "http://localhost:50021"
        self.aizuchi_speaker_id = 3  # ç›¸æ§Œç”¨è©±è€…IDï¼ˆå››å›½ã‚ãŸã‚“ãªã©ï¼‰
        
        # ç›¸æ§Œãƒ‘ã‚¿ãƒ¼ãƒ³
        self.aizuchi_patterns = {
            'neutral': ['ã†ã‚“', 'ãªã‚‹ã»ã©', 'ãã†ã ã­', 'äº†è§£'],
            'positive': ['ãªã‚‹ã»ã©ï¼', 'ãã†ãªã‚“ã ï¼', 'ã¸ã‡ãƒ¼ï¼', 'ãŠã‚‚ã—ã‚ã„ï¼'],
            'thinking': ['ã†ãƒ¼ã‚“', 'ãã†ã‹...', 'ãªã‚‹ã»ã©ã­', 'ãµã‚€ãµã‚€'],
            'sympathy': ['ãã†ãªã‚“ã ...', 'å¤§å¤‰ã ã­', 'ã‚ã‹ã‚‹ã‚ˆ', 'ãã†ãªã‚“ã ã­'],
            'surprise': ['ã¸ã‡ãƒ¼ï¼', 'ã¾ã˜ã§ï¼', 'ã†ãï¼', 'ã»ã‚“ã¨ã«ï¼Ÿ']
        }
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_active = False
        self.speech_start_time = None
        self.last_speech_time = None
        self.last_aizuchi_time = None
        self.continuous_speech_duration = 0.0
        self.pause_count = 0
        self.current_emotion = 'neutral'
        
        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡
        self.speech_buffer = deque(maxlen=1000)  # æœ€è¿‘ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯
        self.energy_history = deque(maxlen=50)   # ã‚¨ãƒãƒ«ã‚®ãƒ¼å±¥æ­´
        self.pitch_history = deque(maxlen=50)     # ãƒ”ãƒƒãƒå±¥æ­´
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ç®¡ç†
        self.aizuchi_thread = None
        self.is_running = False
        
        # ç›¸æ§Œå†ç”Ÿã‚­ãƒ¥ãƒ¼
        self.aizuchi_queue = queue.Queue()
        self.playback_thread = None
        
        # çµ±è¨ˆæƒ…å ±
        self.aizuchi_count = 0
        self.aizuchi_history = []
        
        # åˆæœŸåŒ–
        self._init_voicevox()
    
    def _init_voicevox(self):
        """VOICEVOXåˆæœŸåŒ–"""
        try:
            response = requests.get(f"{self.voicevox_url}/speakers")
            if response.status_code == 200:
                speakers = response.json()
                # ç›¸æ§Œã«é©ã—ãŸè©±è€…ã‚’æ¢ã™
                for speaker in speakers:
                    if speaker["name"] in ["å››å›½ã‚ãŸã‚“", "ãšã‚“ã ã‚‚ã‚“", "æ˜¥æ—¥éƒ¨ã¤ãã¿"]:
                        for style in speaker["styles"]:
                            self.aizuchi_speaker_id = style["id"]
                            break
                        break
                print(f"âœ… ç›¸æ§Œç”¨è©±è€…ID: {self.aizuchi_speaker_id}")
            else:
                print("âš ï¸ VOICEVOXã«æ¥ç¶šã§ãã¾ã›ã‚“")
        except Exception as e:
            print(f"âŒ VOICEVOXåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def start_aizuchi_system(self):
        """ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹"""
        if not self.is_active:
            self.is_active = True
            self.is_running = True
            
            # ç›¸æ§Œå†ç”Ÿã‚¹ãƒ¬ãƒƒãƒ‰
            self.playback_thread = threading.Thread(target=self._aizuchi_playback_loop, daemon=True)
            self.playback_thread.start()
            
            print("ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            return True
        return False
    
    def stop_aizuchi_system(self):
        """ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢"""
        self.is_active = False
        self.is_running = False
        return True
    
    def process_audio_chunk(self, audio_chunk: np.ndarray):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†"""
        if not self.is_active:
            return
        
        current_time = time.time()
        
        # VADã§éŸ³å£°æ¤œå‡º
        is_speech = self._detect_voice_activity(audio_chunk)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—
        energy = np.mean(audio_chunk ** 2)
        self.energy_history.append(energy)
        
        # ãƒ”ãƒƒãƒæ¨å®šï¼ˆç°¡æ˜“ï¼‰
        pitch = self._estimate_pitch(audio_chunk)
        self.pitch_history.append(pitch)
        
        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        self.speech_buffer.append({
            'audio': audio_chunk,
            'timestamp': current_time,
            'is_speech': is_speech,
            'energy': energy,
            'pitch': pitch
        })
        
        # ç™ºè©±çŠ¶æ…‹ã®æ›´æ–°
        self._update_speech_state(is_speech, current_time)
        
        # ç›¸æ§Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åˆ¤å®š
        if is_speech:
            self._check_aizuchi_timing(current_time)
    
    def _detect_voice_activity(self, audio_chunk: np.ndarray) -> bool:
        """éŸ³å£°æ´»å‹•æ¤œå‡º"""
        try:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’16bitã«å¤‰æ›
            audio_int16 = (audio_chunk * 32767).astype(np.int16)
            
            # VADã§åˆ¤å®š
            is_speech = self.vad.is_speech(audio_int16.tobytes(), self.rate)
            return is_speech
            
        except Exception as e:
            print(f"VADã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _estimate_pitch(self, audio_chunk: np.ndarray) -> float:
        """ãƒ”ãƒƒãƒæ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # è‡ªå·±ç›¸é–¢é–¢æ•°ã§åŸºæœ¬å‘¨æ³¢æ•°ã‚’æ¨å®š
            autocorr = np.correlate(audio_chunk, audio_chunk, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            # ãƒ”ãƒ¼ã‚¯æ¤œå‡º
            peak = np.argmax(autocorr[1:]) + 1
            if peak > 0:
                pitch = self.rate / peak
                # äººé–“ã®å£°ã®ç¯„å›²ã«åˆ¶é™
                if 50 <= pitch <= 500:
                    return pitch
        except:
            pass
        
        return 0.0
    
    def _update_speech_state(self, is_speech: bool, current_time: float):
        """ç™ºè©±çŠ¶æ…‹ã‚’æ›´æ–°"""
        if is_speech:
            if self.speech_start_time is None:
                # æ–°ã—ã„ç™ºè©±ã®é–‹å§‹
                self.speech_start_time = current_time
                self.continuous_speech_duration = 0.0
                self.pause_count = 0
                print("ğŸ¤ ç™ºè©±é–‹å§‹æ¤œå‡º")
            
            self.last_speech_time = current_time
            self.continuous_speech_duration = current_time - self.speech_start_time
            
        else:
            # ç„¡éŸ³æ™‚
            if self.last_speech_time and (current_time - self.last_speech_time) > self.pause_threshold:
                # æ–‡ã®åŒºåˆ‡ã‚Šã¨åˆ¤å®š
                self.pause_count += 1
                print(f"â¸ï¸ æ–‡ã®åŒºåˆ‡ã‚Šæ¤œå‡º (åˆè¨ˆ: {self.pause_count})")
    
    def _check_aizuchi_timing(self, current_time: float):
        """ç›¸æ§Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯"""
        # æ¡ä»¶ãƒã‚§ãƒƒã‚¯
        if not self._should_aizuchi(current_time):
            return
        
        # æ„Ÿæƒ…åˆ†æ
        emotion = self._analyze_speech_emotion()
        
        # ç›¸æ§Œã®ç¨®é¡ã‚’é¸æŠ
        aizuchi_text = self._select_aizuchi(emotion)
        
        # ç›¸æ§Œã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        aizuchi_data = {
            'text': aizuchi_text,
            'emotion': emotion,
            'timestamp': current_time,
            'speech_duration': self.continuous_speech_duration
        }
        
        self.aizuchi_queue.put(aizuchi_data)
        self.last_aizuchi_time = current_time
        
        print(f"ğŸ‘‚ ç›¸æ§Œã‚­ãƒ¥ãƒ¼è¿½åŠ : {aizuchi_text} (æ„Ÿæƒ…: {emotion})")
    
    def _should_aizuchi(self, current_time: float) -> bool:
        """ç›¸æ§Œã‚’æ‰“ã¤ã¹ãã‹åˆ¤å®š"""
        # åŸºæœ¬æ¡ä»¶ãƒã‚§ãƒƒã‚¯
        if not self.is_active or not self.speech_start_time:
            return False
        
        # ç™ºè©±ç¶™ç¶šæ™‚é–“ãƒã‚§ãƒƒã‚¯
        if self.continuous_speech_duration < self.aizuchi_min_duration:
            return False
        
        if self.continuous_speech_duration > self.aizuchi_max_duration:
            return False
        
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
        if self.last_aizuchi_time and (current_time - self.last_aizuchi_time) < self.aizuchi_cooldown:
            return False
        
        # æ–‡ã®åŒºåˆ‡ã‚Šãƒã‚§ãƒƒã‚¯ï¼ˆ1å›ä»¥ä¸Šã®ãƒãƒ¼ã‚ºãŒã‚ã‚‹ï¼‰
        if self.pause_count < 1:
            return False
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰å‹•ãƒã‚§ãƒƒã‚¯ï¼ˆè©±ã—æ–¹ã®å¤‰åŒ–ï¼‰
        if len(self.energy_history) < 10:
            return False
        
        energy_variance = np.var(list(self.energy_history)[-10:])
        if energy_variance < 1e-6:  # å˜èª¿ãªç™ºè©±ã¯æ§ãˆã‚‹
            return False
        
        return True
    
    def _analyze_speech_emotion(self) -> str:
        """ç™ºè©±ã®æ„Ÿæƒ…ã‚’åˆ†æ"""
        if len(self.pitch_history) < 5 or len(self.energy_history) < 5:
            return 'neutral'
        
        # ãƒ”ãƒƒãƒã®çµ±è¨ˆ
        recent_pitches = list(self.pitch_history)[-5:]
        pitch_mean = np.mean(recent_pitches)
        pitch_std = np.std(recent_pitches)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®çµ±è¨ˆ
        recent_energies = list(self.energy_history)[-5:]
        energy_mean = np.mean(recent_energies)
        energy_std = np.std(recent_energies)
        
        # æ„Ÿæƒ…åˆ¤å®šï¼ˆç°¡æ˜“ãƒ«ãƒ¼ãƒ«ï¼‰
        if pitch_mean > 200 and pitch_std > 30:
            return 'surprise'
        elif pitch_mean > 180 and energy_std > 0.001:
            return 'positive'
        elif pitch_mean < 100 and energy_std < 0.0005:
            return 'sympathy'
        elif self.pause_count > 2:
            return 'thinking'
        else:
            return 'neutral'
    
    def _select_aizuchi(self, emotion: str) -> str:
        """ç›¸æ§Œã®ç¨®é¡ã‚’é¸æŠ"""
        patterns = self.aizuchi_patterns.get(emotion, self.aizuchi_patterns['neutral'])
        return random.choice(patterns)
    
    def _aizuchi_playback_loop(self):
        """ç›¸æ§Œå†ç”Ÿãƒ«ãƒ¼ãƒ—"""
        while self.is_running:
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ç›¸æ§Œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                aizuchi_data = self.aizuchi_queue.get(timeout=0.1)
                
                # éŸ³å£°åˆæˆã¨å†ç”Ÿ
                self._synthesize_and_play_aizuchi(aizuchi_data)
                
                # VRMã«ç›¸æ§Œãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€ä¿¡
                self._send_vrm_aizuchi_motion(aizuchi_data)
                
                # çµ±è¨ˆæ›´æ–°
                self.aizuchi_count += 1
                self.aizuchi_history.append(aizuchi_data)
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ç›¸æ§Œå†ç”Ÿã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _synthesize_and_play_aizuchi(self, aizuchi_data: Dict):
        """ç›¸æ§Œã®éŸ³å£°åˆæˆã¨å†ç”Ÿ"""
        try:
            # VOICEVOXã§éŸ³å£°åˆæˆ
            query_response = requests.post(
                f"{self.voicevox_url}/audio_query",
                params={
                    'speaker': self.aizuchi_speaker_id,
                    'text': aizuchi_data['text']
                }
            )
            
            if query_response.status_code == 200:
                query = query_response.json()
                
                # ç›¸æ§Œç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
                query['speedScale'] = 1.2  # å°‘ã—é€Ÿã‚
                query['pitchScale'] = 1.0
                query['volumeScale'] = 0.7  # å°‘ã—é™ã‹ã«
                
                # éŸ³å£°åˆæˆ
                synth_response = requests.post(
                    f"{self.voicevox_url}/synthesis",
                    params={'speaker': self.aizuchi_speaker_id},
                    json=query
                )
                
                if synth_response.status_code == 200:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as f:
                        f.write(synth_response.content)
                        temp_file = f.name
                    
                    # éŸ³å£°å†ç”Ÿï¼ˆéåŒæœŸï¼‰
                    self._play_audio_file(temp_file)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    Path(temp_file).unlink(missing_ok=True)
                    
                    print(f"ğŸ”Š ç›¸æ§Œå†ç”Ÿ: {aizuchi_data['text']}")
                
        except Exception as e:
            print(f"ç›¸æ§ŒéŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _play_audio_file(self, file_path: str):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ"""
        try:
            import pygame
            pygame.mixer.init()
            pygame.mixer.music.load(file_path)
            pygame.mixer.music.play()
            
            # å†ç”Ÿçµ‚äº†ã‚’å¾…æ©Ÿï¼ˆéåŒæœŸã«ã™ã‚‹å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
            while pygame.mixer.music.get_busy():
                time.sleep(0.01)
                
        except Exception as e:
            print(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _send_vrm_aizuchi_motion(self, aizuchi_data: Dict):
        """VRMã«ç›¸æ§Œãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€ä¿¡"""
        try:
            # VRMé€£æºæ©Ÿèƒ½ã¯ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã§å®Ÿè£…
            motion_type = "aizuchi"
            emotion = aizuchi_data['emotion']
            
            # JavaScriptã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            js_code = f"""
            <script>
                window.parent.postMessage({{
                    type: 'motion',
                    data: {{ motion: '{motion_type}', emotion: '{emotion}' }}
                }}, '*');
            </script>
            """
            
            # Streamlitã§å®Ÿè¡Œ
            st.components.v1.html(js_code, height=0)
            
        except Exception as e:
            print(f"VRMãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³é€ä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def get_aizuchi_statistics(self) -> Dict:
        """ç›¸æ§Œçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.aizuchi_history:
            return {
                'total_aizuchi': 0,
                'average_interval': 0,
                'emotion_distribution': {},
                'most_used_aizuchi': None
            }
        
        # æ„Ÿæƒ…åˆ†å¸ƒ
        emotion_counts = {}
        for aizuchi in self.aizuchi_history:
            emotion = aizuchi['emotion']
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
        # æœ€ã‚‚ä½¿ç”¨ã—ãŸç›¸æ§Œ
        aizuchi_texts = [a['text'] for a in self.aizuchi_history]
        most_common = max(set(aizuchi_texts), key=aizuchi_texts.count) if aizuchi_texts else None
        
        # å¹³å‡é–“éš”
        if len(self.aizuchi_history) > 1:
            intervals = []
            for i in range(1, len(self.aizuchi_history)):
                interval = self.aizuchi_history[i]['timestamp'] - self.aizuchi_history[i-1]['timestamp']
                intervals.append(interval)
            avg_interval = np.mean(intervals)
        else:
            avg_interval = 0
        
        return {
            'total_aizuchi': self.aizuchi_count,
            'average_interval': avg_interval,
            'emotion_distribution': emotion_counts,
            'most_used_aizuchi': most_common,
            'current_speech_duration': self.continuous_speech_duration,
            'pause_count': self.pause_count
        }
    
    def reset_state(self):
        """çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.speech_start_time = None
        self.last_speech_time = None
        self.last_aizuchi_time = None
        self.continuous_speech_duration = 0.0
        self.pause_count = 0
        self.speech_buffer.clear()
        self.energy_history.clear()
        self.pitch_history.clear()
        
        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        while not self.aizuchi_queue.empty():
            try:
                self.aizuchi_queue.get_nowait()
            except queue.Empty:
                break
    
    def run(self, command: str) -> str:
        """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
        if command == "start_aizuchi":
            if self.start_aizuchi_system():
                return "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸ"
            else:
                return "ã™ã§ã«ç¨¼åƒä¸­ã§ã™"
        
        elif command == "stop_aizuchi":
            if self.stop_aizuchi_system():
                return "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ"
            else:
                return "ç¨¼åƒã—ã¦ã„ã¾ã›ã‚“"
        
        elif command == "status":
            stats = self.get_aizuchi_statistics()
            return f"ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: ç¨¼åƒä¸­={self.is_active}, ç›¸æ§Œæ•°={stats['total_aizuchi']}, ç™ºè©±ç¶™ç¶š={stats['current_speech_duration']:.1f}ç§’"
        
        elif command == "statistics":
            stats = self.get_aizuchi_statistics()
            return json.dumps(stats, ensure_ascii=False, indent=2)
        
        elif command == "reset":
            self.reset_state()
            return "ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ"
        
        else:
            return "ã‚³ãƒãƒ³ãƒ‰å½¢å¼: start_aizuchi, stop_aizuchi, status, statistics, reset"

# Streamlit GUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
def create_aizuchi_gui(aizuchi_system: RealTimeAizuchiSystem):
    """ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ GUIã‚’ä½œæˆ"""
    st.subheader("ğŸ‘‚ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ")
    
    # çµ±è¨ˆæƒ…å ±
    stats = aizuchi_system.get_aizuchi_statistics()
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹",
            "ğŸŸ¢ ç¨¼åƒä¸­" if aizuchi_system.is_active else "ğŸ”´ åœæ­¢ä¸­",
            help="ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã®ç¨¼åƒçŠ¶æ…‹"
        )
    
    with col2:
        st.metric(
            "ç›¸æ§Œå›æ•°",
            stats['total_aizuchi'],
            help="ç´¯è¨ˆç›¸æ§Œå›æ•°"
        )
    
    with col3:
        st.metric(
            "ç™ºè©±ç¶™ç¶š",
            f"{stats['current_speech_duration']:.1f}ç§’",
            help="ç¾åœ¨ã®ç™ºè©±ç¶™ç¶šæ™‚é–“"
        )
    
    with col4:
        st.metric(
            "æ–‡ã®åŒºåˆ‡ã‚Š",
            stats['pause_count'],
            help="æ¤œå‡ºã•ã‚ŒãŸæ–‡ã®åŒºåˆ‡ã‚Šæ•°"
        )
    
    # åˆ¶å¾¡ãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ¯ ç›¸æ§Œé–‹å§‹", type="primary", disabled=aizuchi_system.is_active):
            if aizuchi_system.start_aizuchi_system():
                st.success("ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                st.info("ğŸ—£ï¸ ç™ºè©±ä¸­ã«è‡ªç„¶ãªç›¸æ§ŒãŒå…¥ã‚Šã¾ã™")
            else:
                st.warning("ã™ã§ã«ç¨¼åƒä¸­ã§ã™")
    
    with col2:
        if st.button("â¹ï¸ ç›¸æ§Œåœæ­¢", type="secondary", disabled=not aizuchi_system.is_active):
            if aizuchi_system.stop_aizuchi_system():
                st.info("â¹ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸æ§Œã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    # ç›¸æ§Œãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
    st.write("**ç›¸æ§Œãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**åŸºæœ¬ç›¸æ§Œ**")
        st.code(", ".join(aizuchi_system.aizuchi_patterns['neutral']))
    
    with col2:
        st.write("**æ„Ÿæƒ…åˆ¥ç›¸æ§Œ**")
        for emotion, patterns in aizuchi_system.aizuchi_patterns.items():
            if emotion != 'neutral':
                st.write(f"{emotion}: {', '.join(patterns[:2])}")
    
    # çµ±è¨ˆè©³ç´°
    if st.button("ğŸ“Š ç›¸æ§Œçµ±è¨ˆ"):
        st.json(stats)
    
    # æ‰‹å‹•ãƒ†ã‚¹ãƒˆ
    st.write("**æ‰‹å‹•ãƒ†ã‚¹ãƒˆ**")
    if st.button("ğŸ§ª ãƒ†ã‚¹ãƒˆç›¸æ§Œ"):
        # ãƒ†ã‚¹ãƒˆç”¨ç›¸æ§Œãƒ‡ãƒ¼ã‚¿
        test_aizuchi = {
            'text': 'ãªã‚‹ã»ã©',
            'emotion': 'neutral',
            'timestamp': time.time(),
            'speech_duration': 2.0
        }
        
        aizuchi_system.aizuchi_queue.put(test_aizuchi)
        st.success("ğŸ§ª ãƒ†ã‚¹ãƒˆç›¸æ§Œã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã—ãŸ")
    
    # çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ”„ çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ"):
        aizuchi_system.reset_state()
        st.info("ğŸ”„ ç›¸æ§Œã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
