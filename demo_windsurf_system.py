#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Windsurfãƒãƒ«ãƒAIã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import asyncio
import time
import threading
from typing import Dict, List, Any

from async_ollama_client import AsyncOllamaClient
from coding_task_runner import CodingTaskRunner, TaskPriority
from local_llm_server import LocalLLMServer

class WindsurfSystemDemo:
    """Windsurfã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢"""
    
    def __init__(self):
        self.ollama_client = None
        self.task_runner = None
        self.local_server = None
        self.progress_log = []
    
    def log_progress(self, progress_info: Dict[str, Any]):
        """é€²æ—ã‚’ãƒ­ã‚°è¨˜éŒ²"""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {progress_info.get('task_id', 'SYSTEM')}: {progress_info.get('message', 'No message')} ({progress_info.get('progress', 0):.1f}%)"
        self.progress_log.append(log_entry)
        print(log_entry)
    
    async def setup(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸš€ Windsurfãƒãƒ«ãƒAIã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢é–‹å§‹")
        print("=" * 60)
        
        # 1. éåŒæœŸOllamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        print("\nğŸ“¡ 1. éåŒæœŸOllamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—...")
        self.ollama_client = AsyncOllamaClient(
            ports=[11434, 11435, 11436],
            models=["llama3.2:3b", "llama3.1:8b"]
        )
        
        # 2. ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        print("ğŸ“‹ 2. ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—...")
        self.task_runner = CodingTaskRunner(max_workers=3)
        self.task_runner.add_progress_callback(self.log_progress)
        
        # 3. ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒãƒ¼ã‚’æº–å‚™
        print("ğŸ–¥ï¸ 3. ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒãƒ¼ã‚’æº–å‚™...")
        self.local_server = LocalLLMServer(port=11437)
        
        print("âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    
    async def demo_parallel_ai_generation(self):
        """ä¸¦åˆ—AIç”Ÿæˆãƒ‡ãƒ¢"""
        print("\nğŸ¤– ãƒ‡ãƒ¢1: ä¸¦åˆ—AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆ")
        print("-" * 40)
        
        # è¤‡æ•°ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯
        coding_tasks = [
            "Pythonã§GUIé›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚tkinterã‚’ä½¿ç”¨ã—ã€å››å‰‡æ¼”ç®—ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚",
            "HTML/CSS/JavaScriptã§ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãªé›»å“ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
            "Androidã‚¢ãƒ—ãƒªã§é›»å“ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚Kotlinã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚",
            "Reactã§é›»å“ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        ]
        
        print(f"ğŸ“ {len(coding_tasks)}å€‹ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å‡¦ç†...")
        
        # ä¸¦åˆ—ã§AIç”Ÿæˆã‚’å®Ÿè¡Œ
        async with self.ollama_client as client:
            results = await client.generate_parallel_responses(
                coding_tasks,
                self.log_progress
            )
        
        print(f"\nğŸ“Š ç”Ÿæˆçµæœ:")
        successful_count = 0
        for i, result in enumerate(results):
            if result["success"]:
                successful_count += 1
                print(f"   âœ… ã‚¿ã‚¹ã‚¯{i+1}: {result['model']} (ãƒãƒ¼ãƒˆ: {result['port']}, æ™‚é–“: {result['elapsed_time']:.2f}ç§’)")
                print(f"      ã‚³ãƒ¼ãƒ‰é•·: {len(result['response'])} æ–‡å­—")
            else:
                print(f"   âŒ ã‚¿ã‚¹ã‚¯{i+1}: å¤±æ•— - {result['error']}")
        
        print(f"\nğŸ¯ æˆåŠŸç‡: {successful_count}/{len(coding_tasks)} ({successful_count/len(coding_tasks)*100:.1f}%)")
        
        return results
    
    def demo_task_runner(self, ai_results: List[Dict[str, Any]]):
        """ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼ãƒ‡ãƒ¢"""
        print("\nğŸ“‹ ãƒ‡ãƒ¢2: ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼")
        print("-" * 40)
        
        # AIç”Ÿæˆçµæœã‚’ã‚¿ã‚¹ã‚¯ã¨ã—ã¦è¿½åŠ 
        task_ids = []
        for i, result in enumerate(ai_results):
            if result["success"]:
                task_id = self.task_runner.add_task(
                    description=f"AIç”Ÿæˆã‚³ãƒ¼ãƒ‰é©ç”¨ {i+1}",
                    code=result["response"],
                    file_path=f"generated_code_{i+1}.py",
                    priority=TaskPriority.HIGH if i < 2 else TaskPriority.MEDIUM
                )
                task_ids.append(task_id)
                print(f"   ğŸ“ ã‚¿ã‚¹ã‚¯è¿½åŠ : {task_id}")
        
        print(f"\nğŸ”„ ã‚¿ã‚¹ã‚¯å‡¦ç†ã‚’é–‹å§‹...")
        self.task_runner.start_processing()
        
        # å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
        max_wait_time = 30
        wait_time = 0
        
        while wait_time < max_wait_time:
            completed_tasks = self.task_runner.get_tasks_by_status(TaskStatus.COMPLETED)
            failed_tasks = self.task_runner.get_tasks_by_status(TaskStatus.FAILED)
            
            if len(completed_tasks) + len(failed_tasks) >= len(task_ids):
                break
            
            time.sleep(1)
            wait_time += 1
        
        # çµæœè¡¨ç¤º
        print(f"\nğŸ“Š ã‚¿ã‚¹ã‚¯å‡¦ç†çµæœ:")
        for task_id in task_ids:
            task = self.task_runner.get_task_status(task_id)
            if task:
                status_emoji = {
                    "completed": "âœ…",
                    "failed": "âŒ",
                    "running": "ğŸ”„",
                    "pending": "â³"
                }.get(task.status.value, "â“")
                
                print(f"   {status_emoji} {task.description}: {task.status.value}")
                if task.error_message:
                    print(f"      ã‚¨ãƒ©ãƒ¼: {task.error_message}")
        
        # çµ±è¨ˆæƒ…å ±
        stats = self.task_runner.get_stats()
        print(f"\nğŸ“ˆ å‡¦ç†çµ±è¨ˆ:")
        print(f"   ç·ã‚¿ã‚¹ã‚¯æ•°: {stats['total_tasks']}")
        print(f"   å®Œäº†: {stats['completed_tasks']}")
        print(f"   å¤±æ•—: {stats['failed_tasks']}")
        print(f"   ã‚­ãƒ£ãƒ³ã‚»ãƒ«: {stats['cancelled_tasks']}")
        
        self.task_runner.stop_processing()
    
    def demo_local_server(self):
        """ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¢"""
        print("\nğŸ–¥ï¸ ãƒ‡ãƒ¢3: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒãƒ¼")
        print("-" * 40)
        
        print("ğŸ“¡ ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•...")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
        server_thread = threading.Thread(target=self.local_server.run, daemon=True)
        server_thread.start()
        
        # å°‘ã—å¾…ã£ã¦ã‹ã‚‰æ¥ç¶šãƒ†ã‚¹ãƒˆ
        time.sleep(2)
        
        print("âœ… ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒãƒ¼ãŒãƒãƒ¼ãƒˆ11435ã§èµ·å‹•ã—ã¾ã—ãŸ")
        print("ğŸ“ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:")
        print("   - GET  http://localhost:11435/")
        print("   - GET  http://localhost:11435/api/tags")
        print("   - POST http://localhost:11435/api/generate")
        
        return server_thread
    
    def show_progress_summary(self):
        """é€²æ—ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\nğŸ“œ é€²æ—ãƒ­ã‚°ã‚µãƒãƒªãƒ¼")
        print("-" * 40)
        
        if self.progress_log:
            print(f"ç·ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª: {len(self.progress_log)}")
            
            # æœ€æ–°ã®10ä»¶ã‚’è¡¨ç¤º
            print("\næœ€æ–°ã®é€²æ—:")
            for log in self.progress_log[-10:]:
                print(f"   {log}")
        else:
            print("é€²æ—ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    async def run_full_demo(self):
        """å®Œå…¨ãªãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        try:
            # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            await self.setup()
            
            # ãƒ‡ãƒ¢1: ä¸¦åˆ—AIç”Ÿæˆ
            ai_results = await self.demo_parallel_ai_generation()
            
            # ãƒ‡ãƒ¢2: ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼
            self.demo_task_runner(ai_results)
            
            # ãƒ‡ãƒ¢3: ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼
            server_thread = self.demo_local_server()
            
            # é€²æ—ã‚µãƒãƒªãƒ¼
            self.show_progress_summary()
            
            print("\nğŸ‰ Windsurfãƒãƒ«ãƒAIã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢å®Œäº†ï¼")
            print("=" * 60)
            
            # ç¶­æŒã®ãŸã‚å°‘ã—å¾…æ©Ÿ
            print("\nâ³ ã‚·ã‚¹ãƒ†ãƒ ã‚’5ç§’é–“ç¶­æŒ...")
            time.sleep(5)
            
        except Exception as e:
            print(f"\nâŒ ãƒ‡ãƒ¢å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    demo = WindsurfSystemDemo()
    asyncio.run(demo.run_full_demo())
