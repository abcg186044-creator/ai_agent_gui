#!/usr/bin/env python3
"""
VRM Avatar Integrated AI Agent Application
æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆ
"""

import streamlit as st
import requests
import json
import subprocess
import os
import sys
import time
import datetime
from pathlib import Path
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wav
import threading
import queue
import pyttsx3
from browser_audio_component_fixed import audio_recorder_component

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

if "current_personality" not in st.session_state:
    st.session_state.current_personality = "friend"

if "ollama" not in st.session_state:
    st.session_state.ollama = None

if "vrm_controller" not in st.session_state:
    st.session_state.vrm_controller = None

# Ollamaã‚¯ãƒ©ã‚¹
class OllamaClient:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        self.models = ["llama3.1:8b", "llama3.2", "llama3.2-vision"]
    
    def check_connection(self):
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def generate_response(self, prompt, model="llama3.1:8b"):
        try:
            data = {
                "model": model,
                "prompt": prompt,
                "stream": False
            }
            response = requests.post(f"{self.base_url}/api/generate", json=data, timeout=30)
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "")
            else:
                return None
        except Exception as e:
            print(f"Ollamaç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

# VRMã‚¢ãƒã‚¿ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
class VRMAvatarController:
    def __init__(self):
        self.current_personality = "friend"
        self.expressions = {
            "friend": "happy",
            "copy": "joy", 
            "expert": "neutral"
        }
        self.vrm_path = self._find_vrm_file()
    
    def _find_vrm_file(self):
        search_paths = [
            Path(r"C:\Users\GALLE\Desktop\EzoMomonga_Free") / "avatar.vrm",
            Path(__file__).parent / "static" / "avatar.vrm",
            Path(r"C:\Users\GALLE\Desktop\EzoMomonga_Free") / "EzoMomonga_Free.vrm",
            Path(r"C:\Users\GALLE\Desktop\EzoMomonga_Free\EzoMomonga_Free") / "EzoMomonga_Free.vrm",
            Path(__file__).parent / "static" / "EzoMomonga_Free.vrm",
        ]
        
        for vrm_path in search_paths:
            if vrm_path.exists():
                print(f"âœ… VRMãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {vrm_path}")
                if "static" not in str(vrm_path):
                    static_file = Path(__file__).parent / "static" / vrm_path.name
                    try:
                        import shutil
                        shutil.copy2(vrm_path, static_file)
                        print(f"ğŸ“ VRMãƒ•ã‚¡ã‚¤ãƒ«ã‚’staticã«ã‚³ãƒ”ãƒ¼: {static_file}")
                        return f"/static/{vrm_path.name}"
                    except Exception as e:
                        print(f"âŒ VRMãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—: {str(e)}")
                        continue
                else:
                    return f"/static/{vrm_path.name}"
        
        print("âŒ VRMãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    def update_personality(self, personality):
        self.current_personality = personality
        return self.expressions.get(personality, "neutral")
    
    def set_personality(self, personality):
        return self.update_personality(personality)
    
    def get_vrm_html(self):
        if not self.vrm_path:
            return """
            <div style="width: 100%; height: 400px; background: #f0f0f0; display: flex; align-items: center; justify-content: center; border-radius: 10px;">
                <div style="text-align: center; color: #666;">
                    <h3>ğŸ¤– VRMã‚¢ãƒã‚¿ãƒ¼</h3>
                    <p>VRMãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</p>
                </div>
            </div>
            """
        
        return f"""
        <div style="width: 100%; height: 400px; background: #f0f0f0; border-radius: 10px; position: relative;">
            <canvas id="vrm-canvas" style="width: 100%; height: 100%; border-radius: 10px;"></canvas>
            <script src="https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@2.0.7/lib/three-vrm.min.js"></script>
            <script>
                let scene, camera, renderer, vrmModel;
                
                async function initVRM() {{
                    scene = new THREE.Scene();
                    camera = new THREE.PerspectiveCamera(45, 1, 0.1, 1000);
                    camera.position.set(0, 1.2, 2.5);
                    
                    renderer = new THREE.WebGLRenderer({{
                        canvas: document.getElementById('vrm-canvas'),
                        antialias: true,
                        alpha: true
                    }});
                    renderer.setSize(400, 400);
                    renderer.setPixelRatio(window.devicePixelRatio);
                    
                    const light = new THREE.DirectionalLight(0xffffff, 1.0);
                    light.position.set(1, 1, 1);
                    scene.add(light);
                    
                    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
                    scene.add(ambientLight);
                    
                    try {{
                        const loader = new THREE.GLTFLoader();
                        const gltf = await loader.loadAsync('{self.vrm_path}');
                        vrmModel = await THREE.VRM.from(gltf);
                        scene.add(vrmModel.scene);
                        
                        vrmModel.humanoid.getBoneNode('head').rotation.y = Math.PI;
                        
                        updateVRMExpression('{self.expressions.get(self.current_personality, "neutral")}');
                    }} catch (error) {{
                        console.error('VRMèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
                    }}
                    
                    animate();
                }}
                
                function updateVRMExpression(expressionName) {{
                    if (vrmModel && vrmModel.blendShapeProxy) {{
                        vrmModel.blendShapeProxy.setValue(expressionName, 1.0);
                    }}
                }}
                
                function animate() {{
                    requestAnimationFrame(animate);
                    
                    if (vrmModel && vrmModel.update) {{
                        vrmModel.update(clock.getDelta());
                    }}
                    
                    renderer.render(scene, camera);
                }}
                
                const clock = new THREE.Clock();
                
                window.updateVRMExpression = updateVRMExpression;
                
                initVRM();
            </script>
        </div>
        """

# éŸ³å£°åˆæˆã‚¯ãƒ©ã‚¹
class TTSEngine:
    def __init__(self):
        self.engine = pyttsx3.init()
        voices = self.engine.getProperty('voices')
        
        # æ—¥æœ¬èªéŸ³å£°ã‚’å„ªå…ˆ
        for voice in voices:
            if 'japanese' in voice.name.lower() or 'ja' in voice.id.lower():
                self.engine.setProperty('voice', voice.id)
                break
        
        self.engine.setProperty('rate', 150)
        self.engine.setProperty('volume', 0.9)
    
    def speak(self, text):
        try:
            self.engine.say(text)
            self.engine.runAndWait()
        except Exception as e:
            print(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

# ä¼šè©±å±¥æ­´ä¿å­˜
def save_conversation(conversation, personality):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"conversation_{personality}_{timestamp}.json"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(conversation, f, ensure_ascii=False, indent=2)
        return filename
    except Exception as e:
        print(f"ä¼šè©±å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    st.set_page_config(
        page_title="VRM AI Agent",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¤– VRM AI Agent")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # äººæ ¼é¸æŠ
        st.subheader("ğŸ­ äººæ ¼è¨­å®š")
        personalities = {
            "friend": {
                "name": "è¦ªå‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                "prompt": "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªå£èª¿ã§ã€æŠ€è¡“çš„ãªã“ã¨ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                "icon": "ğŸ‘¨â€ğŸ’»",
                "color": "#4CAF50"
            },
            "copy": {
                "name": "åˆ†èº«",
                "prompt": "ã‚ãªãŸã¯ç§ã®åˆ†èº«ã§ã™ã€‚ç§ã®è€ƒãˆæ–¹ã‚„è©±ã—æ–¹ã‚’çœŸä¼¼ã—ã¦ã€å…±æ„Ÿçš„ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚",
                "icon": "ğŸª",
                "color": "#2196F3"
            },
            "expert": {
                "name": "å°‚é–€å®¶",
                "prompt": "ã‚ãªãŸã¯AIã®å°‚é–€å®¶ã§ã™ã€‚æ­£ç¢ºã§è©³ç´°ãªæƒ…å ±ã‚’ã€å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ã„ãªãŒã‚‰æä¾›ã—ã¦ãã ã•ã„ã€‚",
                "icon": "ğŸ“",
                "color": "#FF9800"
            }
        }
        
        for key, info in personalities.items():
            if st.button(f"{info['icon']} {info['name']}", key=f"personality_{key}"):
                st.session_state.current_personality = key
                if st.session_state.vrm_controller:
                    st.session_state.vrm_controller.set_personality(key)
                
                # VRMè¡¨æƒ…æ›´æ–°
                if st.session_state.get('updateVRMExpression'):
                    js_code = f"window.updateVRMExpression('{st.session_state.vrm_controller.expressions.get(key, 'neutral')}');"
                    st.components.v1.html(f"<script>{js_code}</script>", height=0)
        
        # ç¾åœ¨ã®äººæ ¼è¡¨ç¤º
        current_personality = personalities[st.session_state.current_personality]
        st.success(f"ç¾åœ¨ã®äººæ ¼: {current_personality['icon']} {current_personality['name']}")
        
        # Ollamaæ¥ç¶šç¢ºèª
        if st.button("ğŸ” Ollamaæ¥ç¶šç¢ºèª"):
            if not st.session_state.ollama:
                st.session_state.ollama = OllamaClient()
            
            if st.session_state.ollama.check_connection():
                st.success("âœ… Ollamaã«æ¥ç¶šã•ã‚Œã¦ã„ã¾ã™")
            else:
                st.error("âŒ Ollamaã«æ¥ç¶šã§ãã¾ã›ã‚“")
        
        # ãƒ¢ãƒ‡ãƒ«ç®¡ç†
        st.subheader("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
        if st.session_state.ollama and st.session_state.ollama.check_connection():
            models_status = True
        else:
            models_status = False
        
        if models_status:
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½")
            
            # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            if st.button("ğŸ“¥ llama3.1:8b", help="llama3.1:8bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                with st.spinner("llama3.1:8bã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                    result = subprocess.run(["ollama", "pull", "llama3.1:8b"], capture_output=True, text=True)
                    if result.returncode == 0:
                        st.success("âœ… llama3.1:8bã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        st.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {result.stderr}")
            
            if st.button("ğŸ“¥ llama3.2", help="llama3.2ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                with st.spinner("llama3.2ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                    result = subprocess.run(["ollama", "pull", "llama3.2"], capture_output=True, text=True)
                    if result.returncode == 0:
                        st.success("âœ… llama3.2ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        st.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {result.stderr}")
            
            if st.button("ğŸ“¥ llama3.2-vision", help="llama3.2-visionãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                with st.spinner("llama3.2-visionã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                    result = subprocess.run(["ollama", "pull", "llama3.2-vision"], capture_output=True, text=True)
                    if result.returncode == 0:
                        st.success("âœ… llama3.2-visionã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        st.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {result.stderr}")
            
            # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            if st.button("ğŸ“¦ å…¨ãƒ¢ãƒ‡ãƒ«ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", help="ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€åº¦ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                with st.spinner("å…¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                    models = ["llama3.1:8b", "llama3.2", "llama3.2-vision"]
                    success_count = 0
                    
                    for model in models:
                        result = subprocess.run(["ollama", "pull", model], capture_output=True, text=True)
                        if result.returncode == 0:
                            success_count += 1
                            st.success(f"âœ… {model}ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                        else:
                            st.error(f"âŒ {model}ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {result.stderr}")
                    
                    if success_count == len(models):
                        st.success("âœ… å…¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        st.warning(f"âš ï¸ {success_count}/{len(models)}ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ä¸å¯")
        
        # ä¼šè©±å±¥æ­´ç®¡ç†
        st.subheader("ğŸ’¬ ä¼šè©±å±¥æ­´")
        if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.conversation_history = []
            st.rerun()
        
        if st.button("ğŸ’¾ å±¥æ­´ã‚’ä¿å­˜"):
            if st.session_state.conversation_history:
                filename = save_conversation(
                    st.session_state.conversation_history,
                    st.session_state.current_personality
                )
                st.success(f"ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            else:
                st.warning("ä¿å­˜ã™ã‚‹ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # çµ±è¨ˆæƒ…å ±
        st.subheader("ğŸ“Š çµ±è¨ˆ")
        st.write(f"ä¼šè©±æ•°: {len(st.session_state.conversation_history)}")
        if st.session_state.conversation_history:
            user_messages = [msg for msg in st.session_state.conversation_history if msg["role"] == "user"]
            ai_messages = [msg for msg in st.session_state.conversation_history if msg["role"] == "assistant"]
            st.write(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€: {len(user_messages)}")
            st.write(f"AIå¿œç­”: {len(ai_messages)}")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ™ï¸ éŸ³å£°å…¥åŠ›")
        
        # å…¥åŠ›æ–¹æ³•é¸æŠ
        input_method = st.radio(
            "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ:",
            ["ğŸ™ï¸ éŸ³å£°å…¥åŠ›", "ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ğŸ¤– è‡ªå‹•å¿œç­”"],
            horizontal=True,
            help="éŸ³å£°ã€ãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯è‡ªå‹•å¿œç­”ã§AIã¨å¯¾è©±ã§ãã¾ã™"
        )
        
        if input_method == "ğŸ™ï¸ éŸ³å£°å…¥åŠ›":
            # éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
            audio_data, sample_rate = audio_recorder_component(key="ollama_audio")
            
            # éŸ³å£°èªè­˜ãƒœã‚¿ãƒ³
            if st.button("ğŸ¤ éŸ³å£°èªè­˜", help="éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"):
                if audio_data is not None:
                    with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
                        try:
                            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                            temp_audio_path = "temp_audio.wav"
                            wav.write(temp_audio_path, sample_rate, audio_data)
                            
                            # éŸ³å£°èªè­˜ï¼ˆã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰
                            recognized_text = "éŸ³å£°èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ€ãƒŸãƒ¼ï¼‰"
                            
                            st.session_state.recognized_text = recognized_text
                            st.success(f"èªè­˜çµæœ: {recognized_text}")
                            
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                            if os.path.exists(temp_audio_path):
                                os.remove(temp_audio_path)
                                
                        except Exception as e:
                            st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
                else:
                    st.warning("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŒ²éŸ³ã—ã¦ãã ã•ã„ã€‚")
        
        elif input_method == "ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
            # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢
            user_text = st.text_area(
                "ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›:",
                value=st.session_state.get("user_input_text", ""),
                height=100,
                placeholder="ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                help="AIã¨ã®å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¾ã™"
            )
            
            # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
            st.session_state.user_input_text = user_text
            
            # ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡ãƒœã‚¿ãƒ³
            if st.button("ğŸ“¤ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡", help="å…¥åŠ›ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’AIã«é€ä¿¡"):
                if user_text.strip():
                    st.session_state.recognized_text = user_text.strip()
                    st.success(f"é€ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_text.strip()}")
                else:
                    st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        else:  # è‡ªå‹•å¿œç­”
            st.subheader("ğŸ¤– è‡ªå‹•å¿œç­”ãƒ¢ãƒ¼ãƒ‰")
            st.write("AIãŒè‡ªå‹•çš„ã«ä¼šè©±ã‚’é–‹å§‹ã—ã€ç¶™ç¶šçš„ã«å¿œç­”ã—ã¾ã™ã€‚")
            
            # è‡ªå‹•å¿œç­”è¨­å®š
            col_auto1, col_auto2 = st.columns([2, 1])
            with col_auto1:
                auto_topic = st.selectbox(
                    "ä¼šè©±ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ:",
                    ["å¤©æ°—ã«ã¤ã„ã¦", "æœ€æ–°ã®æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹", "è‡ªå·±ç´¹ä»‹", "é›‘è«‡", "å°‚é–€çš„ãªç›¸è«‡"],
                    help="AIãŒè‡ªå‹•çš„ã«è©±é¡Œã‚’æä¾›ã—ã¾ã™"
                )
            
            with col_auto2:
                auto_count = st.number_input(
                    "å¿œç­”å›æ•°:",
                    min_value=1,
                    max_value=10,
                    value=3,
                    help="è‡ªå‹•å¿œç­”ã®å›æ•°ã‚’è¨­å®š"
                )
            
            # è‡ªå‹•å¿œç­”é–‹å§‹ãƒœã‚¿ãƒ³
            if st.button("ğŸš€ è‡ªå‹•å¿œç­”é–‹å§‹", help="AIãŒè‡ªå‹•çš„ã«ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™"):
                with st.spinner("AIãŒè‡ªå‹•å¿œç­”ã‚’ç”Ÿæˆä¸­..."):
                    try:
                        # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
                        topic_prompts = {
                            "å¤©æ°—ã«ã¤ã„ã¦": "ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦è‡ªç„¶ãªä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚å¤©æ°—ã®è©±é¡Œã‹ã‚‰é–¢é€£ã™ã‚‹è©±é¡Œã«åºƒã’ã¦ãã ã•ã„ã€‚",
                            "æœ€æ–°ã®æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹": "æœ€æ–°ã®æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ã„ã¦èˆˆå‘³æ·±ã„è©±é¡Œã‚’æä¾›ã—ã€è§£èª¬ã—ã¦ãã ã•ã„ã€‚",
                            "è‡ªå·±ç´¹ä»‹": "è‡ªå·±ç´¹ä»‹ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸã®èƒ½åŠ›ã‚„ç‰¹å¾´ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                            "é›‘è«‡": "æ¥½ã—ã„é›‘è«‡ã‚’ã—ã¦ãã ã•ã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¥½ã—ã¾ã›ã‚‹ã‚ˆã†ãªè©±é¡Œã‚’é¸ã‚“ã§ãã ã•ã„ã€‚",
                            "å°‚é–€çš„ãªç›¸è«‡": "å°‚é–€å®¶ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›¸è«‡ã—ãŸã„ã§ã‚ã‚ã†å°‚é–€çš„ãªè³ªå•ã¨å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
                        }
                        
                        # äººæ ¼ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                        personality = st.session_state.current_personality
                        current_personality = personalities[personality]
                        base_prompt = topic_prompts[auto_topic]
                        
                        # è‡ªå‹•å¿œç­”ç”Ÿæˆ
                        auto_responses = []
                        for i in range(auto_count):
                            # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
                            conversation_history = st.session_state.conversation_history[-5:]
                            history_text = ""
                            for conv in conversation_history:
                                history_text += f"User: {conv['user']}\nAssistant: {conv['assistant']}\n"
                            
                            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
                            if i == 0:
                                prompt = f"""{current_personality['prompt']}

{base_prompt}

{history_text}
Assistant:"""
                            else:
                                # å‰ã®å¿œç­”ã‹ã‚‰æ¬¡ã®è©±é¡Œã‚’ç”Ÿæˆ
                                prev_response = auto_responses[-1] if auto_responses else ""
                                prompt = f"""{current_personality['prompt']}

å‰ã®å¿œç­”ã‹ã‚‰è‡ªç„¶ã«ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚æ–°ã—ã„è¦–ç‚¹ã‚„é–¢é€£ã™ã‚‹è©±é¡Œã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

å‰ã®å¿œç­”: {prev_response}

{history_text}
Assistant:"""
                            
                            # Ollamaã§å¿œç­”ç”Ÿæˆ
                            if not st.session_state.ollama:
                                st.session_state.ollama = OllamaClient()
                            
                            response = st.session_state.ollama.generate_response(prompt)
                            
                            if response:
                                auto_responses.append(response)
                                
                                # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                                st.session_state.conversation_history.append({
                                    "user": f"è‡ªå‹•å¿œç­” {i+1} ({auto_topic})",
                                    "assistant": response,
                                    "personality": personality,
                                    "timestamp": datetime.datetime.now().isoformat()
                                })
                        
                        # è‡ªå‹•å¿œç­”çµæœã‚’è¡¨ç¤º
                        st.success(f"âœ… è‡ªå‹•å¿œç­”ã‚’ {len(auto_responses)} ä»¶ç”Ÿæˆã—ã¾ã—ãŸï¼")
                        
                        for i, response in enumerate(auto_responses):
                            with st.expander(f"ğŸ¤– è‡ªå‹•å¿œç­” {i+1}"):
                                st.write(response)
                        
                        # VRMã‚¢ãƒã‚¿ãƒ¼è¡¨æƒ…æ›´æ–°
                        if st.session_state.vrm_controller:
                            st.session_state.vrm_controller.set_personality(personality)
                        
                    except Exception as e:
                        st.error(f"è‡ªå‹•å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # èªè­˜çµæœãƒ»å…¥åŠ›çµæœè¡¨ç¤º
        if "recognized_text" in st.session_state and st.session_state.recognized_text:
            st.subheader("ğŸ’­ å…¥åŠ›å†…å®¹")
            st.write(st.session_state.recognized_text)
            
            # AIå¿œç­”ç”Ÿæˆ
            if st.button("ğŸ¤– AIå¿œç­”ç”Ÿæˆ", help="å…¥åŠ›å†…å®¹ã«å¯¾ã™ã‚‹AIå¿œç­”ã‚’ç”Ÿæˆ"):
                with st.spinner("AIå¿œç­”ã‚’ç”Ÿæˆä¸­..."):
                    try:
                        # äººæ ¼ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                        personality = st.session_state.current_personality
                        current_personality = personalities[personality]
                        
                        # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
                        conversation_history = st.session_state.conversation_history[-5:]
                        history_text = ""
                        for conv in conversation_history:
                            history_text += f"User: {conv['user']}\nAssistant: {conv['assistant']}\n"
                        
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
                        prompt = f"""{current_personality['prompt']}

ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã«å¯¾ã—ã¦ã€äººæ ¼ã«å¿œã˜ã¦è‡ªç„¶ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: {st.session_state.recognized_text}

{history_text}
Assistant:"""
                        
                        # Ollamaã§å¿œç­”ç”Ÿæˆ
                        if not st.session_state.ollama:
                            st.session_state.ollama = OllamaClient()
                        
                        response = st.session_state.ollama.generate_response(prompt)
                        
                        if response:
                            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                            st.session_state.conversation_history.append({
                                "user": st.session_state.recognized_text,
                                "assistant": response,
                                "personality": personality,
                                "timestamp": datetime.datetime.now().isoformat()
                            })
                            
                            # å¿œç­”è¡¨ç¤º
                            st.subheader("ğŸ¤– AIå¿œç­”")
                            st.write(response)
                            
                            # VRMã‚¢ãƒã‚¿ãƒ¼è¡¨æƒ…æ›´æ–°
                            if st.session_state.vrm_controller:
                                st.session_state.vrm_controller.set_personality(personality)
                            
                            # éŸ³å£°åˆæˆ
                            if st.button("ğŸ”Š å¿œç­”ã‚’éŸ³å£°ã§å†ç”Ÿ", key="tts_button"):
                                with st.spinner("éŸ³å£°åˆæˆä¸­..."):
                                    try:
                                        tts_engine = TTSEngine()
                                        tts_engine.speak(response)
                                        st.success("âœ… éŸ³å£°å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸ")
                                    except Exception as e:
                                        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                        else:
                            st.error("âŒ AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                            
                    except Exception as e:
                        st.error(f"AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with col2:
        st.header("ğŸ­ VRMã‚¢ãƒã‚¿ãƒ¼")
        
        # VRMã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤º
        if not st.session_state.vrm_controller:
            st.session_state.vrm_controller = VRMAvatarController()
        
        if st.session_state.vrm_controller.vrm_path:
            vrm_html = st.session_state.vrm_controller.get_vrm_html()
            st.components.v1.html(vrm_html, height=450)
        else:
            st.error("âŒ VRMãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ç¾åœ¨ã®äººæ ¼æƒ…å ±è¡¨ç¤º
        current_personality = personalities[st.session_state.current_personality]
        st.info(f"""
        **ç¾åœ¨ã®äººæ ¼**: {current_personality['icon']} {current_personality['name']}
        
        **è¡¨æƒ…**: {st.session_state.vrm_controller.expressions.get(st.session_state.current_personality, 'neutral')}
        """)
    
    # ä¼šè©±å±¥æ­´è¡¨ç¤º
    if st.session_state.conversation_history:
        st.header("ğŸ’¬ ä¼šè©±å±¥æ­´")
        
        for i, msg in enumerate(reversed(st.session_state.conversation_history[-10:])):
            with st.expander(f"ğŸ’­ {msg['user'][:30]}... ({msg.get('timestamp', 'N/A')})"):
                st.write(f"**ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {msg['user']}")
                st.write(f"**AI**: {msg['assistant']}")
                st.write(f"**äººæ ¼**: {msg.get('personality', 'N/A')}")
    else:
        st.info("ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚AIã¨ã®å¯¾è©±ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
