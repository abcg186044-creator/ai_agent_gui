#!/usr/bin/env python3
"""
AI Agent System - ãƒ“ã‚¸ãƒ§ãƒ³AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ 
llama3.2-visionãƒ¢ãƒ‡ãƒ«ã¨ç”»é¢èªè­˜ã‚’çµ±åˆã—ãŸé«˜åº¦ãªAIã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
import ollama
import pyautogui
import tempfile
import os
import time
from datetime import datetime
from PIL import Image
import io
import base64
import json

class VisionAISystem:
    """ãƒ“ã‚¸ãƒ§ãƒ³AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.ollama_client = None
        self.vision_model = "llama3.2-vision"
        self.text_model = "llama3.1:8b"
        self.current_mode = "text"  # text, vision, hybrid
        
    def initialize(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            self.ollama_client = ollama.Client()
            return True
        except Exception as e:
            st.error(f"âŒ ãƒ“ã‚¸ãƒ§ãƒ³AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def capture_screen(self, save_temp=True):
        """ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£å–å¾—"""
        try:
            screenshot = pyautogui.screenshot()
            
            if save_temp:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                temp_path = f"temp_screenshot_{timestamp}.png"
                screenshot.save(temp_path)
                return temp_path, screenshot
            else:
                return None, screenshot
                
        except Exception as e:
            st.error(f"âŒ ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, None
    
    def image_to_base64(self, image_path):
        """ç”»åƒã‚’base64ã«å¤‰æ›"""
        try:
            with open(image_path, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode('utf-8')
        except Exception as e:
            st.error(f"âŒ ç”»åƒå¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def analyze_screen_with_vision(self, prompt="ã“ã®ç”»é¢ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„"):
        """ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ç”»é¢åˆ†æ"""
        try:
            # ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£å–å¾—
            temp_path, screenshot = self.capture_screen()
            
            if temp_path is None:
                return "ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã§åˆ†æ
            with st.spinner("ğŸ” ãƒ“ã‚¸ãƒ§ãƒ³AIã§ç”»é¢åˆ†æä¸­..."):
                response = self.ollama_client.generate(
                    model=self.vision_model,
                    prompt=prompt,
                    images=[temp_path]
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(temp_path)
            except:
                pass
            
            return response['response']
            
        except Exception as e:
            return f"âŒ ç”»é¢åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def analyze_image_file(self, image_file, prompt="ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„"):
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        try:
            with st.spinner("ğŸ” ãƒ“ã‚¸ãƒ§ãƒ³AIã§ç”»åƒåˆ†æä¸­..."):
                response = self.ollama_client.generate(
                    model=self.vision_model,
                    prompt=prompt,
                    images=[image_file]
                )
            
            return response['response']
            
        except Exception as e:
            return f"âŒ ç”»åƒåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def hybrid_analysis(self, prompt, image_path=None):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æï¼ˆãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒï¼‰"""
        try:
            # ç”»åƒãŒãªã„å ´åˆã¯ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£
            if image_path is None:
                image_path, _ = self.capture_screen()
            
            if image_path is None:
                return "ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            with st.spinner("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIåˆ†æä¸­..."):
                response = self.ollama_client.generate(
                    model=self.vision_model,
                    prompt=f"ä»¥ä¸‹ã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’çµ±åˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„:\n\nãƒ†ã‚­ã‚¹ãƒˆ: {prompt}\n\nç”»åƒ:",
                    images=[image_path]
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                if os.path.exists(image_path) and "temp_screenshot" in image_path:
                    os.unlink(image_path)
            except:
                pass
            
            return response['response']
            
        except Exception as e:
            return f"âŒ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def extract_text_from_screen(self):
        """ç”»é¢ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆOCRæ©Ÿèƒ½ï¼‰"""
        try:
            temp_path, _ = self.capture_screen()
            
            if temp_path is None:
                return "ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            ocr_prompt = """ã“ã®ç”»åƒã‹ã‚‰ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
            èª­ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä¿ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            ãƒœã‚¿ãƒ³ã€ãƒ©ãƒ™ãƒ«ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã©ã€ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚"""
            
            with st.spinner("ğŸ“ ç”»é¢ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­..."):
                response = self.ollama_client.generate(
                    model=self.vision_model,
                    prompt=ocr_prompt,
                    images=[temp_path]
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(temp_path)
            except:
                pass
            
            return response['response']
            
        except Exception as e:
            return f"âŒ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def analyze_ui_elements(self):
        """UIè¦ç´ ã®åˆ†æ"""
        try:
            temp_path, _ = self.capture_screen()
            
            if temp_path is None:
                return "ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            ui_prompt = """ã“ã®ç”»é¢ã®UIè¦ç´ ã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ï¼š
            1. ã™ã¹ã¦ã®ãƒœã‚¿ãƒ³ã¨ãã®ãƒ©ãƒ™ãƒ«
            2. ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã¨éšå±¤æ§‹é€ 
            3. å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
            4. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„è­¦å‘Š
            5. ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³è¦ç´ 
            6. å…¨ä½“çš„ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ 
            
            å¯èƒ½ãªé™ã‚Šè©³ç´°ã«ã€æ§‹é€ åŒ–ã—ã¦å ±å‘Šã—ã¦ãã ã•ã„ã€‚"""
            
            with st.spinner("ğŸ¨ UIè¦ç´ åˆ†æä¸­..."):
                response = self.ollama_client.generate(
                    model=self.vision_model,
                    prompt=ui_prompt,
                    images=[temp_path]
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(temp_path)
            except:
                pass
            
            return response['response']
            
        except Exception as e:
            return f"âŒ UIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def render_vision_interface():
    """ãƒ“ã‚¸ãƒ§ãƒ³AIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.header("ğŸ‘ï¸ ãƒ“ã‚¸ãƒ§ãƒ³AIã‚·ã‚¹ãƒ†ãƒ ")
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“¸ ç”»é¢åˆ†æ", type="primary"):
            vision_system.current_mode = "screen_analysis"
    
    with col2:
        if st.button("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º", type="primary"):
            vision_system.current_mode = "text_extraction"
    
    with col3:
        if st.button("ğŸ¨ UIè¦ç´ åˆ†æ", type="primary"):
            vision_system.current_mode = "ui_analysis"
    
    st.markdown("---")
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›
    custom_prompt = st.text_area(
        "ğŸ” ã‚«ã‚¹ã‚¿ãƒ åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        placeholder="ç”»é¢ã«ã¤ã„ã¦ã©ã®ã‚ˆã†ãªåˆ†æã‚’ã—ã¾ã™ã‹ï¼Ÿ",
        height=100,
        key="vision_prompt"
    )
    
    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ” ç”»é¢ã‚’åˆ†æ", type="primary", key="analyze_screen"):
            if custom_prompt:
                result = vision_system.analyze_screen_with_vision(custom_prompt)
            else:
                result = vision_system.analyze_screen_with_vision()
            
            st.subheader("ğŸ“Š åˆ†æçµæœ")
            st.write(result)
    
    with col2:
        if st.button("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º", type="primary", key="extract_text"):
            result = vision_system.extract_text_from_screen()
            st.subheader("ğŸ“ æŠ½å‡ºçµæœ")
            st.write(result)
    
    # UIè¦ç´ åˆ†æ
    if st.button("ğŸ¨ UIè¦ç´ ã‚’åˆ†æ", type="primary", key="analyze_ui"):
        result = vision_system.analyze_ui_elements()
        st.subheader("ğŸ¨ UIè¦ç´ åˆ†æçµæœ")
        st.write(result)
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ
    st.markdown("---")
    st.subheader("ğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ")
    
    uploaded_file = st.file_uploader(
        "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        type=['png', 'jpg', 'jpeg', 'bmp', 'gif'],
        key="vision_image_file"
    )
    
    if uploaded_file:
        # ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        image = Image.open(uploaded_file)
        st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)
        
        # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        image_prompt = st.text_area(
            "ğŸ” ç”»åƒåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            placeholder="ã“ã®ç”»åƒã«ã¤ã„ã¦ã©ã®ã‚ˆã†ãªåˆ†æã‚’ã—ã¾ã™ã‹ï¼Ÿ",
            height=100,
            key="image_prompt",
            value="ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„"
        )
        
        if st.button("ğŸ” ç”»åƒã‚’åˆ†æ", type="primary", key="analyze_image"):
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            result = vision_system.analyze_image_file(tmp_file_path, image_prompt)
            st.subheader("ğŸ“Š ç”»åƒåˆ†æçµæœ")
            st.write(result)
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(tmp_file_path)
            except:
                pass

def render_hybrid_interface():
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.header("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIåˆ†æ")
    
    # ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã¨ãƒ†ã‚­ã‚¹ãƒˆã®çµ±åˆåˆ†æ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“¸ ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£")
        if st.button("ğŸ“¸ ç”»é¢ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£", key="capture_for_hybrid"):
            temp_path, screenshot = vision_system.capture_screen(save_temp=False)
            if screenshot:
                st.session_state.hybrid_image = screenshot
                st.success("âœ… ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£å®Œäº†")
                st.image(screenshot, caption="ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸç”»é¢", use_column_width=True)
    
    with col2:
        st.subheader("ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›")
        hybrid_prompt = st.text_area(
            "ğŸ’¬ åˆ†æãƒ†ã‚­ã‚¹ãƒˆ",
            placeholder="ç”»é¢ã«ã¤ã„ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚„æŒ‡ç¤ºãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            height=150,
            key="hybrid_prompt"
        )
    
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æå®Ÿè¡Œ
    if st.button("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æ", type="primary", key="hybrid_analysis"):
        if 'hybrid_image' in st.session_state and hybrid_prompt:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:
                screenshot = st.session_state.hybrid_image
                screenshot.save(tmp_file.name)
                tmp_file_path = tmp_file.name
            
            result = vision_system.hybrid_analysis(hybrid_prompt, tmp_file_path)
            st.subheader("ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æçµæœ")
            st.write(result)
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(tmp_file_path)
            except:
                pass
        else:
            st.warning("âš ï¸ ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")

def render_quick_actions():
    """ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
    st.header("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“¸ ç”»é¢ã‚’èª¬æ˜", key="quick_describe"):
            result = vision_system.analyze_screen_with_vision("ã“ã®ç”»é¢ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„")
            st.info("ğŸ“Š ç”»é¢èª¬æ˜:")
            st.write(result)
    
    with col2:
        if st.button("âŒ ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º", key="quick_error"):
            error_prompt = """ã“ã®ç”»é¢ã«ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€è­¦å‘Šã€å•é¡Œç‚¹ãŒãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
            èµ¤ã„æ–‡å­—ã€ã‚¨ãƒ©ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã€è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ç•°å¸¸ãªè¡¨ç¤ºãªã©ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚"""
            result = vision_system.analyze_screen_with_vision(error_prompt)
            st.info("ğŸš¨ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœ:")
            st.write(result)
    
    with col3:
        if st.button("ğŸ’¡ æ“ä½œæ‰‹é †ã‚’èª¬æ˜", key="quick_instructions"):
            instruction_prompt = """ã“ã®ç”»é¢ã®æ“ä½œæ–¹æ³•ã‚„æ‰‹é †ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
            ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯é †åºã€å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä½¿ã„æ–¹ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ãªã©ã‚’è©³ç´°ã«æ•™ãˆã¦ãã ã•ã„ã€‚"""
            result = vision_system.analyze_screen_with_vision(instruction_prompt)
            st.info("ğŸ“‹ æ“ä½œæ‰‹é †:")
            st.write(result)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    st.set_page_config(
        page_title="ğŸ‘ï¸ Vision AI System",
        page_icon="ğŸ‘ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ‘ï¸ AI Agent Vision System")
    st.markdown("### ğŸš€ llama3.2-vision + ç”»é¢èªè­˜ã®çµ±åˆ")
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°åˆæœŸåŒ–
    if 'vision_system' not in st.session_state:
        st.session_state.vision_system = VisionAISystem()
        if st.session_state.vision_system.initialize():
            st.success("âœ… ãƒ“ã‚¸ãƒ§ãƒ³AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        else:
            st.error("âŒ ãƒ“ã‚¸ãƒ§ãƒ³AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—")
            st.stop()
    
    vision_system = st.session_state.vision_system
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
    with st.sidebar:
        st.header("ğŸ‘ï¸ ãƒ“ã‚¸ãƒ§ãƒ³AIè¨­å®š")
        
        st.write(f"**ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«**: {vision_system.vision_model}")
        st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«**: {vision_system.text_model}")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        try:
            models = vision_system.ollama_client.list()
            vision_models = [m['name'] for m in models if 'vision' in m['name'].lower()]
            st.write("**åˆ©ç”¨å¯èƒ½ãªãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«**:")
            for model in vision_models:
                st.write(f"- {model}")
        except:
            st.write("âŒ ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼")
        
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ©ç”¨çµ±è¨ˆ")
        
        # ç°¡å˜ãªçµ±è¨ˆè¡¨ç¤ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯DBã«ä¿å­˜ï¼‰
        st.metric("åˆ†æå®Ÿè¡Œå›æ•°", "0")
        st.metric("ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå›æ•°", "0")
        st.metric("UIåˆ†æå›æ•°", "0")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
    tab1, tab2, tab3 = st.tabs(["ğŸ‘ï¸ ãƒ“ã‚¸ãƒ§ãƒ³AI", "ğŸ§  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æ", "âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"])
    
    with tab1:
        render_vision_interface()
    
    with tab2:
        render_hybrid_interface()
    
    with tab3:
        render_quick_actions()
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.markdown("---")
    st.markdown(f"**æœ€çµ‚æ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.markdown("**ğŸš€ llama3.2-visionãƒ¢ãƒ‡ãƒ«ã§é«˜åº¦ãªç”»åƒèªè­˜ã‚’å®Ÿç¾**")

if __name__ == "__main__":
    main()
