#!/usr/bin/env python3
"""
YouTubeéŸ³å£°åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
RVCå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã‚’æ”¯æ´
"""

import os
import json
import subprocess
import librosa
import soundfile as sf
import numpy as np
from pathlib import Path
import yt_dlp
from typing import List, Dict, Optional
import argparse

class VoiceCollector:
    def __init__(self, output_dir: str = "voice_dataset"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        (self.output_dir / "raw").mkdir(exist_ok=True)
        (self.output_dir / "processed").mkdir(exist_ok=True)
        (self.output_dir / "metadata").mkdir(exist_ok=True)
        
        self.metadata = {
            "collected_videos": [],
            "total_duration": 0,
            "sample_rate": 22050,
            "created_at": None
        }
    
    def download_audio(self, url: str, quality: str = "best") -> Optional[str]:
        """YouTubeã‹ã‚‰éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            ydl_opts = {
                'format': 'bestaudio/best',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'wav',
                    'preferredquality': '192',
                }],
                'outtmpl': str(self.output_dir / "raw" / "%(title)s.%(ext)s"),
                'quiet': False,
                'no_warnings': False,
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                title = info.get('title', 'unknown')
                duration = info.get('duration', 0)
                
                # WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
                wav_path = self.output_dir / "raw" / f"{title}.wav"
                
                if wav_path.exists():
                    print(f"âœ… éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {title}")
                    print(f"ğŸ“ ä¿å­˜å…ˆ: {wav_path}")
                    print(f"â±ï¸ é•·ã•: {duration}ç§’")
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
                    self.metadata["collected_videos"].append({
                        "title": title,
                        "url": url,
                        "duration": duration,
                        "file_path": str(wav_path),
                        "collected_at": str(Path(wav_path).stat().st_mtime)
                    })
                    
                    return str(wav_path)
                else:
                    print("âŒ WAVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return None
                    
        except Exception as e:
            print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def process_audio(self, wav_path: str, segment_length: float = 10.0) -> List[str]:
        """éŸ³å£°ã‚’RVCå­¦ç¿’ç”¨ã«å‡¦ç†"""
        try:
            # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
            y, sr = librosa.load(wav_path, sr=22050)
            
            # ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡ºã—ã¦åˆ†å‰²
            intervals = librosa.effects.split(y, top_db=20)
            
            processed_files = []
            base_name = Path(wav_path).stem
            
            for i, (start, end) in enumerate(intervals):
                segment = y[start:end]
                
                # çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if len(segment) / sr < 1.0:
                    continue
                
                # é•·ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯åˆ†å‰²
                if len(segment) / sr > segment_length:
                    sub_segments = self._split_long_segment(segment, sr, segment_length)
                    for j, sub_seg in enumerate(sub_segments):
                        output_path = self.output_dir / "processed" / f"{base_name}_seg{i}_{j}.wav"
                        sf.write(output_path, sub_seg, sr)
                        processed_files.append(str(output_path))
                else:
                    output_path = self.output_dir / "processed" / f"{base_name}_seg{i}.wav"
                    sf.write(output_path, segment, sr)
                    processed_files.append(str(output_path))
            
            print(f"âœ… éŸ³å£°å‡¦ç†å®Œäº†: {len(processed_files)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            return processed_files
            
        except Exception as e:
            print(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _split_long_segment(self, segment: np.ndarray, sr: int, max_length: float) -> List[np.ndarray]:
        """é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²"""
        max_samples = int(max_length * sr)
        segments = []
        
        for i in range(0, len(segment), max_samples):
            end = min(i + max_samples, len(segment))
            segments.append(segment[i:end])
        
        return segments
    
    def create_dataset_metadata(self, processed_files: List[str]):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        dataset_info = {
            "files": [],
            "total_files": len(processed_files),
            "total_duration": 0,
            "sample_rate": 22050,
            "created_at": str(Path().cwd())
        }
        
        for file_path in processed_files:
            try:
                duration = librosa.get_duration(filename=file_path)
                dataset_info["files"].append({
                    "path": file_path,
                    "duration": duration,
                    "name": Path(file_path).name
                })
                dataset_info["total_duration"] += duration
            except Exception as e:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {file_path} - {str(e)}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        metadata_path = self.output_dir / "metadata" / "dataset_info.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")
        print(f"ğŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {dataset_info['total_files']}")
        print(f"â±ï¸ ç·æ™‚é–“: {dataset_info['total_duration']:.2f}ç§’")
        
        return dataset_info
    
    def create_rvc_config(self, target_voice_name: str):
        """RVCå­¦ç¿’ç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        config = {
            "model_name": target_voice_name,
            "sample_rate": 22050,
            "pitch_extraction_algorithm": "harvest",
            "feature_index": 1,
            "feature_index_file": "added_IVF512_Flat_nprobe_1_v2.index",
            "index_rate": 0.8,
            "device": "cuda:0",
            "is_half": True,
            "f0_method": "harvest",
            "filter_radius": 3,
            "resample_sr": 0,
            "rms_mix_rate": 0.25,
            "protect": 0.33,
            "crepe_hop_length": 128,
            "spk2id": {
                target_voice_name: 0
            }
        }
        
        config_path = self.output_dir / "metadata" / "rvc_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… RVCè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {config_path}")
        return config_path
    
    def save_metadata(self):
        """åé›†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        metadata_path = self.output_dir / "metadata" / "collection_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, indent=2, ensure_ascii=False)
        print(f"âœ… åé›†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")

def main():
    parser = argparse.ArgumentParser(description="YouTubeéŸ³å£°åé›†ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--url", required=True, help="YouTubeå‹•ç”»URL")
    parser.add_argument("--output", default="voice_dataset", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--voice-name", default="target_voice", help="ç›®æ¨™éŸ³å£°å")
    parser.add_argument("--segment-length", type=float, default=10.0, help="ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰")
    
    args = parser.parse_args()
    
    collector = VoiceCollector(args.output)
    
    print("ğŸ¤ YouTubeéŸ³å£°åé›†ã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"ğŸ“º URL: {args.url}")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {args.output}")
    
    # éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    wav_path = collector.download_audio(args.url)
    if not wav_path:
        print("âŒ éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # éŸ³å£°å‡¦ç†
    processed_files = collector.process_audio(wav_path, args.segment_length)
    if not processed_files:
        print("âŒ éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dataset_info = collector.create_dataset_metadata(processed_files)
    
    # RVCè¨­å®šä½œæˆ
    collector.create_rvc_config(args.voice_name)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    collector.save_metadata()
    
    print("ğŸ‰ éŸ³å£°åé›†å®Œäº†ï¼")
    print(f"ğŸ“Š å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(processed_files)}å€‹")
    print(f"â±ï¸ ç·æ™‚é–“: {dataset_info['total_duration']:.2f}ç§’")
    print(f"ğŸ”§ RVCå­¦ç¿’æº–å‚™å®Œäº†: {args.output}")

if __name__ == "__main__":
    main()
