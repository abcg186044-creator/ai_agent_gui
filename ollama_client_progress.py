#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ollama APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆ240ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ + é€”ä¸­å ±å‘Šæ©Ÿèƒ½ï¼‰
"""

import requests
import json
import time
import threading
from queue import Queue

class OllamaClient:
    def __init__(self, base_url="http://localhost:11434", model="llama3.1:8b", timeout=240):
        self.base_url = base_url
        self.model = model
        self.timeout = timeout
        self.progress_queue = Queue()
        self.is_generating = False
        
    def _progress_reporter(self, callback):
        """é€”ä¸­å ±å‘Šã‚’è¡Œã†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        start_time = time.time()
        progress_steps = [
            "ğŸ” Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šä¸­...",
            "ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡ä¸­...",
            "ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ãŒæ€è€ƒã‚’é–‹å§‹...",
            "ğŸ§  è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...",
            "âš¡ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ•´å½¢ä¸­...",
            "âœ… å¿œç­”ç”Ÿæˆå®Œäº†"
        ]
        
        step = 0
        while self.is_generating and step < len(progress_steps):
            elapsed = time.time() - start_time
            progress_percent = min((elapsed / self.timeout) * 100, 95)
            
            callback({
                "step": progress_steps[step],
                "progress": progress_percent,
                "elapsed": elapsed,
                "remaining": max(self.timeout - elapsed, 0)
            })
            
            step += 1
            time.sleep(10)  # 10ç§’ã”ã¨ã«å ±å‘Š
        
        # æœ€çµ‚å ±å‘Š
        if self.is_generating:
            callback({
                "step": "ğŸ”„ ã¾ã å¿œç­”ã‚’ç”Ÿæˆä¸­...ã‚‚ã†å°‘ã€…ãŠå¾…ã¡ãã ã•ã„",
                "progress": 95,
                "elapsed": time.time() - start_time,
                "remaining": max(self.timeout - (time.time() - start_time), 0)
            })
    
    def generate_response(self, prompt, max_tokens=1000, progress_callback=None):
        """Ollama APIã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆï¼ˆé€”ä¸­å ±å‘Šä»˜ãï¼‰"""
        self.is_generating = True
        progress_thread = None
        
        if progress_callback:
            # é€”ä¸­å ±å‘Šã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
            progress_thread = threading.Thread(
                target=self._progress_reporter, 
                args=(progress_callback,),
                daemon=True
            )
            progress_thread.start()
        
        try:
            url = f"{self.base_url}/api/generate"
            
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": max_tokens
                }
            }
            
            print(f"ğŸ” Ollama APIå‘¼ã³å‡ºã—: {self.base_url}")
            print(f"ğŸ” ãƒ¢ãƒ‡ãƒ«: {self.model}")
            print(f"ğŸ” ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {self.timeout}ç§’")
            print(f"ğŸ” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt)} æ–‡å­—")
            
            start_time = time.time()
            
            response = requests.post(
                url,
                json=payload,
                timeout=self.timeout,
                headers={"Content-Type": "application/json"}
            )
            
            elapsed_time = time.time() - start_time
            print(f"â±ï¸ å¿œç­”æ™‚é–“: {elapsed_time:.2f}ç§’")
            
            self.is_generating = False
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“")
                
                # æœ€çµ‚å ±å‘Š
                if progress_callback:
                    progress_callback({
                        "step": "âœ… å¿œç­”ç”Ÿæˆå®Œäº†",
                        "progress": 100,
                        "elapsed": elapsed_time,
                        "remaining": 0,
                        "response_length": len(response_text)
                    })
                
                return response_text
            else:
                print(f"âŒ APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return f"APIã‚¨ãƒ©ãƒ¼: {response.status_code}"
                
        except requests.exceptions.Timeout:
            elapsed_time = time.time() - start_time
            print(f"âŒ Ollama APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ{self.timeout}ç§’ï¼‰")
            self.is_generating = False
            
            if progress_callback:
                progress_callback({
                    "step": f"âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿï¼ˆ{self.timeout}ç§’ï¼‰",
                    "progress": 100,
                    "elapsed": elapsed_time,
                    "remaining": 0,
                    "error": "timeout"
                })
            
            return f"AIå¿œç­”ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{self.timeout}ç§’ï¼‰ã€‚æ™‚é–“ã‚’ç½®ã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Ollama APIã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.is_generating = False
            
            if progress_callback:
                progress_callback({
                    "step": f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}",
                    "progress": 100,
                    "elapsed": elapsed_time,
                    "remaining": 0,
                    "error": str(e)
                })
            
            return f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        finally:
            self.is_generating = False

# ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    def progress_callback(progress_info):
        print(f"ğŸ“Š {progress_info['step']} ({progress_info['progress']:.1f}%)")
        print(f"   â±ï¸ çµŒéæ™‚é–“: {progress_info['elapsed']:.1f}ç§’")
        print(f"   â³ æ®‹ã‚Šæ™‚é–“: {progress_info['remaining']:.1f}ç§’")
        print("-" * 50)
    
    client = OllamaClient(timeout=240)
    
    # é›»å“ã‚¢ãƒ—ãƒªä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    prompt = """Pythonã§GUIã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦æ“ä½œã§ãã‚‹é›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
Tkinterã‚’ä½¿ç”¨ã—ã¦ã€åŸºæœ¬çš„ãªå››å‰‡æ¼”ç®—ãŒã§ãã‚‹å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. æ•°å­—ãƒœã‚¿ãƒ³ï¼ˆ0-9ï¼‰
2. æ¼”ç®—å­ãƒœã‚¿ãƒ³ï¼ˆ+ã€-ã€*ã€/ï¼‰
3. ã‚¤ã‚³ãƒ¼ãƒ«ãƒœã‚¿ãƒ³
4. ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
5. å°æ•°ç‚¹ãƒœã‚¿ãƒ³
6. è¡¨ç¤ºç”»é¢
7. ã‚¨ãƒ©ãƒ¼å‡¦ç†
8. ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›å¯¾å¿œ
å®Œå…¨ãªå®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""
    
    print("ğŸš€ 240ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ + é€”ä¸­å ±å‘Šæ©Ÿèƒ½ã§é›»å“ã‚¢ãƒ—ãƒªä½œæˆé–‹å§‹")
    print("=" * 60)
    
    response = client.generate_response(prompt, progress_callback=progress_callback)
    
    print("\nğŸ”§ ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰:")
    print("-" * 40)
    print(response)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open("calculator_with_progress.py", "w", encoding="utf-8") as f:
        f.write(response)
    
    print("\nğŸ’¾ ã‚³ãƒ¼ãƒ‰ã‚’ calculator_with_progress.py ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    if response and not response.startswith("AIå¿œç­”ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"):
        print("âœ… é›»å“ã‚¢ãƒ—ãƒªã®ç”Ÿæˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
        print("ğŸš€ å®Ÿè¡Œæ–¹æ³•: python calculator_with_progress.py")
    else:
        print("âŒ é›»å“ã‚¢ãƒ—ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
