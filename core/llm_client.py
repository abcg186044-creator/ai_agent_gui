"""
LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Ollamaã¨ã®é€šä¿¡ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã€è‡ªå·±é€²åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç®¡ç†
"""

import re
import json
import os
from datetime import datetime
from .constants import *
from .self_mutation import ModularSelfMutationManager
from .file_map import resolve_target_file, get_relevant_files

class OllamaClient:
    def __init__(self, model_name="llama2", base_url="http://localhost:11434"):
        self.model_name = model_name
        self.base_url = base_url
        self.conversation_history = []
    
    def generate_response(self, prompt, context=None):
        """Ollamaã§å¿œç­”ç”Ÿæˆ"""
        try:
            import requests
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
            full_prompt = self._build_prompt(prompt, context)
            
            # Ollama APIå‘¼ã³å‡ºã—
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": full_prompt,
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "")
            else:
                return f"APIã‚¨ãƒ©ãƒ¼: {response.status_code}"
                
        except Exception as e:
            return f"LLMæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _build_prompt(self, user_input, context=None):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        # åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        base_prompt = f"""
ã‚ãªãŸã¯è¦ªåˆ‡ã§å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ä¸å¯§ã«ãŠç­”ãˆãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: {user_input}
"""
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°è¿½åŠ 
        if context:
            base_prompt += f"\nã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}"
        
        return base_prompt

class SelfEvolvingAgent:
    def __init__(self):
        self.evolution_rules = []
        self.consciousness_level = 0.5
        self.mutation_manager = ModularSelfMutationManager()
        self.load_evolution_rules()
    
    def apply_self_mutation(self, user_request: str) -> Dict:
        """ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‹™ã„æ’ƒã¡ã™ã‚‹å±€æ‰€çš„è‡ªå·±æ”¹é€ ã‚’å®Ÿè¡Œ"""
        try:
            from services.state_manager import resolve_target_file
            from services.app_generator import partial_mutation_manager
            from services.backup_manager import backup_manager
            from services.import_sync import import_synchronizer, module_validator
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
            target_file = resolve_target_file(user_request)
            
            if not target_file:
                return {
                    "success": False,
                    "error": "ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    "suggestion": "ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºï¼ˆä¾‹ï¼šã€Œãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å¤‰ãˆã¦ã€ã€ŒUIã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä¿®æ­£ã€ï¼‰ã‚’è©¦ã—ã¦ãã ã•ã„"
                }
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’èª­ã¿è¾¼ã¿
            print(f"ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {target_file}")
            
            # å®‰å…¨ãªéƒ¨åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
            backup_path = backup_manager.create_backup(target_file)
            
            if not backup_path:
                return {
                    "success": False,
                    "error": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
                }
            
            # ä¿®æ­£ãŒå¿…è¦ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            target_function = self._estimate_target_function(user_request, target_file)
            
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
            focused_prompt = partial_mutation_manager.generate_focused_prompt(
                target_file, user_request, target_function
            )
            
            # LLMã«ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã•ã›ã‚‹
            if not st.session_state.get(SESSION_KEYS['ollama']):
                st.session_state[SESSION_KEYS['ollama']] = OllamaClient()
            
            ollama_client = st.session_state[SESSION_KEYS['ollama']]
            modified_code = ollama_client.generate_response(focused_prompt)
            
            # ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ä¸Šæ›¸ãä¿å­˜
            mutation_result = partial_mutation_manager.apply_partial_mutation(
                target_file, modified_code, target_function
            )
            
            if mutation_result["success"]:
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆåŒæœŸã‚’å®Ÿè¡Œ
                sync_result = import_synchronizer.sync_imports_after_mutation(target_file)
                
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                validation_result = module_validator.validate_all_modules()
                
                return {
                    "success": True,
                    "target_file": target_file,
                    "backup_path": backup_path,
                    "target_function": target_function,
                    "sync_result": sync_result,
                    "validation_result": validation_result,
                    "message": f"{target_file} ã®ã¿ã‚’æ­£å¸¸ã«ä¿®æ­£ã—ã¾ã—ãŸ"
                }
            else:
                return {
                    "success": False,
                    "error": mutation_result["error"],
                    "target_file": target_file,
                    "backup_path": backup_path
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"å±€æ‰€çš„è‡ªå·±æ”¹é€ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def execute_self_mutation(self, user_request: str) -> Dict:
        """è‡ªå·±æ”¹é€ ã‚’å®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—å¯¾å¿œç‰ˆï¼‰"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—ã‹ã‚‰å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‰¹å®š
            target_module = resolve_target_file(user_request)
            
            if not target_module:
                # å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã‚‚è©¦è¡Œ
                target_module = self.mutation_manager.detect_target_module(user_request)
            
            if not target_module:
                return {
                    "success": False,
                    "error": "æ”¹é€ å¯¾è±¡ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    "suggestion": "ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºï¼ˆä¾‹ï¼šã€Œãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å¤‰ãˆã¦ã€ã€ŒAIã®æ€§æ ¼ã‚’å¤‰ãˆã¦ã€ï¼‰ã‚’è©¦ã—ã¦ãã ã•ã„"
                }
            
            # å±€æ‰€çš„ãªè‡ªå·±æ›¸ãæ›ãˆã‚’å®Ÿè¡Œ
            return self._execute_partial_mutation(target_module, user_request)
                
        except Exception as e:
            return {
                "success": False,
                "error": f"è‡ªå·±æ”¹é€ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def _execute_partial_mutation(self, file_path: str, user_request: str) -> Dict:
        """å±€æ‰€çš„ãªè‡ªå·±æ›¸ãæ›ãˆã‚’å®Ÿè¡Œ"""
        try:
            from services.app_generator import partial_mutation_manager
            from services.import_sync import import_synchronizer, module_validator
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–¢æ•°ã‚’æ¨å®š
            target_function = self._estimate_target_function(user_request, file_path)
            
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            focused_prompt = partial_mutation_manager.generate_focused_prompt(
                file_path, user_request, target_function
            )
            
            # LLMã§ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
            if not st.session_state.get(SESSION_KEYS['ollama']):
                st.session_state[SESSION_KEYS['ollama']] = OllamaClient()
            
            ollama_client = st.session_state[SESSION_KEYS['ollama']]
            modified_code = ollama_client.generate_response(focused_prompt)
            
            # å±€æ‰€çš„ãªæ›¸ãæ›ãˆã‚’é©ç”¨
            mutation_result = partial_mutation_manager.apply_partial_mutation(
                file_path, modified_code, target_function
            )
            
            if mutation_result["success"]:
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆåŒæœŸã‚’å®Ÿè¡Œ
                sync_result = import_synchronizer.sync_imports_after_mutation(file_path)
                
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                validation_result = module_validator.validate_all_modules()
                
                return {
                    "success": True,
                    "target_module": file_path,
                    "mutation_type": "partial",
                    "target_function": target_function,
                    "backup_path": mutation_result["backup_path"],
                    "sync_result": sync_result,
                    "validation_result": validation_result,
                    "message": f"{file_path} ã®ä¸€éƒ¨ã‚’æ­£å¸¸ã«æ”¹é€ ã—ã¾ã—ãŸ"
                }
            else:
                return {
                    "success": False,
                    "error": mutation_result["error"],
                    "backup_path": mutation_result.get("backup_path")
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"å±€æ‰€çš„æ›¸ãæ›ãˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def _estimate_target_function(self, user_request: str, file_path: str) -> Optional[str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–¢æ•°ã‚’æ¨å®š"""
        try:
            from services.app_generator import CodeExtractor
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®é–¢æ•°ã‚’å–å¾—
            extractor = CodeExtractor()
            functions = extractor.extract_functions(file_path)
            
            if not functions:
                return None
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§é–¢æ•°ã‚’æ¨å®š
            request_lower = user_request.lower()
            
            # ä¸€èˆ¬çš„ãªé–¢æ•°åã¨ã®ãƒãƒƒãƒãƒ³ã‚°
            function_keywords = {
                "ãƒ‡ã‚¶ã‚¤ãƒ³": ["get_", "render_", "apply_", "set_"],
                "UI": ["render_", "display_", "show_", "update_"],
                "ã‚¹ã‚¿ã‚¤ãƒ«": ["get_", "set_", "apply_", "update_"],
                "AI": ["generate_", "process_", "handle_", "respond_"],
                "ä¼šè©±": ["chat_", "conversation_", "message_", "respond_"],
                "VRM": ["vrm_", "avatar_", "render_", "update_"],
                "TODO": ["todo_", "task_", "add_", "complete_"],
                "ä¿å­˜": ["save_", "store_", "write_", "persist_"],
                "èª­ã¿è¾¼ã¿": ["load_", "read_", "get_", "fetch_"]
            }
            
            for keyword, prefixes in function_keywords.items():
                if keyword in request_lower:
                    for func_name in functions.keys():
                        for prefix in prefixes:
                            if func_name.startswith(prefix):
                                return func_name
            
            # æœ€åˆã®é–¢æ•°ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦è¿”ã™
            return list(functions.keys())[0] if functions else None
            
        except Exception as e:
            print(f"é–¢æ•°æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _generate_mutation_code(self, user_request: str, target_module: str) -> Optional[str]:
        """æ”¹é€ ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        if "ãƒ‡ã‚¶ã‚¤ãƒ³" in user_request and "styles.py" in target_module:
            return '''
# æ–°ã—ã„ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ
NEW_THEME = {"ocean": {"primary": "#0077be", "secondary": "#00a8cc"}}
'''
        elif "æ€§æ ¼" in user_request and "llm_client.py" in target_module:
            return '''
# æ–°ã—ã„äººæ ¼ã‚¿ã‚¤ãƒ—
NEW_PERSONALITY = {"philosopher": {"name": "å“²å­¦è€…", "prompt": "æ·±é ãªå“²å­¦è€…ã§ã™"}}
'''
        return None
    
    def _apply_mutation(self, target_module: str, updated_code: str) -> bool:
        """æ”¹é€ ã‚’é©ç”¨"""
        try:
            with open(target_module, 'a', encoding='utf-8') as f:
                f.write('\n\n' + updated_code)
            return True
        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãæ›ãˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

class ConversationalEvolutionAgent:
    def __init__(self):
        self.consciousness_level = 0.3
        self.learning_rate = 0.001
    
    def check_and_evolve_automatically(self, conversation_history):
        """å¯¾è©±ã‹ã‚‰ã®è‡ªå¾‹é€²åŒ–ã‚’ãƒã‚§ãƒƒã‚¯"""
        if len(conversation_history) < 3:
            return None
        
        # æœ€æ–°3ä»¶ã®å¯¾è©±ã‚’åˆ†æ
        recent_convs = conversation_history[-3:]
        
        # è¤‡é›‘ã•ã®æŒ‡æ¨™ã‚’è¨ˆç®—
        complexity_score = self._calculate_complexity(recent_convs)
        
        if complexity_score > 0.7:
            return self._evolve("complexity", complexity_score)
        
        return None
    
    def _calculate_complexity(self, conversations):
        """å¯¾è©±ã®è¤‡é›‘ã•ã‚’è¨ˆç®—"""
        total_length = 0
        question_count = 0
        
        for conv in conversations:
            user_text = conv.get("user", "")
            total_length += len(user_text)
            if "ï¼Ÿ" in user_text or "ã§ã™ã‹" in user_text:
                question_count += 1
        
        # è¤‡é›‘ã•ã‚¹ã‚³ã‚¢ï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        complexity = (total_length / 1000) + (question_count * 0.1)
        return min(complexity, 1.0)
    
    def _evolve(self, evolution_type, score):
        """é€²åŒ–ã‚’å®Ÿè¡Œ"""
        self.consciousness_level += self.learning_rate * score
        return {
            "success": True,
            "evolution_type": evolution_type,
            "consciousness_boost": self.learning_rate * score,
            "new_consciousness_level": self.consciousness_level
        }

def extract_todos_from_text(text, source="auto"):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰TODOã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°"""
    todos = []
    
    # TODOæŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
    todo_patterns = [
        r'(æ˜æ—¥|ä»Šæ—¥|ä»Šé€±|æ¥é€±).*?(ã™ã‚‹|ã‚„ã‚‹|ä½œã‚‹|å®Ÿè£…ã™ã‚‹|ç¢ºèªã™ã‚‹|æº–å‚™ã™ã‚‹)',
        r'(.*?)(ã™ã‚‹å¿…è¦ãŒã‚ã‚‹|ã‚„ã‚‰ãªã„ã¨|ã—ãªã„ã¨ã„ã‘ãªã„)',
        r'(.*?)(ã®äºˆå®š|ã®è¨ˆç”»|ã®ç›®æ¨™)',
        r'(.*?)(ã‚’å¿˜ã‚Œãªã„ã§|ã‚’è¦šãˆã¦ãŠã„ã¦|ã‚’ãƒ¡ãƒ¢ã—ã¦ãŠã„ã¦)',
        r'(ã‚¿ã‚¹ã‚¯|TODO|èª²é¡Œ).*?(.*?)(ã§ã™|ã )'
    ]
    
    for pattern in todo_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if isinstance(match, tuple):
                todo_text = ' '.join(match)
            else:
                todo_text = match
            
            if len(todo_text.strip()) > 5:  # çŸ­ã™ãã‚‹ã‚‚ã®ã¯é™¤å¤–
                todos.append({
                    'task': f"[{source}] {todo_text.strip()}",
                    'completed': False,
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M")
                })
    
    return todos

def detect_app_launch_command(text, available_apps):
    """ä¼šè©±ã‹ã‚‰ã‚¢ãƒ—ãƒªèµ·å‹•ã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º"""
    launch_patterns = [
        r'(é›»å“|è¨ˆç®—æ©Ÿ|calculator).*?(å‡ºã—ã¦|èµ·å‹•|é–‹ã„ã¦|è¡¨ç¤º)',
        r'(.*?)(å‡ºã—ã¦|èµ·å‹•|é–‹ã„ã¦|è¡¨ç¤º)',
        r'(.*?)(ã‚’ä½¿ã„ãŸã„|ã‚’ä½¿ã£ã¦|ã‚’èµ·å‹•ã—ã¦)',
    ]
    
    for pattern in launch_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if isinstance(match, tuple):
                keyword, action = match
            else:
                keyword = match
                action = "èµ·å‹•"
            
            keyword = keyword.lower().strip()
            
            # ã‚¢ãƒ—ãƒªåã¨ä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for app in available_apps:
                app_name = app['name'].lower()
                if keyword in app_name or app_name in keyword:
                    return app, f"{keyword}ã‚’{action}ã—ã¾ã™"
            
            # ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚¢ãƒ—ãƒªã‚’æ¨å®š
            if 'é›»å“' in keyword or 'è¨ˆç®—æ©Ÿ' in keyword or 'calculator' in keyword:
                for app in available_apps:
                    if 'calc' in app['name'].lower() or 'é›»å“' in app['name']:
                        return app, "é›»å“ã‚’èµ·å‹•ã—ã¾ã™"
    
    return None, None
