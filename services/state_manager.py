"""
ã‚¹ãƒ†ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ä¼šè©±å±¥æ­´ã€TODOã€é€²åŒ–ãƒ«ãƒ¼ãƒ«ã®JSONä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã‚’ç®¡ç†
"""

import json
import os
import datetime
from pathlib import Path
from core.constants import *
from core.file_map import file_resolver, get_relevant_files, should_load_file
from services.import_validator import import_error_detector, auto_import_fixer

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
_file_cache = {}

def safe_function_call(module_path: str, function_name: str, *args, **kwargs):
    """å®‰å…¨ãªé–¢æ•°å‘¼ã³å‡ºã— with ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸è¶³æ¤œçŸ¥"""
    try:
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‹•çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        module = __import__(module_path, fromlist=[function_name])
        func = getattr(module, function_name)
        return func(*args, **kwargs)
        
    except AttributeError as e:
        # AttributeErrorã‚’æ¤œçŸ¥ã—ã¦è‡ªå‹•ä¿®æ­£ã‚’è©¦ã¿ã‚‹
        error_info = import_error_detector.analyze_error(str(e))
        
        if error_info['error_type'] != 'unknown':
            print(f"ğŸ” ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸è¶³ã‚’æ¤œçŸ¥: {error_info}")
            
            # å‘¼ã³å‡ºã—å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã¦è‡ªå‹•ä¿®æ­£
            caller_file = _get_caller_file()
            if caller_file:
                print("ğŸ”§ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ä¿®æ­£ä¸­...")
                fix_result = auto_import_fixer.fix_import_error(error_info, caller_file)
                
                if fix_result['success']:
                    print(f"âœ… {fix_result['message']}")
                    
                    # ä¿®æ­£ã‚’æ¤œè¨¼
                    validation = auto_import_fixer.validate_import_fix(caller_file)
                    if validation['success']:
                        print("âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¿®æ­£ã‚’æ¤œè¨¼ã—ã¾ã—ãŸ")
                        # å†åº¦é–¢æ•°å‘¼ã³å‡ºã—ã‚’è©¦è¡Œ
                        module = __import__(module_path, fromlist=[function_name])
                        func = getattr(module, function_name)
                        return func(*args, **kwargs)
                    else:
                        print(f"âŒ æ¤œè¨¼å¤±æ•—: {validation['error']}")
                else:
                    print(f"âŒ è‡ªå‹•ä¿®æ­£å¤±æ•—: {fix_result['error']}")
        
        raise e
        
    except ImportError as e:
        # ImportErrorã‚’æ¤œçŸ¥ã—ã¦è‡ªå‹•ä¿®æ­£ã‚’è©¦ã¿ã‚‹
        error_info = import_error_detector.analyze_error(str(e))
        
        if error_info['error_type'] != 'unknown':
            print(f"ğŸ” ImportErrorã‚’æ¤œçŸ¥: {error_info}")
            
            caller_file = _get_caller_file()
            if caller_file:
                print("ğŸ”§ ImportErrorã‚’è‡ªå‹•ä¿®æ­£ä¸­...")
                fix_result = auto_import_fixer.fix_import_error(error_info, caller_file)
                
                if fix_result['success']:
                    print(f"âœ… {fix_result['message']}")
                    # å†åº¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                    module = __import__(module_path, fromlist=[function_name])
                    func = getattr(module, function_name)
                    return func(*args, **kwargs)
        
        raise e
    
    except Exception as e:
        print(f"âŒ é–¢æ•°å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise e

def _get_caller_file():
    """å‘¼ã³å‡ºã—å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    import inspect
    frame = inspect.currentframe()
    try:
        # å‘¼ã³å‡ºã—å…ƒã‚’é¡ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        for _ in range(3):  # 3éšå±¤é¡ã‚‹
            frame = frame.f_back
            if frame and frame.f_code.co_filename:
                return frame.f_code.co_filename
    finally:
        del frame
    return None

def load_file_with_cache(file_path: str, user_request: str = None) -> str:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ããƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ã„ã¦èª­ã¿è¾¼ã¿å¿…è¦æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    if user_request and not should_load_file(file_path, user_request):
        return ""
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if file_path in _file_cache:
        cache_time, content = _file_cache[file_path]
        file_mtime = Path(file_path).stat().st_mtime if Path(file_path).exists() else 0
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã‘ã‚Œã°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™
        if cache_time >= file_mtime:
            return content
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    try:
        if Path(file_path).exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            file_mtime = Path(file_path).stat().st_mtime
            _file_cache[file_path] = (file_mtime, content)
            
            return content
        else:
            return ""
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        return ""

def clear_file_cache():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
    global _file_cache
    _file_cache.clear()

def resolve_target_file(user_request: str) -> Optional[str]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‹ã‚‰ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š"""
    try:
        from ..core.file_map import resolve_target_file as file_map_resolver
        return file_map_resolver(user_request)
    except Exception as e:
        print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æ±ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_optimized_file_list(user_request: str) -> list:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ã„ã¦æœ€é©åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    all_files = list(file_resolver.file_map.keys())
    relevant_files = get_relevant_files(user_request)
    
    # é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆã—ã€æ®‹ã‚Šã‚’å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
    prioritized_files = []
    
    # é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ˆé ­ã«è¿½åŠ 
    for file_path in relevant_files:
        if file_path in all_files:
            prioritized_files.append(file_path)
    
    # æ®‹ã‚Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆåº¦é †ã«è¿½åŠ 
    remaining_files = [f for f in all_files if f not in prioritized_files]
    remaining_files = file_resolver.optimize_loading_order(remaining_files)
    prioritized_files.extend(remaining_files)
    
    return prioritized_files

def save_workspace_state():
    """ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹ã‚’ä¿å­˜"""
    try:
        workspace_data = {
            'todo_list': st.session_state.get(SESSION_KEYS['todo_list'], []),
            'quick_memos': st.session_state.get(SESSION_KEYS['quick_memos'], []),
            'last_saved': datetime.datetime.now().isoformat()
        }
        
        # dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        DATA_DIR.mkdir(exist_ok=True)
        
        # ä¿å­˜
        with open(WORKSPACE_STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(workspace_data, f, ensure_ascii=False, indent=2)
        
        print("âœ… ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def load_workspace_state():
    """ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if WORKSPACE_STATE_FILE.exists():
            with open(WORKSPACE_STATE_FILE, "r", encoding="utf-8") as f:
                workspace_data = json.load(f)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«å¾©å…ƒ
            st.session_state[SESSION_KEYS['todo_list']] = workspace_data.get('todo_list', [])
            st.session_state[SESSION_KEYS['quick_memos']] = workspace_data.get('quick_memos', [])
            
            print("âœ… ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return True
        
        return False
        
    except Exception as e:
        print(f"âŒ ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def save_conversation_history(conversation_history):
    """ä¼šè©±å±¥æ­´ã‚’ä¿å­˜"""
    try:
        DATA_DIR.mkdir(exist_ok=True)
        
        history_file = DATA_DIR / "conversation_history.json"
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¼šè©±å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def load_conversation_history():
    """ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
    try:
        history_file = DATA_DIR / "conversation_history.json"
        
        if history_file.exists():
            with open(history_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        return []
        
    except Exception as e:
        print(f"âŒ ä¼šè©±å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def save_evolution_rules(evolution_rules):
    """é€²åŒ–ãƒ«ãƒ¼ãƒ«ã‚’ä¿å­˜"""
    try:
        custom_data = {
            "evolution_rules": evolution_rules,
            "last_updated": datetime.datetime.now().isoformat()
        }
        
        with open(PERSONALITIES_CUSTOM_FILE, "w", encoding="utf-8") as f:
            json.dump(custom_data, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"âŒ é€²åŒ–ãƒ«ãƒ¼ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def load_evolution_rules():
    """é€²åŒ–ãƒ«ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if PERSONALITIES_CUSTOM_FILE.exists():
            with open(PERSONALITIES_CUSTOM_FILE, "r", encoding="utf-8") as f:
                custom_data = json.load(f)
                return custom_data.get("evolution_rules", [])
        
        return []
        
    except Exception as e:
        print(f"âŒ é€²åŒ–ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def write_agent_diary(entry_type, content):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ—¥è¨˜ã‚’æ›¸ãè¾¼ã‚€"""
    try:
        diary_file = AGENT_DIARY_FILE
        
        # æ—¢å­˜ã®æ—¥è¨˜ã‚’èª­ã¿è¾¼ã¿
        if diary_file.exists():
            with open(diary_file, "r", encoding="utf-8") as f:
                diary_data = json.load(f)
        else:
            diary_data = {"entries": []}
        
        # æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ä½œæˆ
        new_entry = {
            "timestamp": datetime.datetime.now().isoformat(),
            "date": datetime.datetime.now().strftime("%Y-%m-%d"),
            "type": entry_type,
            "content": content
        }
        
        diary_data["entries"].append(new_entry)
        
        # æœ€æ–°30ä»¶ã®ã¿ä¿æŒ
        if len(diary_data["entries"]) > 30:
            diary_data["entries"] = diary_data["entries"][-30:]
        
        # ä¿å­˜
        diary_file.parent.mkdir(exist_ok=True)
        with open(diary_file, "w", encoding="utf-8") as f:
            json.dump(diary_data, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"æ—¥è¨˜æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def read_agent_diary():
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ—¥è¨˜ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        if AGENT_DIARY_FILE.exists():
            with open(AGENT_DIARY_FILE, "r", encoding="utf-8") as f:
                diary_data = json.load(f)
            return diary_data.get("entries", [])
        
        return []
        
    except Exception as e:
        print(f"æ—¥è¨˜èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def cleanup_temp_files():
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ•´ç†"""
    try:
        cleanup_log = []
        
        # generated_appsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†
        if GENERATED_APPS_DIR.exists():
            backup_files = list(GENERATED_APPS_DIR.glob("*_backup.py"))
            for backup_file in backup_files:
                # 7æ—¥ä»¥ä¸Šå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯å‰Šé™¤
                file_age = datetime.datetime.now() - datetime.datetime.fromtimestamp(backup_file.stat().st_mtime)
                if file_age.days > 7:
                    backup_file.unlink()
                    cleanup_log.append(f"å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤: {backup_file.name}")
        
        # dataãƒ•ã‚©ãƒ«ãƒ€å†…ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†
        if DATA_DIR.exists():
            temp_files = list(DATA_DIR.glob("temp_*"))
            for temp_file in temp_files:
                # 1æ—¥ä»¥ä¸Šå‰ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤
                file_age = datetime.datetime.now() - datetime.datetime.fromtimestamp(temp_file.stat().st_mtime)
                if file_age.days > 1:
                    temp_file.unlink()
                    cleanup_log.append(f"å¤ã„ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {temp_file.name}")
        
        if cleanup_log:
            print(f"ğŸ§¹ ã‚»ãƒ«ãƒ•ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†: {len(cleanup_log)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†")
        
        return cleanup_log
        
    except Exception as e:
        print(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def cleanup_conversation_history():
    """ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæœ€æ–°100ä»¶ã‚’ä¿æŒï¼‰"""
    try:
        if SESSION_KEYS['conversation_history'] in st.session_state:
            history = st.session_state[SESSION_KEYS['conversation_history']]
            if len(history) > 100:
                st.session_state[SESSION_KEYS['conversation_history']] = history[-100:]
                print("âœ… ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¼šè©±å±¥æ­´ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def archive_old_conversations():
    """å¤ã„ä¼šè©±ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
    try:
        DATA_DIR.mkdir(exist_ok=True)
        archive_dir = DATA_DIR / "conversation_archive"
        archive_dir.mkdir(exist_ok=True)
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤šã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
        archive_files = list(archive_dir.glob("conversation_archive_*.json"))
        if len(archive_files) > 10:
            archive_files.sort(key=lambda x: x.stat().st_mtime)
            for old_file in archive_files[:-10]:
                old_file.unlink()
                print(f"ğŸ—‘ï¸ å¤ã„ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å‰Šé™¤: {old_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def get_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        status = {
            "workspace_state_exists": WORKSPACE_STATE_FILE.exists(),
            "conversation_history_exists": (DATA_DIR / "conversation_history.json").exists(),
            "agent_diary_exists": AGENT_DIARY_FILE.exists(),
            "generated_apps_count": len(list(GENERATED_APPS_DIR.glob("*.py"))) if GENERATED_APPS_DIR.exists() else 0,
            "data_dir_exists": DATA_DIR.exists(),
            "custom_personalities_exists": PERSONALITIES_CUSTOM_FILE.exists()
        }
        
        return status
        
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def export_all_data():
    """ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        export_data = {
            "export_timestamp": datetime.datetime.now().isoformat(),
            "workspace_state": {},
            "conversation_history": [],
            "agent_diary": [],
            "evolution_rules": []
        }
        
        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹
        if WORKSPACE_STATE_FILE.exists():
            with open(WORKSPACE_STATE_FILE, "r", encoding="utf-8") as f:
                export_data["workspace_state"] = json.load(f)
        
        # ä¼šè©±å±¥æ­´
        history_file = DATA_DIR / "conversation_history.json"
        if history_file.exists():
            with open(history_file, "r", encoding="utf-8") as f:
                export_data["conversation_history"] = json.load(f)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ—¥è¨˜
        if AGENT_DIARY_FILE.exists():
            with open(AGENT_DIARY_FILE, "r", encoding="utf-8") as f:
                diary_data = json.load(f)
                export_data["agent_diary"] = diary_data.get("entries", [])
        
        # é€²åŒ–ãƒ«ãƒ¼ãƒ«
        export_data["evolution_rules"] = load_evolution_rules()
        
        return export_data
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def import_all_data(import_data):
    """ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        success_count = 0
        
        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çŠ¶æ…‹
        if import_data.get("workspace_state"):
            with open(WORKSPACE_STATE_FILE, "w", encoding="utf-8") as f:
                json.dump(import_data["workspace_state"], f, ensure_ascii=False, indent=2)
            success_count += 1
        
        # ä¼šè©±å±¥æ­´
        if import_data.get("conversation_history"):
            history_file = DATA_DIR / "conversation_history.json"
            with open(history_file, "w", encoding="utf-8") as f:
                json.dump(import_data["conversation_history"], f, ensure_ascii=False, indent=2)
            success_count += 1
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ—¥è¨˜
        if import_data.get("agent_diary"):
            diary_data = {"entries": import_data["agent_diary"]}
            with open(AGENT_DIARY_FILE, "w", encoding="utf-8") as f:
                json.dump(diary_data, f, ensure_ascii=False, indent=2)
            success_count += 1
        
        # é€²åŒ–ãƒ«ãƒ¼ãƒ«
        if import_data.get("evolution_rules"):
            save_evolution_rules(import_data["evolution_rules"])
            success_count += 1
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {success_count}/4 é …ç›®")
        return success_count
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return 0
