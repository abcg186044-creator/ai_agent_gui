#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éåŒæœŸãƒãƒ«ãƒAI vs å¾“æ¥å‹ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
"""

import time
import asyncio
from typing import Dict, List, Any
from async_multi_ai import AsyncMultiAICodingSystem
from unlimited_agent_main import UnlimitedFriendAgent
from parallel_file_processor import ParallelFileProcessor, FileTask

class PerformanceComparison:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.async_system = AsyncMultiAICodingSystem()
        self.traditional_agent = UnlimitedFriendAgent()
        self.file_processor = ParallelFileProcessor(max_workers=4)
    
    def compare_single_task_performance(self, test_cases: List[Dict[str, str]]) -> Dict[str, Any]:
        """å˜ä¸€ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ"""
        print("ğŸš€ å˜ä¸€ã‚¿ã‚¹ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ")
        print("=" * 60)
        
        results = {
            "traditional": [],
            "async": [],
            "comparison": {}
        }
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {test_case['name']}")
            print("-" * 40)
            
            # å¾“æ¥å‹ãƒ†ã‚¹ãƒˆ
            print("ğŸŒ å¾“æ¥å‹AIå®Ÿè¡Œä¸­...")
            start_time = time.time()
            traditional_result = self.traditional_agent.generate_response_with_fallback(
                test_case['prompt'], 
                test_case['task']
            )
            traditional_time = time.time() - start_time
            
            # éåŒæœŸãƒãƒ«ãƒAIãƒ†ã‚¹ãƒˆ
            print("ğŸš€ éåŒæœŸãƒãƒ«ãƒAIå®Ÿè¡Œä¸­...")
            start_time = time.time()
            async_result = self.async_system.generate_response_sync(
                test_case['prompt'], 
                test_case['task']
            )
            async_time = time.time() - start_time
            
            # çµæœè¨˜éŒ²
            traditional_data = {
                "name": test_case['name'],
                "time": traditional_time,
                "success": traditional_result['success'],
                "approach": traditional_result.get('approach', 'N/A'),
                "response_length": len(traditional_result.get('response', ''))
            }
            
            async_data = {
                "name": test_case['name'],
                "time": async_time,
                "success": async_result['success'],
                "ai_type": async_result.get('ai_type', 'N/A'),
                "response_length": len(async_result.get('response', ''))
            }
            
            results["traditional"].append(traditional_data)
            results["async"].append(async_data)
            
            # æ¯”è¼ƒ
            improvement = ((traditional_time - async_time) / traditional_time * 100) if traditional_time > 0 else 0
            
            print(f"ğŸ“Š çµæœ:")
            print(f"   å¾“æ¥å‹: {traditional_time:.2f}ç§’ ({traditional_data['approach']})")
            print(f"   éåŒæœŸ: {async_time:.2f}ç§’ ({async_data['ai_type']})")
            print(f"   æ”¹å–„ç‡: {improvement:.1f}%")
            
            if async_time < traditional_time:
                print(f"   âœ… éåŒæœŸãŒ {traditional_time - async_time:.2f}ç§’ é€Ÿã„")
            else:
                print(f"   âŒ å¾“æ¥å‹ãŒ {async_time - traditional_time:.2f}ç§’ é€Ÿã„")
        
        # ç·åˆæ¯”è¼ƒ
        total_traditional = sum(r['time'] for r in results["traditional"])
        total_async = sum(r['time'] for r in results["async"])
        overall_improvement = ((total_traditional - total_async) / total_traditional * 100) if total_traditional > 0 else 0
        
        results["comparison"] = {
            "total_traditional": total_traditional,
            "total_async": total_async,
            "overall_improvement": overall_improvement,
            "traditional_success_rate": sum(1 for r in results["traditional"] if r['success']) / len(results["traditional"]),
            "async_success_rate": sum(1 for r in results["async"] if r['success']) / len(results["async"])
        }
        
        print(f"\nğŸ“Š ç·åˆæ¯”è¼ƒ:")
        print(f"ğŸŒ å¾“æ¥å‹ç·æ™‚é–“: {total_traditional:.2f}ç§’")
        print(f"ğŸš€ éåŒæœŸç·æ™‚é–“: {total_async:.2f}ç§’")
        print(f"ğŸ“ˆ ç·åˆæ”¹å–„ç‡: {overall_improvement:.1f}%")
        print(f"âœ… å¾“æ¥å‹æˆåŠŸç‡: {results['comparison']['traditional_success_rate']:.1%}")
        print(f"âœ… éåŒæœŸæˆåŠŸç‡: {results['comparison']['async_success_rate']:.1%}")
        
        return results
    
    def compare_file_processing_performance(self, project_tasks: List[FileTask]) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ"""
        print(f"\nğŸš€ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ")
        print("=" * 60)
        
        # é€æ¬¡å‡¦ç†ï¼ˆå¾“æ¥å‹ï¼‰
        print("ğŸŒ é€æ¬¡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­...")
        start_time = time.time()
        
        sequential_results = {}
        for task in project_tasks:
            task_start = time.time()
            result = self.traditional_agent.generate_response_with_fallback(
                task.prompt, 
                task.task_type
            )
            task_time = time.time() - task_start
            
            sequential_results[task.file_path] = {
                "success": result['success'],
                "time": task_time,
                "response": result.get('response', '')
            }
        
        sequential_total = time.time() - start_time
        
        # ä¸¦åˆ—å‡¦ç†ï¼ˆéåŒæœŸï¼‰
        print("ğŸš€ ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­...")
        start_time = time.time()
        
        parallel_results = self.file_processor.process_files_sync(project_tasks)
        parallel_total = time.time() - start_time
        
        # æ¯”è¼ƒ
        sequential_success = sum(1 for r in sequential_results.values() if r['success'])
        parallel_success = sum(1 for r in parallel_results.values() if r['success'])
        
        improvement = ((sequential_total - parallel_total) / sequential_total * 100) if sequential_total > 0 else 0
        
        print(f"\nğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¯”è¼ƒ:")
        print(f"ğŸŒ é€æ¬¡å‡¦ç†: {sequential_total:.2f}ç§’ ({sequential_success}/{len(project_tasks)} æˆåŠŸ)")
        print(f"ğŸš€ ä¸¦åˆ—å‡¦ç†: {parallel_total:.2f}ç§’ ({parallel_success}/{len(project_tasks)} æˆåŠŸ)")
        print(f"ğŸ“ˆ æ”¹å–„ç‡: {improvement:.1f}%")
        
        if parallel_total < sequential_total:
            print(f"âœ… ä¸¦åˆ—å‡¦ç†ãŒ {sequential_total - parallel_total:.2f}ç§’ é€Ÿã„")
        else:
            print(f"âŒ é€æ¬¡å‡¦ç†ãŒ {parallel_total - sequential_total:.2f}ç§’ é€Ÿã„")
        
        return {
            "sequential": {
                "total_time": sequential_total,
                "success_count": sequential_success,
                "results": sequential_results
            },
            "parallel": {
                "total_time": parallel_total,
                "success_count": parallel_success,
                "results": {k: {"success": v.success, "time": v.elapsed_time} for k, v in parallel_results.items()}
            },
            "improvement": improvement
        }
    
    def generate_performance_report(self, single_results: Dict[str, Any], file_results: Dict[str, Any]) -> str:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = f"""
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ

## å˜ä¸€ã‚¿ã‚¹ã‚¯æ¯”è¼ƒ
- å¾“æ¥å‹ç·æ™‚é–“: {single_results['comparison']['total_traditional']:.2f}ç§’
- éåŒæœŸç·æ™‚é–“: {single_results['comparison']['total_async']:.2f}ç§’
- ç·åˆæ”¹å–„ç‡: {single_results['comparison']['overall_improvement']:.1f}%
- å¾“æ¥å‹æˆåŠŸç‡: {single_results['comparison']['traditional_success_rate']:.1%}
- éåŒæœŸæˆåŠŸç‡: {single_results['comparison']['async_success_rate']:.1%}

## ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¯”è¼ƒ
- é€æ¬¡å‡¦ç†æ™‚é–“: {file_results['sequential']['total_time']:.2f}ç§’
- ä¸¦åˆ—å‡¦ç†æ™‚é–“: {file_results['parallel']['total_time']:.2f}ç§’
- æ”¹å–„ç‡: {file_results['improvement']:.1f}%

## è©³ç´°çµæœ

### å˜ä¸€ã‚¿ã‚¹ã‚¯è©³ç´°
"""
        
        for i, (trad, async_res) in enumerate(zip(single_results['traditional'], single_results['async'])):
            improvement = ((trad['time'] - async_res['time']) / trad['time'] * 100) if trad['time'] > 0 else 0
            report += f"""
#### {trad['name']}
- å¾“æ¥å‹: {trad['time']:.2f}ç§’ ({trad['approach']})
- éåŒæœŸ: {async_res['time']:.2f}ç§’ ({async_res['ai_type']})
- æ”¹å–„ç‡: {improvement:.1f}%
"""
        
        report += f"""
### ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†è©³ç´°
"""
        
        for file_path in file_results['sequential']['results'].keys():
            seq_time = file_results['sequential']['results'][file_path]['time']
            par_time = file_results['parallel']['results'][file_path]['time']
            improvement = ((seq_time - par_time) / seq_time * 100) if seq_time > 0 else 0
            
            report += f"""
#### {file_path}
- é€æ¬¡: {seq_time:.2f}ç§’
- ä¸¦åˆ—: {par_time:.2f}ç§’
- æ”¹å–„ç‡: {improvement:.1f}%
"""
        
        report += f"""
## çµè«–
éåŒæœŸãƒãƒ«ãƒAIã‚·ã‚¹ãƒ†ãƒ ã¯å¾“æ¥å‹ã¨æ¯”è¼ƒã—ã¦:
- å˜ä¸€ã‚¿ã‚¹ã‚¯ã§{single_results['comparison']['overall_improvement']:.1f}%ã®æ”¹å–„
- ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã§{file_results['improvement']:.1f}%ã®æ”¹å–„
- æˆåŠŸç‡ã¯åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¶­æŒ

## æ¨å¥¨äº‹é …
1. å˜ä¸€ã‚¿ã‚¹ã‚¯ã«ã¯éåŒæœŸãƒãƒ«ãƒAIã‚’ä½¿ç”¨
2. è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã«ã¯ä¸¦åˆ—å‡¦ç†ã‚’æ´»ç”¨
3. å„ªå…ˆåº¦ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã‹ã‚‰å‡¦ç†ã‚’é–‹å§‹
4. ä¾å­˜é–¢ä¿‚ã‚’é©åˆ‡ã«ç®¡ç†
"""
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    comparison = PerformanceComparison()
    
    # å˜ä¸€ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ
    single_test_cases = [
        {
            "name": "é›»å“ã‚¢ãƒ—ãƒªé–‹ç™º",
            "prompt": "Pythonã§GUIã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦æ“ä½œã§ãã‚‹é›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„",
            "task": "Python GUIé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º"
        },
        {
            "name": "Webã‚¢ãƒ—ãƒªé–‹ç™º",
            "prompt": "HTMLã§é›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„",
            "task": "Webé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º"
        },
        {
            "name": "Androidã‚¢ãƒ—ãƒªé–‹ç™º",
            "prompt": "Androidã§é›»å“ã‚¢ãƒ—ãƒªã‚’é–‹ç™ºã—ã¦ãã ã•ã„",
            "task": "Androidé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º"
        }
    ]
    
    single_results = comparison.compare_single_task_performance(single_test_cases)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ†ã‚¹ãƒˆ
    file_tasks = [
        FileTask("src/calculator.py", "Python GUIé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º", "Pythonã§GUIé›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆ", priority=10),
        FileTask("web/calculator.html", "Webé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º", "HTMLã§é›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆ", priority=8),
        FileTask("android/MainActivity.kt", "Androidé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º", "Androidã§é›»å“ã‚¢ãƒ—ãƒªã‚’é–‹ç™º", priority=6),
        FileTask("docs/README.md", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ", "READMEãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ", priority=4),
        FileTask("tests/test_calculator.py", "ãƒ†ã‚¹ãƒˆä½œæˆ", "å˜ä½“ãƒ†ã‚¹ãƒˆã‚’ä½œæˆ", priority=3)
    ]
    
    file_results = comparison.compare_file_processing_performance(file_tasks)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = comparison.generate_performance_report(single_results, file_results)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open("performance_comparison_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: performance_comparison_report.md")
    print(f"\nğŸ‰ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒå®Œäº†ï¼")
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š æœ€çµ‚ã‚µãƒãƒªãƒ¼:")
    print(f"ğŸš€ éåŒæœŸãƒãƒ«ãƒAIã¯å¾“æ¥å‹ã‚ˆã‚Šå¤§å¹…ã«é«˜é€Ÿ")
    print(f"âš¡ æœ€å¤§æ”¹å–„ç‡: {max(single_results['comparison']['overall_improvement'], file_results['improvement']):.1f}%")
    print(f"ğŸ“ˆ ä¸¦åˆ—å‡¦ç†ã§è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ™‚ã«å‡¦ç†å¯èƒ½")
    print(f"âœ… æˆåŠŸç‡ã‚’ç¶­æŒã—ãªãŒã‚‰é€Ÿåº¦ã‚’å‘ä¸Š")

if __name__ == "__main__":
    main()
