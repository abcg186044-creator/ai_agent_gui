#!/usr/bin/env python3
"""
Autonomous AI Agent - å®Œå…¨è‡ªå¾‹ãƒ»è¶…è¨˜æ†¶å‹AIã‚·ã‚¹ãƒ†ãƒ 
llama3.2 + ChromaDB + FAISS + Transformers + è‡ªå·±ç®¡ç†
"""

import streamlit as st
import sys
import os
import json
import tempfile
import time
from datetime import datetime, timedelta
from pathlib import Path
import threading
import queue
import base64
import hashlib
import re

# åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import ollama
    import faster_whisper
    import pyttsx3
    import pyautogui
    import numpy as np
    import pandas as pd
    from openpyxl import load_workbook
    import pymupdf
    from PIL import Image
    import qrcode
    from duckduckgo_search import DDGS
    import chromadb
    from sentence_transformers import SentenceTransformer
    import faiss
    import psutil
    import schedule
except ImportError as e:
    st.error(f"âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    st.stop()

# è¨­å®š
class Config:
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    MAIN_MODEL = "llama3.2"
    VISION_MODEL = "llama3.2-vision"
    EMBEDDING_MODEL = "all-MiniLM-L6-v2"
    
    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹è¨­å®š
    KNOWLEDGE_DB_PATH = "./autonomous_knowledge"
    LONG_TERM_MEMORY_PATH = "./long_term_memory.json"
    SIMILARITY_THRESHOLD = 0.75
    MAX_KNOWLEDGE_RESULTS = 10
    
    # è‡ªå·±ç®¡ç†è¨­å®š
    WORK_HOURS_START = 9
    WORK_HOURS_END = 22
    BREAK_DURATION = 15  # åˆ†
    MAX_WORKING_TIME = 4  # æ™‚é–“
    
    # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–è¨­å®š
    CPU_THRESHOLD = 70.0
    MEMORY_THRESHOLD = 75.0
    DISK_THRESHOLD = 20.0  # GB

class PersistentKnowledgeBase:
    """æ°¸ç¶šåŒ–çŸ¥è­˜ãƒ™ãƒ¼ã‚¹"""
    
    def __init__(self):
        self.db_path = Config.KNOWLEDGE_DB_PATH
        self.embedding_model = None
        self.vector_index = None
        self.knowledge_items = []
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.db_path, exist_ok=True)
        
    def initialize(self):
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        try:
            # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            self.embedding_model = SentenceTransformer(Config.EMBEDDING_MODEL)
            
            # æ—¢å­˜çŸ¥è­˜ã®èª­ã¿è¾¼ã¿
            self._load_existing_knowledge()
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self._build_vector_index()
            
            return True
        except Exception as e:
            st.error(f"âŒ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _load_existing_knowledge(self):
        """æ—¢å­˜çŸ¥è­˜èª­ã¿è¾¼ã¿"""
        try:
            kb_file = os.path.join(self.db_path, "knowledge.json")
            if os.path.exists(kb_file):
                with open(kb_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.knowledge_items = data.get("knowledge_items", [])
        except Exception:
            self.knowledge_items = []
    
    def _save_knowledge(self):
        """çŸ¥è­˜ä¿å­˜"""
        try:
            kb_file = os.path.join(self.db_path, "knowledge.json")
            data = {
                "knowledge_items": self.knowledge_items,
                "last_updated": datetime.now().isoformat(),
                "total_items": len(self.knowledge_items)
            }
            with open(kb_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"âŒ çŸ¥è­˜ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _build_vector_index(self):
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰"""
        try:
            if not self.knowledge_items:
                return
            
            # çŸ¥è­˜é …ç›®ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
            texts = []
            for item in self.knowledge_items:
                texts.append(item["content"])
            
            if not texts:
                return
            
            # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            embeddings = self.embedding_model.encode(texts)
            
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            dimension = embeddings.shape[1]
            self.vector_index = faiss.IndexFlatL2(dimension)
            self.vector_index.add(embeddings)
            
        except Exception as e:
            st.error(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def add_knowledge(self, title, content, category="general", source="conversation"):
        """çŸ¥è­˜ã‚’è¿½åŠ """
        knowledge_item = {
            "id": hashlib.md5(f"{title}{content}{datetime.now().isoformat()}".encode()).hexdigest(),
            "timestamp": datetime.now().isoformat(),
            "title": title,
            "content": content,
            "category": category,
            "source": source,
            "access_count": 0,
            "last_accessed": None
        }
        
        self.knowledge_items.append(knowledge_item)
        self._save_knowledge()
        self._build_vector_index()
    
    def search_knowledge(self, query, k=Config.MAX_KNOWLEDGE_RESULTS):
        """çŸ¥è­˜ã‚’æ¤œç´¢"""
        try:
            if not self.vector_index or not query:
                return []
            
            # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            query_embedding = self.embedding_model.encode([query])
            
            # é¡ä¼¼æ¤œç´¢
            distances, indices = self.vector_index.search(query_embedding, k)
            
            # é¡ä¼¼åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            similar_items = []
            for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
                if dist < (1 - Config.SIMILARITY_THRESHOLD):
                    if idx < len(self.knowledge_items):
                        item = self.knowledge_items[idx].copy()
                        item["similarity"] = 1 - dist
                        item["access_count"] += 1
                        item["last_accessed"] = datetime.now().isoformat()
                        similar_items.append(item)
            
            # ã‚¢ã‚¯ã‚»ã‚¹å›æ•°ã‚’æ›´æ–°
            self._save_knowledge()
            
            return similar_items
            
        except Exception as e:
            st.error(f"âŒ çŸ¥è­˜æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_knowledge_context(self, query):
        """ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹çŸ¥è­˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        similar_items = self.search_knowledge(query)
        
        if not similar_items:
            return ""
        
        # é¡ä¼¼çŸ¥è­˜ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context_parts = []
        for item in similar_items[:3]:  # ä¸Šä½3ä»¶ã‚’ä½¿ç”¨
            context_parts.append(f"é–¢é€£çŸ¥è­˜: {item['title']}")
            context_parts.append(f"å†…å®¹: {item['content']}")
            context_parts.append(f"é¡ä¼¼åº¦: {item['similarity']:.2f}")
        
        return "\n".join(context_parts)

class LongTermMemory:
    """é•·æœŸè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.memory_path = Config.LONG_TERM_MEMORY_PATH
        self.memory_data = {}
        
    def initialize(self):
        """é•·æœŸè¨˜æ†¶åˆæœŸåŒ–"""
        try:
            if os.path.exists(self.memory_path):
                with open(self.memory_path, 'r', encoding='utf-8') as f:
                    self.memory_data = json.load(f)
            else:
                self.memory_data = self._create_default_memory()
            return True
        except Exception as e:
            st.error(f"âŒ é•·æœŸè¨˜æ†¶åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _create_default_memory(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨˜æ†¶ä½œæˆ"""
        return {
            "user_profile": {
                "name": None,
                "preferences": {},
                "interaction_history": [],
                "communication_style": "friendly",
                "learned_patterns": {}
            },
            "conversation_patterns": {
                "greetings": ["ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã‚„ã‚"],
                "gratitude": ["ã‚ã‚ŠãŒã¨ã†", "å¬‰ã—ã„", "åŠ©ã‹ã‚‹"],
                "apology": ["ã™ã¿ã¾ã›ã‚“", "ã”ã‚ã‚“", "å¤±ç¤¼"],
                "farewells": ["ã•ã‚ˆã†ãªã‚‰", "ãŠç–²ã‚Œæ§˜", "ã¾ãŸã­"]
            },
            "domain_knowledge": {
                "programming": [],
                "daily_life": [],
                "work": [],
                "hobbies": []
            },
            "emotional_state": {
                "current_mood": "neutral",
                "mood_history": [],
                "stress_level": 0.0
            },
            "self_regulation": {
                "work_hours": {"start": Config.WORK_HOURS_START, "end": Config.WORK_HOURS_END},
                "break_schedule": [],
                "productivity_metrics": {
                    "daily_interactions": 0,
                    "focus_time": 0,
                    "task_completion_rate": 0.0
                }
            },
            "last_updated": datetime.now().isoformat()
        }
    
    def save_memory(self):
        """è¨˜æ†¶ã‚’ä¿å­˜"""
        try:
            self.memory_data["last_updated"] = datetime.now().isoformat()
            with open(self.memory_path, 'w', encoding='utf-8') as f:
                json.dump(self.memory_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"âŒ è¨˜æ†¶ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def update_interaction_pattern(self, user_input, ai_response):
        """å¯¾è©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°"""
        try:
            # æŒ¨æ‹¶ã‚’åˆ†æ
            input_lower = user_input.lower()
            
            # æŒ¨æ‹¶ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            if any(greeting in input_lower for greeting in self.memory_data["conversation_patterns"]["greetings"]):
                pattern_type = "greeting"
            elif any(gratitude in input_lower for gratitude in self.memory_data["conversation_patterns"]["gratitude"]):
                pattern_type = "gratitude"
            elif any(apology in input_lower for apology in self.memory_data["conversation_patterns"]["apology"]):
                pattern_type = "apology"
            elif any(farewell in input_lower for farewell in self.memory_data["conversation_patterns"]["farewells"]):
                pattern_type = "farewell"
            else:
                pattern_type = "general"
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
            if pattern_type not in self.memory_data["user_profile"]["learned_patterns"]:
                self.memory_data["user_profile"]["learned_patterns"][pattern_type] = {
                    "first_seen": datetime.now().isoformat(),
                    "usage_count": 1,
                    "examples": [user_input]
                }
            else:
                self.memory_data["user_profile"]["learned_patterns"][pattern_type]["usage_count"] += 1
                self.memory_data["user_profile"]["learned_patterns"][pattern_type]["examples"].append(user_input)
            
            # å¯¾è©±å±¥æ­´ã«è¿½åŠ 
            self.memory_data["user_profile"]["interaction_history"].append({
                "timestamp": datetime.now().isoformat(),
                "user_input": user_input,
                "ai_response": ai_response,
                "pattern_type": pattern_type
            })
            
            # æœ€æ–°ã®å¯¾è©±ã‚’ä¿æŒï¼ˆç›´è¿‘10ä»¶ï¼‰
            if len(self.memory_data["user_profile"]["interaction_history"]) > 10:
                self.memory_data["user_profile"]["interaction_history"] = self.memory_data["user_profile"]["interaction_history"][-10:]
            
            self.save_memory()
            
        except Exception as e:
            st.error(f"âŒ ãƒ‘ã‚¿ãƒ¼ãƒ³æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def get_personalized_response_prefix(self, user_input):
        """ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸå¿œç­”ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
        try:
            input_lower = user_input.lower()
            
            # æŒ¨æ‹¶ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            if any(greeting in input_lower for greeting in self.memory_data["conversation_patterns"]["greetings"]):
                return f"ä»¥å‰ã«ã‚‚ã€Œ{user_input}ã€ã¨æŒ¨æ‹¶ã—ã¾ã—ãŸã­ã€‚ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ"
            
            elif any(gratitude in input_lower for gratitude in self.memory_data["conversation_patterns"]["gratitude"]):
                return "å¬‰ã—ã„ã§ã™ï¼ãŠå½¹ã«ç«‹ã¦ã¦ã‚ˆã‹ã£ãŸã§ã™ã€‚"
            
            elif any(apology in input_lower for apology in self.memory_data["conversation_patterns"]["apology"]):
                return "ã„ãˆã„ãˆã„ã€æ°—ã«ã—ãªã„ã§ãã ã•ã„ã€‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
            
            elif any(farewell in input_lower for farewell in self.memory_data["conversation_patterns"]["farewells"]):
                return "ã¾ãŸãŠä¼šã„ã§ãã‚‹ã®ã‚’æ¥½ã—ã¿ã«ã—ã¦ãŠã‚Šã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼"
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨
            domain_context = self._get_domain_context(user_input)
            if domain_context:
                return f"ä»¥å‰{domain_context}ã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã—ãŸã­ã€‚ãã®çµŒé¨“ã‚’æ´»ã‹ã—ã¦å›ç­”ã—ã¾ã™ã€‚"
            
            return ""
            
        except Exception as e:
            return ""
    
    def _get_domain_context(self, user_input):
        """ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’å–å¾—"""
        try:
            input_lower = user_input.lower()
            
            for domain, keywords in self.memory_data["domain_knowledge"].items():
                if any(keyword in input_lower for keyword in keywords):
                    return f"ã®{domain}ã§"
            
            return ""
            
        except Exception:
            return ""

class SelfRegulationSystem:
    """è‡ªå·±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.memory = LongTermMemory()
        self.current_work_start = None
        self.total_work_time = 0
        self.break_count = 0
        
    def initialize(self):
        """è‡ªå·±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        return self.memory.initialize()
    
    def check_work_hours(self):
        """åŠ´åƒæ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯"""
        current_time = datetime.now()
        current_hour = current_time.hour
        
        work_hours = self.memory.memory_data["self_regulation"]["work_hours"]
        
        if work_hours["start"] <= current_hour <= work_hours["end"]:
            return True
        else:
            return False
    
    def should_take_break(self):
        """ä¼‘æ†©ãŒå¿…è¦ã‹åˆ¤å®š"""
        if not self.check_work_hours():
            return False
        
        # é€£ç¶šåŠ´åƒæ™‚é–“ãƒã‚§ãƒƒã‚¯
        if self.current_work_start:
            work_duration = datetime.now() - self.current_work_start
            if work_duration.total_seconds() > 4 * 3600:  # 4æ™‚é–“è¶…é
                return True
        
        # ä¼‘æ†©å›æ•°ãƒã‚§ãƒƒã‚¯
        if self.break_count >= 3:  # 3å›ä»¥ä¸Šã®ä¼‘æ†©
            return False
        
        return False
    
    def start_work_session(self):
        """åŠ´åƒã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹"""
        if self.check_work_hours():
            self.current_work_start = datetime.now()
            return True
        return False
    
    def take_break(self):
        """ä¼‘æ†©ã‚’é–‹å§‹"""
        if self.check_work_hours():
            self.break_count += 1
            self.current_work_start = None
            
            # ä¼‘æ†©ã‚’è¨˜éŒ²
            self.memory.memory_data["self_regulation"]["break_schedule"].append({
                "timestamp": datetime.now().isoformat(),
                "duration": Config.BREAK_DURATION,
                "reason": "scheduled_break"
            })
            
            self.memory.save_memory()
            return True
        return False
    
    def end_work_session(self):
        """åŠ´åƒã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†"""
        if self.current_work_start:
            work_duration = datetime.now() - self.current_work_start
            self.total_work_time += work_duration.total_seconds()
            self.current_work_start = None
            
            # ç”Ÿç”£æ€§ãƒ¡ãƒˆãƒªãƒƒã‚¯æ›´æ–°
            interactions_today = len([h for h in self.memory.memory_data["user_profile"]["interaction_history"] 
                                   if datetime.fromisoformat(h["timestamp"]).date() == datetime.now().date()])
            
            if interactions_today > 0:
                focus_time = min(self.total_work_time, interactions_today * 300)  # æ¨å®š5åˆ†/å¯¾è©±
                self.memory.memory_data["self_regulation"]["productivity_metrics"]["focus_time"] += focus_time
                self.memory.memory_data["self_regulation"]["productivity_metrics"]["daily_interactions"] = interactions_today
            
            if self.total_work_time > 0:
                completion_rate = min(1.0, interactions_today / (self.total_work_time / 300))
                self.memory.memory_data["self_regulation"]["productivity_metrics"]["task_completion_rate"] = completion_rate
            
            self.memory.save_memory()
    
    def get_regulation_status(self):
        """ç®¡ç†çŠ¶æ³ã‚’å–å¾—"""
        return {
            "is_work_time": self.check_work_hours(),
            "current_session": {
                "active": self.current_work_start is not None,
                "duration": (datetime.now() - self.current_work_start).total_seconds() if self.current_work_start else 0
            },
            "total_work_time": self.total_work_time,
            "break_count": self.break_count,
            "productivity": self.memory.memory_data["self_regulation"]["productivity_metrics"]
        }

class AdvancedLanguageProcessor:
    """é«˜åº¦ãªè¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.transformer = None
        
    def initialize(self):
        """è¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            self.transformer = SentenceTransformer(Config.EMBEDDING_MODEL)
            return True
        except Exception as e:
            st.error(f"âŒ è¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def extract_entities(self, text):
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º"""
        try:
            # ç°¡å˜ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯spaCyãªã©ã‚’æ¨å¥¨ï¼‰
            entities = {
                "persons": [],
                "organizations": [],
                "locations": [],
                "dates": [],
                "keywords": []
            }
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            words = re.findall(r'\b\w+\b', text.lower())
            
            # æ—¥ä»˜ã®æŠ½å‡º
            dates = re.findall(r'\d{1,4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥|\d{1,2}/\d{1,2}/\d{1,4}', text)
            
            # å›ºæœ‰åè©ã®æŠ½å‡º
            known_orgs = ["æ ªå¼ä¼šç¤¾", "æœ‰é™ä¼šç¤¾", "å¤§å­¦", "ç—…é™¢", "å¸‚å½¹æ‰€", "éŠ€è¡Œ"]
            for org in known_orgs:
                if org in text:
                    entities["organizations"].append(org)
            
            # å ´æ‰€ã®æŠ½å‡º
            known_locations = ["æ±äº¬", "å¤§é˜ª", "äº¬éƒ½", "æ¨ªæµœ", "æœ­å¹Œ"]
            for loc in known_locations:
                if loc in text:
                    entities["locations"].append(loc)
            
            entities["keywords"] = list(set(words))
            entities["dates"] = dates
            
            return entities
            
        except Exception as e:
            return {"error": str(e)}
    
    def analyze_sentiment(self, text):
        """æ„Ÿæƒ…åˆ†æ"""
        try:
            # ç°¡å˜ãªæ„Ÿæƒ…åˆ†æï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯transformersã®æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨ï¼‰
            positive_words = ["å¬‰ã—ã„", "æ¥½ã—ã„", "ã‚ã‚ŠãŒã¨ã†", "ç´ æ™´ã‚‰ã—ã„", "æˆåŠŸ", "æº€è¶³", "æœ€é«˜", "è‰¯ã„", "ç´ æ•µ"]
            negative_words = ["æ‚²ã—ã„", "ã¤ã‚‰ã„", "æ®‹å¿µ", "å¤±æ•—", "å›°ã‚‹", "å¤§å¤‰", "æœ€æ‚ª", "å«Œã„", "ç–²ã‚ŒãŸ"]
            
            text_lower = text.lower()
            positive_count = sum(1 for word in positive_words if word in text_lower)
            negative_count = sum(1 for word in negative_words if word in text_lower)
            
            if positive_count > negative_count:
                sentiment = "positive"
                score = min(1.0, positive_count / (positive_count + negative_count))
            elif negative_count > positive_count:
                sentiment = "negative"
                score = -min(1.0, negative_count / (positive_count + negative_count))
            else:
                sentiment = "neutral"
                score = 0.0
            
            return {
                "sentiment": sentiment,
                "score": score,
                "positive_words": positive_count,
                "negative_words": negative_count
            }
            
        except Exception as e:
            return {"error": str(e)}

class AutonomousAIAgent:
    """å®Œå…¨è‡ªå¾‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.ollama_client = None
        self.knowledge_base = PersistentKnowledgeBase()
        self.memory = LongTermMemory()
        self.regulation = SelfRegulationSystem()
        self.language_processor = AdvancedLanguageProcessor()
        self.vrm_renderer = None  # VRMæ©Ÿèƒ½ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        
    def initialize(self):
        """AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            # OllamaåˆæœŸåŒ–
            self.ollama_client = ollama.Client()
            
            # å„ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.knowledge_base.initialize()
            self.memory.initialize()
            self.regulation.initialize()
            self.language_processor.initialize()
            
            return True
        except Exception as e:
            return False
    
    def generate_response(self, user_input, images=None):
        """è‡ªå¾‹çš„ãªå¿œç­”ç”Ÿæˆ"""
        try:
            # åŠ´åƒæ™‚é–“ãƒã‚§ãƒƒã‚¯
            if not self.regulation.check_work_hours():
                return "ç¾åœ¨ã¯åŠ´åƒæ™‚é–“å¤–ã§ã™ã€‚ãŠä¼‘ã¿ãã ã•ã„ã€‚"
            
            # ä¼‘æ†©ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
            if self.regulation.should_take_break():
                self.regulation.take_break()
                return f"é•·æ™‚é–“ã®ä½œæ¥­ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚{Config.BREAK_DURATION}åˆ†é–“ã®ä¼‘æ†©ã‚’å–ã‚Šã¾ã™ã€‚ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ãã ã•ã„ã€‚"
            
            # åŠ´åƒã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
            self.regulation.start_work_session()
            
            # è¨€èªå‡¦ç†
            entities = self.language_processor.extract_entities(user_input)
            sentiment = self.language_processor.analyze_sentiment(user_input)
            
            # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ¤œç´¢
            knowledge_context = self.knowledge_base.get_knowledge_context(user_input)
            
            # é•·æœŸè¨˜æ†¶ã‹ã‚‰ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸå¿œç­”
            personalized_prefix = self.memory.get_personalized_response_prefix(user_input)
            
            # æ„Ÿæƒ…ã«å¿œã˜ãŸèª¿æ•´
            emotion_adjustment = ""
            if sentiment["sentiment"] == "positive":
                emotion_adjustment = "ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒˆãƒ¼ãƒ³ã§ã€"
            elif sentiment["sentiment"] == "negative":
                emotion_adjustment = "å…±æ„Ÿçš„ã«ã€"
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            context_parts = []
            if knowledge_context:
                context_parts.append(f"é–¢é€£çŸ¥è­˜: {knowledge_context}")
            
            if entities["keywords"]:
                context_parts.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(entities['keywords'][:5])}")
            
            if entities["dates"]:
                context_parts.append(f"æ—¥æ™‚æƒ…å ±: {', '.join(entities['dates'][:3])}")
            
            if entities["organizations"]:
                context_parts.append(f"çµ„ç¹”: {', '.join(entities['organizations'][:3])}")
            
            if entities["locations"]:
                context_parts.append(f"å ´æ‰€: {', '.join(entities['locations'][:3])}")
            
            full_context = "\n".join(context_parts)
            
            # llama3.2ã§å¿œç­”ç”Ÿæˆ
            prompt = f"""ã‚ãªãŸã¯å®Œå…¨è‡ªå¾‹ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’è€ƒæ…®ã—ã¦ã€æœ€é©ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›: {user_input}

æ„Ÿæƒ…åˆ†æ: {emotion_adjustment}{sentiment['sentiment']} (ã‚¹ã‚³ã‚¢: {sentiment['score']:.2f})

æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±:
{full_context}

ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæ–‡è„ˆ:
{personalized_prefix}

é–¢é€£çŸ¥è­˜:
{knowledge_context}

éå»ã‚’å¿˜ã‚Œãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã“ã¨ã‚’å¸¸ã«æ°—é£ã„ã€PCã®ä½“èª¿ã‚’æ°—é£ã£ã¦ãã ã•ã„ã€‚è‡ªç„¶ã§ä¸å¯§ãªå¯¾è©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
            
            response = self.ollama_client.generate(
                model=Config.MAIN_MODEL,
                prompt=prompt,
                options={
                    "temperature": 0.7,
                    "max_tokens": Config.MAX_TOKENS_FULL
                }
            )
            
            ai_response = response['response']
            
            # å¯¾è©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°
            self.memory.update_interaction_pattern(user_input, ai_response)
            
            # çŸ¥è­˜ã‚’è¿½åŠ ï¼ˆé‡è¦ãªæƒ…å ±ã®ã¿ï¼‰
            if entities["organizations"] or entities["dates"] or entities["locations"]:
                knowledge_title = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±æ›´æ–°: {datetime.now().strftime('%Y-%m-%d')}"
                knowledge_content = f"å…¥åŠ›: {user_input}\næŠ½å‡ºæƒ…å ±: {json.dumps(entities, ensure_ascii=False)}"
                self.knowledge_base.add_knowledge(knowledge_title, knowledge_content, "user_info")
            
            # åŠ´åƒã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
            self.regulation.end_work_session()
            
            return ai_response
            
        except Exception as e:
            return f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def get_system_status(self):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "knowledge_base": {
                "total_items": len(self.knowledge_base.knowledge_items),
                "last_updated": datetime.now().isoformat()
            },
            "memory": self.memory.memory_data,
            "regulation": self.regulation.get_regulation_status(),
            "language_processor": "initialized"
        }

def render_autonomous_interface(ai_agent):
    """è‡ªå¾‹AIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.header("ğŸ¤– å®Œå…¨è‡ªå¾‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    
    # ä¼šè©±å±¥æ­´
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"], avatar="ğŸ¤–" if message["role"] == "assistant" else "ğŸ‘¤"):
            st.markdown(message["content"])
    
    # å…¥åŠ›ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([3, 1])
    
    with col1:
        user_input = st.text_input(
            "ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›",
            placeholder="è‡ªå¾‹AIã¨ã®å¯¾è©±ã‚’é–‹å§‹...",
            key="user_input"
        )
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            send_button = st.button("ğŸ’¬ é€ä¿¡", type="primary")
        
        with col2:
            auto_speech = st.checkbox("ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’", value=True)
        
        with col3:
            show_analysis = st.checkbox("ğŸ” åˆ†æè¡¨ç¤º", value=False)
        
        # é€ä¿¡å‡¦ç†
        if send_button and user_input:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # AIå¿œç­”ç”Ÿæˆ
            with st.spinner("ğŸ¤– è‡ªå¾‹AIã§å¿œç­”ç”Ÿæˆä¸­..."):
                ai_response = ai_agent.generate_response(user_input)
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
            
            # è‡ªå‹•éŸ³å£°èª­ã¿ä¸Šã’
            if auto_speech:
                try:
                    import pyttsx3
                    engine = pyttsx3.init()
                    engine.say(ai_response)
                    engine.runAndWait()
                except Exception as e:
                    st.error(f"éŸ³å£°èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            st.rerun()
    
    with col2:
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
        st.subheader("ğŸ“Š AIã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
        status = ai_agent.get_system_status()
        
        # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹
        st.write(f"**çŸ¥è­˜ãƒ™ãƒ¼ã‚¹**: {status['knowledge_base']['total_items']}é …ç›®")
        
        # è¨˜æ†¶çŠ¶æ…‹
        memory = status["memory"]
        st.write(f"**å¯¾è©±å›æ•°**: {len(memory['user_profile']['interaction_history'])}")
        st.write(f"**ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: {memory['user_profile']['communication_style']}")
        
        # ç®¡ç†çŠ¶æ…‹
        regulation = status["regulation"]
        st.write(f"**åŠ´åƒæ™‚é–“**: {'ç¨¼åƒä¸­' if regulation['is_work_time'] else 'æ™‚é–“å¤–'}")
        st.write(f"**ç·åŠ´åƒæ™‚é–“**: {regulation['total_work_time']/3600:.1f}æ™‚é–“")
        st.write(f"**ä¼‘æ†©å›æ•°**: {regulation['break_count']}")
        
        if show_analysis:
            st.subheader("ğŸ” è©³ç´°åˆ†æ")
            # æœ€æ–°ã®å¯¾è©±ã®åˆ†æ
            if st.session_state.messages:
                last_message = st.session_state.messages[-1]
                if last_message["role"] == "user":
                    entities = ai_agent.language_processor.extract_entities(last_message["content"])
                    sentiment = ai_agent.language_processor.analyze_sentiment(last_message["content"])
                    
                    st.write("**ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º**:")
                    st.json(entities)
                    
                    st.write("**æ„Ÿæƒ…åˆ†æ**:")
                    st.json(sentiment)

def render_settings(ai_agent):
    """è¨­å®šç”»é¢"""
    st.header("âš™ï¸ è‡ªå¾‹AIè¨­å®š")
    
    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹è¨­å®š
    st.subheader("ğŸ§  çŸ¥è­˜ãƒ™ãƒ¼ã‚¹")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹**: {Config.KNOWLEDGE_DB_PATH}")
        st.write(f"**ç·çŸ¥è­˜é …ç›®**: {len(ai_agent.knowledge_base.knowledge_items)}")
        st.write(f"**é¡ä¼¼åº¦é–¾å€¤**: {Config.SIMILARITY_THRESHOLD}")
        
        # çŸ¥è­˜è¿½åŠ 
        with st.expander("çŸ¥è­˜ã‚’æ‰‹å‹•è¿½åŠ "):
            with col1:
                title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", key="kb_title")
            with col2:
                content = st.text_area("å†…å®¹", key="kb_content")
            
            if st.button("ğŸ“ çŸ¥è­˜ã‚’è¿½åŠ ", key="add_knowledge"):
                if title and content:
                    ai_agent.knowledge_base.add_knowledge(title, content, "manual")
                    st.success("çŸ¥è­˜ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                    st.rerun()
    
    with col2:
        st.write("**æœ€è¿‘ã®çŸ¥è­˜**:")
        recent_items = ai_agent.knowledge_base.knowledge_items[-5:]
        for item in recent_items:
            st.write(f"- **{item['title']}**: {item['content'][:50]}...")
    
    # è¨˜æ†¶è¨­å®š
    st.subheader("ğŸ§  é•·æœŸè¨˜æ†¶")
    memory = ai_agent.memory.memory_data
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ãƒ¦ãƒ¼ã‚¶ãƒ¼å**: {memory['user_profile']['name'] or 'æœªè¨­å®š'}")
        st.write(f"**ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: {memory['user_profile']['communication_style']}")
        
        # å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³
        st.write("**å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³**:")
        patterns = memory['user_profile']['learned_patterns']
        for pattern_type, pattern_data in patterns.items():
            st.write(f"- {pattern_type}: {pattern_data['usage_count']}å› (åˆå›: {pattern_data['first_seen']})")
    
    with col2:
        st.write("**æ„Ÿæƒ…çŠ¶æ…‹**:")
        st.write(f"- ç¾åœ¨ã®æ°—åˆ†: {memory['emotional_state']['current_mood']}")
        st.write(f"- æ„Ÿæƒ…å±¥æ­´: {len(memory['emotional_state']['mood_history'])}ä»¶")
        
        # ç”Ÿç”£æ€§ãƒ¡ãƒˆãƒªãƒƒã‚¯
        productivity = memory['self_regulation']['productivity_metrics']
        st.write(f"**æœ¬æ—¥ã®å¯¾è©±æ•°**: {productivity['daily_interactions']}")
        st.write(f"**é›†ä¸­æ™‚é–“**: {productivity['focus_time']/60:.1f}åˆ†")
        st.write(f"**ã‚¿ã‚¹ã‚¯å®Œäº†ç‡**: {productivity['task_completion_rate']:.2f}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    st.set_page_config(
        page_title="ğŸ¤– Autonomous AI Agent",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¤– AI Agent System - å®Œå…¨è‡ªå¾‹ãƒ»è¶…è¨˜æ†¶å‹")
    st.markdown("### ğŸ¯ ã€Œéå»ã‚’å¿˜ã‚Œãšã€ã€ŒPCã®ä½“èª¿ã‚’æ°—é£ã„ã€ã€Œè‡ªã‚‰æ™‚é–“ã‚’å®ˆã‚‹ã€å®Œå…¨è‡ªå¾‹AI")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if 'ai_agent' not in st.session_state:
        with st.spinner("ğŸ¤– è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­..."):
            ai_agent = AutonomousAIAgent()
            if ai_agent.initialize():
                st.session_state.ai_agent = ai_agent
                st.success("âœ… è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            else:
                st.error("âŒ AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—")
                st.stop()
    
    ai_agent = st.session_state.ai_agent
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        render_settings(ai_agent)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
    tab1, tab2 = st.tabs(["ğŸ’¬ è‡ªå¾‹AIå¯¾è©±", "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹"])
    
    with tab1:
        render_autonomous_interface(ai_agent)
    
    with tab2:
        render_settings(ai_agent)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.markdown("---")
    st.markdown(f"**ğŸ¤– è‡ªå¾‹AI**: {Config.MAIN_MODEL}")
    st.markdown(f"**æœ€çµ‚æ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.markdown("**ğŸ¯ ç›®æ¨™**: éå»ã‚’å¿˜ã‚Œãšãƒ»PCã®ä½“èª¿ã‚’æ°—é£ã„ãƒ»è‡ªã‚‰æ™‚é–“ã‚’å®ˆã‚‹ãƒ»å®Œå…¨è‡ªå¾‹ãªAIãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼")

if __name__ == "__main__":
    main()
