#!/usr/bin/env python3
"""
Ollamaãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import requests
import time
import json
import logging
import subprocess

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OllamaModelSetup:
    def __init__(self):
        self.ollama_host = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
        self.models_to_pull = [
            'llama3.2',
            'llama3.2-vision'
        ]
    
    def wait_for_ollama(self, timeout=300):
        """OllamaãŒèµ·å‹•ã™ã‚‹ã®ã‚’å¾…ã¤"""
        logger.info("ğŸ”„ Ollamaã®èµ·å‹•ã‚’å¾…ã£ã¦ã„ã¾ã™...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                response = requests.get(f"{self.ollama_host}/api/tags", timeout=5)
                if response.status_code == 200:
                    logger.info("âœ… OllamaãŒèµ·å‹•ã—ã¾ã—ãŸ")
                    return True
            except requests.exceptions.RequestException:
                pass
            
            logger.info("â³ Ollamaèµ·å‹•ä¸­...")
            time.sleep(5)
        
        logger.error("âŒ Ollamaã®èµ·å‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return False
    
    def check_models(self):
        """å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª"""
        logger.info("ğŸ” ãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèªã—ã¾ã™...")
        
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=10)
            if response.status_code == 200:
                data = response.json()
                available_models = [model['name'] for model in data.get('models', [])]
                
                missing_models = []
                for model in self.models_to_pull:
                    if model not in available_models:
                        missing_models.append(model)
                
                if missing_models:
                    logger.info(f"âš ï¸ æ¬ ã‘ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«: {missing_models}")
                    return False, missing_models
                else:
                    logger.info("âœ… å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                    return True, []
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return False, []
        
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return False, []
    
    def pull_model_background(self, model_name):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ—ãƒ«"""
        logger.info(f"ğŸ“¥ ãƒ¢ãƒ‡ãƒ« {model_name} ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        try:
            # Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œ
            cmd = f"docker exec -d ai-ollama ollama pull {model_name}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ« {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                return True
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ« {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹å¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ« {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def check_pull_progress(self, model_name):
        """ãƒ—ãƒ«ã®é€²æ—ã‚’ç¢ºèª"""
        try:
            cmd = f"docker exec ai-ollama ollama list"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                output = result.stdout
                if model_name in output:
                    logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ« {model_name} ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                    return True
                else:
                    logger.info(f"â³ ãƒ¢ãƒ‡ãƒ« {model_name} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                    return False
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ—ãƒ«é€²æ—ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def setup_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å…¨ä½“"""
        logger.info("ğŸš€ Ollamaãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # 1. Ollamaã®èµ·å‹•ã‚’å¾…ã¤
        if not self.wait_for_ollama():
            return False
        
        # 2. ãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª
        models_ok, missing_models = self.check_models()
        
        if models_ok:
            logger.info("âœ… å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒæ—¢ã«åˆ©ç”¨å¯èƒ½ã§ã™")
            return True
        
        # 3. æ¬ ã‘ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ—ãƒ«
        logger.info("ğŸ“¥ æ¬ ã‘ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
        
        for model in missing_models:
            if self.pull_model_background(model):
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ« {model} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ« {model} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹å¤±æ•—")
                return False
        
        # 4. ãƒ—ãƒ«ã®å®Œäº†ã‚’å¾…ã¤
        logger.info("â³ ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
        
        max_wait_time = 600  # 10åˆ†
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            all_ready = True
            
            for model in missing_models:
                if not self.check_pull_progress(model):
                    all_ready = False
                    break
            
            if all_ready:
                logger.info("âœ… å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                return True
            
            logger.info("â³ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            time.sleep(30)
        
        logger.error("âŒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸ¯ Ollamaãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    
    setup = OllamaModelSetup()
    
    try:
        success = setup.setup_models()
        if success:
            logger.info("ğŸ‰ ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æˆåŠŸ")
            return 0
        else:
            logger.error("âŒ ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—")
            return 1
            
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        return 0
    except Exception as e:
        logger.error(f"âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
