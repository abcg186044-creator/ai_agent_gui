#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¦ªå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒãƒ«ãƒAIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹å–„ç‰ˆï¼‰
"""

import asyncio
import time
import json
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor

class TaskStep(Enum):
    """ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒƒãƒ—"""
    INITIALIZATION = "initialization"
    REQUIREMENT_ANALYSIS = "requirement_analysis"
    AI_PLANNING = "ai_planning"
    PARALLEL_EXECUTION = "parallel_execution"
    CODE_VALIDATION = "code_validation"
    CODE_INTEGRATION = "code_integration"
    FINALIZATION = "finalization"

@dataclass
class OrchestratedTask:
    """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯"""
    id: str
    description: str
    user_request: str
    current_step: TaskStep = TaskStep.INITIALIZATION
    progress: float = 0.0
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    error_message: Optional[str] = None
    results: Dict[str, Any] = field(default_factory=dict)
    subtasks: List[str] = field(default_factory=list)
    step_progress: Dict[str, float] = field(default_factory=dict)

class MockAsyncOllamaClient:
    """ãƒ¢ãƒƒã‚¯éåŒæœŸOllamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, ports=None, models=None):
        self.ports = ports or [11434, 11435, 11436]
        self.models = models or ["llama3.2:3b", "llama3.1:8b"]
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass
    
    async def generate_response_async(self, prompt: str, progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """ãƒ¢ãƒƒã‚¯å¿œç­”ç”Ÿæˆ"""
        await asyncio.sleep(0.1)  # å°‘ã—é…å»¶
        
        if progress_callback:
            progress_callback({"step": "åˆ†æä¸­...", "progress": 50})
        
        # ç°¡å˜ãªãƒ¢ãƒƒã‚¯å¿œç­”
        if "é›»å“" in prompt:
            response = '''
{
  "main_functions": ["å››å‰‡æ¼”ç®—", "GUIè¡¨ç¤º", "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"],
  "technical_requirements": ["tkinter", "Python 3.8+", "ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"],
  "implementation_priority": ["åŸºæœ¬æ¼”ç®—", "UIè¨­è¨ˆ", "æ©Ÿèƒ½æ‹¡å¼µ"],
  "components": ["Calculatorã‚¯ãƒ©ã‚¹", "Buttonã‚¯ãƒ©ã‚¹", "Displayã‚¯ãƒ©ã‚¹"],
  "challenges": ["ã‚¼ãƒ­é™¤ç®—", "å…¥åŠ›æ¤œè¨¼", "UIå¿œç­”æ€§"]
}
'''
        else:
            response = '''
{
  "main_functions": ["åŸºæœ¬æ©Ÿèƒ½å®Ÿè£…"],
  "technical_requirements": ["Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"],
  "implementation_priority": ["åŸºæœ¬è¨­è¨ˆ", "å®Ÿè£…", "ãƒ†ã‚¹ãƒˆ"],
  "components": ["Mainã‚¯ãƒ©ã‚¹"],
  "challenges": ["è¦ä»¶å®šç¾©"]
}
'''
        
        return {
            "success": True,
            "response": response,
            "model": "mock_model",
            "port": 11434,
            "elapsed_time": 0.1
        }

class MockRobustMultiAISystem:
    """ãƒ¢ãƒƒã‚¯å …ç‰¢ãƒãƒ«ãƒAIã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, ollama_ports=None):
        self.ollama_ports = ollama_ports or [11434, 11435, 11436]
    
    async def generate_response_async(self, prompt: str, task_description: str = "", progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """ãƒ¢ãƒƒã‚¯ä¸¦åˆ—å¿œç­”ç”Ÿæˆ"""
        await asyncio.sleep(0.2)  # å°‘ã—é…å»¶
        
        if progress_callback:
            progress_callback({"step": "AIãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œä¸­...", "progress": 50})
        
        # ç°¡å˜ãªãƒ¢ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        if "é›»å“" in prompt:
            code = '''import tkinter as tk

class Calculator:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("é›»å“")
        self.setup_ui()
    
    def setup_ui(self):
        self.display = tk.Entry(self.root, font=("Arial", 20))
        self.display.pack()
        
        buttons = ["7", "8", "9", "/", "4", "5", "6", "*", "1", "2", "3", "-", "0", ".", "=", "+"]
        
        for i, text in enumerate(buttons):
            btn = tk.Button(self.root, text=text, command=lambda t=text: self.on_click(t))
            btn.grid(row=i//4, column=i%4)
    
    def on_click(self, text):
        if text == "=":
            try:
                result = eval(self.display.get())
                self.display.delete(0, tk.END)
                self.display.insert(0, str(result))
            except:
                self.display.delete(0, tk.END)
                self.display.insert(0, "Error")
        else:
            self.display.insert(tk.END, text)
    
    def run(self):
        self.root.mainloop()

if __name__ == "__main__":
    app = Calculator()
    app.run()
'''
        else:
            code = '''# åŸºæœ¬å®Ÿè£…
def main():
    print("Hello World")

if __name__ == "__main__":
    main()
'''
        
        return {
            "success": True,
            "response": code,
            "ai_type": "mock_ai",
            "elapsed_time": 0.2
        }

class MockCodingTaskRunner:
    """ãƒ¢ãƒƒã‚¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼"""
    
    def __init__(self, max_workers=3):
        self.max_workers = max_workers
        self.tasks = {}
        self.progress_callbacks = []
    
    def add_progress_callback(self, callback):
        self.progress_callbacks.append(callback)
    
    def add_task(self, description: str, code: str, file_path: str = None, priority=None) -> str:
        task_id = f"task_{int(time.time() * 1000)}"
        self.tasks[task_id] = {
            "id": task_id,
            "description": description,
            "code": code,
            "file_path": file_path,
            "status": "completed"
        }
        
        # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        for callback in self.progress_callbacks:
            callback({"task_id": task_id, "message": "ã‚¿ã‚¹ã‚¯å®Œäº†", "progress": 100})
        
        return task_id
    
    def start_processing(self):
        pass
    
    def stop_processing(self):
        pass
    
    def get_task_status(self, task_id: str):
        return self.tasks.get(task_id)

class FriendOrchestratorFixed:
    """æ”¹å–„ç‰ˆè¦ªå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, max_concurrent_tasks: int = 3):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.ollama_client = None
        self.multi_ai_system = None
        self.task_runner = None
        self.active_tasks: Dict[str, OrchestratedTask] = {}
        self.task_queue = asyncio.Queue()
        self.progress_callbacks: List[Callable] = []
        self.running = False
        self.step_handlers = {}
        self.setup_step_handlers()
    
    def setup_step_handlers(self):
        """ã‚¹ãƒ†ãƒƒãƒ—ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š"""
        self.step_handlers = {
            TaskStep.INITIALIZATION: self.handle_initialization,
            TaskStep.REQUIREMENT_ANALYSIS: self.handle_requirement_analysis,
            TaskStep.AI_PLANNING: self.handle_ai_planning,
            TaskStep.PARALLEL_EXECUTION: self.handle_parallel_execution,
            TaskStep.CODE_VALIDATION: self.handle_code_validation,
            TaskStep.CODE_INTEGRATION: self.handle_code_integration,
            TaskStep.FINALIZATION: self.handle_finalization
        }
    
    def add_progress_callback(self, callback: Callable):
        """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ """
        self.progress_callbacks.append(callback)
    
    def notify_progress(self, task_id: str, step: TaskStep, message: str, progress: float, details: Dict[str, Any] = None):
        """é€²æ—ã‚’é€šçŸ¥"""
        progress_info = {
            "task_id": task_id,
            "step": step.value,
            "message": message,
            "progress": progress,
            "timestamp": time.time(),
            "details": details or {}
        }
        
        for callback in self.progress_callbacks:
            try:
                callback(progress_info)
            except Exception as e:
                print(f"Progress callback error: {e}")
    
    async def setup(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        if self.ollama_client is None:
            self.ollama_client = MockAsyncOllamaClient(
                ports=[11434, 11435, 11436],
                models=["llama3.2:3b", "llama3.1:8b"]
            )
        
        if self.multi_ai_system is None:
            self.multi_ai_system = MockRobustMultiAISystem(ollama_ports=[11434, 11435, 11436])
        
        if self.task_runner is None:
            self.task_runner = MockCodingTaskRunner(max_workers=3)
            self.task_runner.add_progress_callback(self.on_task_runner_progress)
    
    def on_task_runner_progress(self, progress_info: Dict[str, Any]):
        """ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        for task_id, task in self.active_tasks.items():
            if task.current_step in [TaskStep.CODE_VALIDATION, TaskStep.CODE_INTEGRATION]:
                task.step_progress[task.current_step.value] = progress_info.get('progress', 0.0)
                self.notify_progress(
                    task_id, 
                    task.current_step, 
                    f"ã‚³ãƒ¼ãƒ‰å‡¦ç†ä¸­: {progress_info.get('message', '')}", 
                    task.progress,
                    {"subtask_progress": progress_info}
                )
    
    async def create_task(self, user_request: str, description: str) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ"""
        task_id = f"orch_task_{int(time.time() * 1000)}"
        
        task = OrchestratedTask(
            id=task_id,
            description=description,
            user_request=user_request
        )
        
        self.active_tasks[task_id] = task
        await self.task_queue.put(task_id)
        
        self.notify_progress(task_id, TaskStep.INITIALIZATION, "ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ", 0.0)
        return task_id
    
    async def process_task_step(self, task_id: str, step: TaskStep) -> bool:
        """ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‡¦ç†"""
        task = self.active_tasks.get(task_id)
        if not task:
            return False
        
        task.current_step = step
        handler = self.step_handlers.get(step)
        
        if handler:
            try:
                self.notify_progress(task_id, step, f"{step.value}ã‚’é–‹å§‹ã—ã¾ã™", task.progress)
                result = await handler(task)
                
                if result["success"]:
                    task.results[step.value] = result
                    task.progress += (100.0 / len(TaskStep))
                    self.notify_progress(task_id, step, f"{step.value}ãŒå®Œäº†ã—ã¾ã—ãŸ", task.progress, result)
                    return True
                else:
                    task.error_message = result.get("error", "Unknown error")
                    self.notify_progress(task_id, step, f"{step.value}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ", task.progress, {"error": task.error_message})
                    return False
                    
            except Exception as e:
                task.error_message = str(e)
                self.notify_progress(task_id, step, f"{step.value}ã§ä¾‹å¤–ãŒç™ºç”Ÿ", task.progress, {"error": str(e)})
                return False
        
        return False
    
    async def handle_initialization(self, task: OrchestratedTask) -> Dict[str, Any]:
        """åˆæœŸåŒ–å‡¦ç†"""
        await self.setup()
        
        return {
            "success": True,
            "message": "ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†",
            "systems_initialized": ["ollama_client", "multi_ai_system", "task_runner"]
        }
    
    async def handle_requirement_analysis(self, task: OrchestratedTask) -> Dict[str, Any]:
        """è¦ä»¶åˆ†æå‡¦ç†"""
        self.notify_progress(task.id, TaskStep.REQUIREMENT_ANALYSIS, "ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’åˆ†æä¸­...", 10.0)
        
        analysis_prompt = f"""
        ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’åˆ†æã—ã€å®Ÿè£…è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
        
        è¦æ±‚: {task.user_request}
        èª¬æ˜: {task.description}
        
        åˆ†æé …ç›®ï¼š
        1. ä¸»è¦æ©Ÿèƒ½ã®ç‰¹å®š
        2. æŠ€è¡“è¦ä»¶ã®æŠ½å‡º
        3. å®Ÿè£…å„ªå…ˆé †ä½
        4. å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        5. äºˆæ¸¬ã•ã‚Œã‚‹èª²é¡Œ
        
        JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
        """
        
        async with self.ollama_client as client:
            result = await client.generate_response_async(
                analysis_prompt,
                lambda p: self.notify_progress(task.id, TaskStep.REQUIREMENT_ANALYSIS, p.get('step', ''), 30.0 + p.get('progress', 0) * 0.4)
            )
        
        if result["success"]:
            try:
                analysis = json.loads(result["response"])
                return {
                    "success": True,
                    "analysis": analysis,
                    "model_used": result["model"],
                    "port_used": result["port"]
                }
            except:
                return {
                    "success": True,
                    "analysis": {"raw_response": result["response"]},
                    "model_used": result["model"],
                    "port_used": result["port"]
                }
        else:
            return {"success": False, "error": result.get("error", "Analysis failed")}
    
    async def handle_ai_planning(self, task: OrchestratedTask) -> Dict[str, Any]:
        """AIè¨ˆç”»å‡¦ç†"""
        self.notify_progress(task.id, TaskStep.AI_PLANNING, "AIå®Ÿè¡Œè¨ˆç”»ã‚’ä½œæˆä¸­...", 40.0)
        
        # ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ
        subtasks = [
            {
                "id": f"{task.id}_basic",
                "description": "åŸºæœ¬æ©Ÿèƒ½ã®å®Ÿè£…",
                "prompt": task.user_request,
                "priority": "high"
            },
            {
                "id": f"{task.id}_advanced",
                "description": "æ‹¡å¼µæ©Ÿèƒ½ã®å®Ÿè£…",
                "prompt": f"{task.user_request}\n\nè¿½åŠ æ©Ÿèƒ½ï¼šã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ†ã‚¹ãƒˆã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                "priority": "medium"
            },
            {
                "id": f"{task.id}_optimized",
                "description": "æœ€é©åŒ–ã¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°",
                "prompt": f"{task.user_request}\n\næœ€é©åŒ–ï¼šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã‚³ãƒ¼ãƒ‰å“è³ªã€ä¿å®ˆæ€§",
                "priority": "low"
            }
        ]
        
        task.subtasks = [subtask["id"] for subtask in subtasks]
        
        return {
            "success": True,
            "subtasks": subtasks,
            "total_subtasks": len(subtasks)
        }
    
    async def handle_parallel_execution(self, task: OrchestratedTask) -> Dict[str, Any]:
        """ä¸¦åˆ—å®Ÿè¡Œå‡¦ç†"""
        self.notify_progress(task.id, TaskStep.PARALLEL_EXECUTION, "è¤‡æ•°AIã§ä¸¦åˆ—å®Ÿè¡Œä¸­...", 50.0)
        
        planning_result = task.results.get(TaskStep.AI_PLANNING.value, {})
        subtasks = planning_result.get("subtasks", [])
        
        if not subtasks:
            return {"success": False, "error": "No subtasks to execute"}
        
        # å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        execution_results = []
        
        def progress_callback_factory(subtask_id):
            def callback(progress_info):
                new_info = progress_info.copy()
                new_info["subtask_id"] = subtask_id
                self.notify_progress(task.id, TaskStep.PARALLEL_EXECUTION, 
                                  f"ã‚µãƒ–ã‚¿ã‚¹ã‚¯å®Ÿè¡Œä¸­: {progress_info.get('step', '')}", 
                                  50.0 + progress_info.get('progress', 0) * 0.3, new_info)
            return callback
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        tasks = []
        for subtask in subtasks:
            task_coroutine = self.multi_ai_system.generate_response_async(
                subtask["prompt"],
                subtask["description"],
                progress_callback_factory(subtask["id"])
            )
            tasks.append(task_coroutine)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                execution_results.append({
                    "subtask_id": subtasks[i]["id"],
                    "success": False,
                    "error": str(result)
                })
            else:
                execution_results.append({
                    "subtask_id": subtasks[i]["id"],
                    "success": result["success"],
                    "response": result.get("response", ""),
                    "ai_type": result.get("ai_type", ""),
                    "elapsed_time": result.get("elapsed_time", 0)
                })
        
        successful_results = [r for r in execution_results if r["success"]]
        
        return {
            "success": len(successful_results) > 0,
            "execution_results": execution_results,
            "successful_count": len(successful_results),
            "total_count": len(execution_results)
        }
    
    async def handle_code_validation(self, task: OrchestratedTask) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰æ¤œè¨¼å‡¦ç†"""
        self.notify_progress(task.id, TaskStep.CODE_VALIDATION, "ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’æ¤œè¨¼ä¸­...", 70.0)
        
        execution_result = task.results.get(TaskStep.PARALLEL_EXECUTION.value, {})
        execution_results = execution_result.get("execution_results", [])
        
        validation_results = []
        
        for result in execution_results:
            if result["success"] and result["response"]:
                task_id = self.task_runner.add_task(
                    description=f"ã‚³ãƒ¼ãƒ‰æ¤œè¨¼: {result['subtask_id']}",
                    code=result["response"],
                    file_path=f"validated_{result['subtask_id']}.py",
                    priority="high"
                )
                
                validation_results.append({
                    "subtask_id": result["subtask_id"],
                    "validation_task_id": task_id,
                    "code_length": len(result["response"])
                })
        
        return {
            "success": True,
            "validation_results": validation_results,
            "successful_count": len(validation_results),
            "total_count": len(validation_results)
        }
    
    async def handle_code_integration(self, task: OrchestratedTask) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰çµ±åˆå‡¦ç†"""
        self.notify_progress(task.id, TaskStep.CODE_INTEGRATION, "ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆä¸­...", 85.0)
        
        validation_result = task.results.get(TaskStep.CODE_VALIDATION.value, {})
        validation_results = validation_result.get("validation_results", [])
        
        integrated_code = ""
        successful_integrations = 0
        
        for validation in validation_results:
            integrated_code += f"\n# {validation['subtask_id']}\n"
            integrated_code += f"# ã‚³ãƒ¼ãƒ‰é•·: {validation['code_length']} æ–‡å­—\n"
            integrated_code += "# æ¤œè¨¼æ¸ˆã¿ã‚³ãƒ¼ãƒ‰\n"
            integrated_code += "print('ã‚³ãƒ¼ãƒ‰ãŒæ­£å¸¸ã«çµ±åˆã•ã‚Œã¾ã—ãŸ')\n"
            integrated_code += "\n" + "="*50 + "\n"
            successful_integrations += 1
        
        if integrated_code:
            final_task_id = self.task_runner.add_task(
                description=f"æœ€çµ‚çµ±åˆã‚³ãƒ¼ãƒ‰: {task.description}",
                code=integrated_code,
                file_path=f"final_{task.id}.py",
                priority="urgent"
            )
            
            return {
                "success": True,
                "integrated_code_length": len(integrated_code),
                "successful_integrations": successful_integrations,
                "final_task_id": final_task_id
            }
        else:
            return {
                "success": False,
                "error": "No validated code to integrate"
            }
    
    async def handle_finalization(self, task: OrchestratedTask) -> Dict[str, Any]:
        """æœ€çµ‚å‡¦ç†"""
        self.notify_progress(task.id, TaskStep.FINALIZATION, "ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã—ã¦ã„ã¾ã™...", 95.0)
        
        task.completed_at = time.time()
        total_time = task.completed_at - task.created_at
        
        summary = {
            "task_id": task.id,
            "description": task.description,
            "user_request": task.user_request,
            "total_time": total_time,
            "completed_steps": list(task.results.keys()),
            "final_status": "completed" if task.error_message is None else "failed"
        }
        
        self.notify_progress(task.id, TaskStep.FINALIZATION, "ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸï¼", 100.0, summary)
        
        return {
            "success": True,
            "summary": summary,
            "total_time": total_time
        }
    
    async def execute_task(self, task_id: str) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
        task = self.active_tasks.get(task_id)
        if not task:
            return {"success": False, "error": "Task not found"}
        
        task.started_at = time.time()
        
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œ
        for step in TaskStep:
            success = await self.process_task_step(task_id, step)
            
            if not success:
                task.error_message = f"Failed at step: {step.value}"
                break
            
            await asyncio.sleep(0.5)
        
        return {
            "success": task.error_message is None,
            "task_id": task_id,
            "total_time": time.time() - task.started_at if task.started_at else 0,
            "error": task.error_message
        }
    
    def get_task_status(self, task_id: str) -> Optional[OrchestratedTask]:
        """ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
        return self.active_tasks.get(task_id)
    
    def get_all_tasks(self) -> List[OrchestratedTask]:
        """ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
        return list(self.active_tasks.values())

# ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    async def demo_orchestrator():
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ‡ãƒ¢"""
        print("ğŸš€ è¦ªå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒãƒ«ãƒAIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¢ï¼ˆæ”¹å–„ç‰ˆï¼‰")
        print("=" * 60)
        
        def progress_callback(progress_info):
            timestamp = time.strftime("%H:%M:%S")
            print(f"[{timestamp}] ğŸ“Š {progress_info['task_id']}: {progress_info['message']} ({progress_info['progress']:.1f}%)")
            if progress_info.get('details'):
                for key, value in progress_info['details'].items():
                    if isinstance(value, dict):
                        print(f"           {key}: {json.dumps(value, ensure_ascii=False)[:100]}...")
                    else:
                        print(f"           {key}: {value}")
            print("-" * 50)
        
        orchestrator = FriendOrchestratorFixed(max_concurrent_tasks=2)
        orchestrator.add_progress_callback(progress_callback)
        
        # ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        task_id = await orchestrator.create_task(
            user_request="Pythonã§GUIé›»å“ã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚tkinterã‚’ä½¿ç”¨ã—ã€å››å‰‡æ¼”ç®—ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚",
            description="GUIé›»å“ã‚¢ãƒ—ãƒªé–‹ç™º"
        )
        
        print(f"ğŸ“ ã‚¿ã‚¹ã‚¯ä½œæˆ: {task_id}")
        
        # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
        result = await orchestrator.execute_task(task_id)
        
        print(f"\nğŸ¯ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœ:")
        print(f"   æˆåŠŸ: {result['success']}")
        print(f"   ç·æ™‚é–“: {result['total_time']:.2f}ç§’")
        if result['error']:
            print(f"   ã‚¨ãƒ©ãƒ¼: {result['error']}")
        
        # æœ€çµ‚ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        final_task = orchestrator.get_task_status(task_id)
        if final_task:
            print(f"\nğŸ“‹ æœ€çµ‚ã‚¿ã‚¹ã‚¯è©³ç´°:")
            print(f"   ID: {final_task.id}")
            print(f"   èª¬æ˜: {final_task.description}")
            print(f"   é€²æ—: {final_task.progress:.1f}%")
            print(f"   ç¾åœ¨ã‚¹ãƒ†ãƒƒãƒ—: {final_task.current_step.value}")
            print(f"   å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—: {list(final_task.results.keys())}")
        
        print("\nğŸ‰ ãƒ‡ãƒ¢å®Œäº†ï¼")
    
    asyncio.run(demo_orchestrator())
