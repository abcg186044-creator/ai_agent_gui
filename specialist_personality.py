"""
ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼ã‚·ã‚¹ãƒ†ãƒ 
Excel/PDFè§£æã¨å°‚é–€çŸ¥è­˜ã«åŸºã¥ãå›ç­”ã‚’æä¾›ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆäººæ ¼
"""

import os
import json
import requests
import tempfile
import hashlib
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import streamlit as st
import pandas as pd
from dataclasses import dataclass
import re

# Excel/PDFè§£æãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import openpyxl
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False

try:
    import fitz  # PyMuPDF
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

try:
    from sentence_transformers import SentenceTransformer
    import faiss
    import numpy as np
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False


@dataclass
class KnowledgeSource:
    """çŸ¥è­˜ã‚½ãƒ¼ã‚¹"""
    source_id: str
    source_type: str  # 'excel', 'pdf', 'web'
    source_path: str
    title: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None
    chunks: List[str] = None
    
    def __post_init__(self):
        if self.chunks is None:
            self.chunks = []


@dataclass
class PersonalityState:
    """äººæ ¼çŠ¶æ…‹"""
    name: str
    vrm_expression: str
    voice_character: str
    theme_colors: Dict[str, str]
    system_prompt: str


class SpecialistPersonality:
    """ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.name = "specialist_personality"
        self.description = "Excel/PDFå°‚é–€çŸ¥è­˜ã«åŸºã¥ãã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆäººæ ¼"
        
        # äººæ ¼å®šç¾©
        self.personalities = {
            "friend": PersonalityState(
                name="è¦ªå‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                vrm_expression="happy",
                voice_character="normal",
                theme_colors={"primary": "#4CAF50", "background": "#ffffff"},
                system_prompt="ã‚ãªãŸã¯è¦ªå‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦ã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã«ä¼šè©±ã—ã¾ã™ã€‚"
            ),
            "copy": PersonalityState(
                name="ã‚‚ã†ä¸€äººã®åƒ•",
                vrm_expression="joy",
                voice_character="similar",
                theme_colors={"primary": "#2196F3", "background": "#ffffff"},
                system_prompt="ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ†èº«ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨åŒã˜è¦–ç‚¹ã§è€ƒãˆã¾ã™ã€‚"
            ),
            "expert": PersonalityState(
                name="ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ",
                vrm_expression="neutral",
                voice_character="professional",
                theme_colors={"primary": "#9C27B0", "background": "#f3e5f5"},
                system_prompt="ã‚ãªãŸã¯å°‚é–€å®¶ã¨ã—ã¦ã€æä¾›ã•ã‚ŒãŸè³‡æ–™ã«åŸºã¥ãæ­£ç¢ºãªå›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚"
            )
        }
        
        self.current_personality = "friend"
        self.knowledge_sources: List[KnowledgeSource] = []
        self.rag_index = None
        self.embedding_model = None
        
        # åˆæœŸåŒ–
        self._initialize_rag()
        self._load_knowledge_sources()
    
    def _initialize_rag(self):
        """RAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        if RAG_AVAILABLE:
            try:
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                self.rag_index = faiss.IndexFlatL2(384)  # MiniLMã®æ¬¡å…ƒæ•°
            except Exception as e:
                st.warning(f"âš ï¸ RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
    
    def _load_knowledge_sources(self):
        """çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        # Xiãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰èª­ã¿è¾¼ã¿
        xi_path = Path("C:/Users/GALLE/Desktop/Xi")
        if xi_path.exists():
            self._load_from_directory(xi_path)
        
        # Webã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
        self._load_web_sources()
    
    def _load_from_directory(self, directory: Path):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        for file_path in directory.rglob("*"):
            if file_path.is_file():
                if file_path.suffix.lower() in ['.xlsx', '.xls']:
                    self._load_excel_file(file_path)
                elif file_path.suffix.lower() == '.pdf':
                    self._load_pdf_file(file_path)
    
    def _load_excel_file(self, file_path: Path):
        """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if not EXCEL_AVAILABLE:
            st.warning("âš ï¸ openpyxlãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
            with open(file_path, 'rb') as f:
                file_content = f.read()
            
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
            workbook = openpyxl.load_workbook(file_path, data_only=True)
            content_parts = []
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                content_parts.append(f"=== ã‚·ãƒ¼ãƒˆ: {sheet_name} ===")
                
                for row in sheet.iter_rows(values_only=True):
                    if any(cell is not None for cell in row):
                        row_text = "\t".join(str(cell) if cell is not None else "" for cell in row)
                        content_parts.append(row_text)
            
            content = "\n".join(content_parts)
            
            # çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ç™»éŒ²
            knowledge_source = KnowledgeSource(
                source_id=f"excel_{hashlib.md5(str(file_path).encode()).hexdigest()}",
                source_type="excel",
                source_path=str(file_path),
                title=file_path.name,
                content=content,
                metadata={
                    "file_size": len(file_content),
                    "sheets": workbook.sheetnames,
                    "last_modified": datetime.fromtimestamp(file_path.stat().st_mtime)
                }
            )
            
            self._add_knowledge_source(knowledge_source)
            
        except Exception as e:
            st.error(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path.name}): {e}")
    
    def _load_pdf_file(self, file_path: Path):
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if not PDF_AVAILABLE:
            st.warning("âš ï¸ PyMuPDFãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
            with open(file_path, 'rb') as f:
                file_content = f.read()
            
            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
            pdf_document = fitz.open(stream=file_content, filetype="pdf")
            content_parts = []
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                text = page.get_text()
                content_parts.append(f"=== ãƒšãƒ¼ã‚¸ {page_num + 1} ===")
                content_parts.append(text)
            
            content = "\n".join(content_parts)
            
            # çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ç™»éŒ²
            knowledge_source = KnowledgeSource(
                source_id=f"pdf_{hashlib.md5(str(file_path).encode()).hexdigest()}",
                source_type="pdf",
                source_path=str(file_path),
                title=file_path.name,
                content=content,
                metadata={
                    "file_size": len(file_content),
                    "pages": len(pdf_document),
                    "last_modified": datetime.fromtimestamp(file_path.stat().st_mtime)
                }
            )
            
            self._add_knowledge_source(knowledge_source)
            
        except Exception as e:
            st.error(f"âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path.name}): {e}")
    
    def _load_web_sources(self):
        """Webã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Webã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿
        config_file = Path("web_sources.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    web_sources = json.load(f)
                
                for source in web_sources:
                    self._load_web_source(source)
            except Exception as e:
                st.warning(f"âš ï¸ Webã‚½ãƒ¼ã‚¹è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _load_web_source(self, source_config: Dict[str, str]):
        """Webã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            url = source_config.get('url')
            if not url:
                return
            
            # URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            content_type = response.headers.get('content-type', '')
            
            if 'excel' in content_type or url.endswith(('.xlsx', '.xls')):
                # Excelãƒ•ã‚¡ã‚¤ãƒ«
                with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp_file:
                    tmp_file.write(response.content)
                    self._load_excel_file(Path(tmp_file.name))
                    os.unlink(tmp_file.name)
            
            elif 'pdf' in content_type or url.endswith('.pdf'):
                # PDFãƒ•ã‚¡ã‚¤ãƒ«
                with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
                    tmp_file.write(response.content)
                    self._load_pdf_file(Path(tmp_file.name))
                    os.unlink(tmp_file.name)
            
            else:
                # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                content = response.text
                knowledge_source = KnowledgeSource(
                    source_id=f"web_{hashlib.md5(url.encode()).hexdigest()}",
                    source_type="web",
                    source_path=url,
                    title=source_config.get('title', url),
                    content=content,
                    metadata={
                        "content_type": content_type,
                        "retrieved_at": datetime.now()
                    }
                )
                
                self._add_knowledge_source(knowledge_source)
                
        except Exception as e:
            st.error(f"âŒ Webã‚½ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({url}): {e}")
    
    def _add_knowledge_source(self, source: KnowledgeSource):
        """çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ """
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        source.chunks = self._chunk_text(source.content)
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        if self.embedding_model and RAG_AVAILABLE:
            try:
                embeddings = self.embedding_model.encode(source.chunks)
                source.embedding = embeddings
                
                # RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ 
                for i, embedding in enumerate(embeddings):
                    self.rag_index.add(np.array([embedding]))
            except Exception as e:
                st.warning(f"âš ï¸ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        self.knowledge_sources.append(source)
    
    def _chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # æ–‡ã®åŒºåˆ‡ã‚Šã§åˆ†å‰²
            if end < len(text):
                # æœ€å¾Œã®å¥ç‚¹ã‚„æ”¹è¡Œã‚’æ¢ã™
                for i in range(end, max(start + chunk_size // 2, start), -1):
                    if text[i] in ['ã€‚', '\n', '.', '\n\n']:
                        end = i + 1
                        break
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
        
        return chunks
    
    def switch_personality(self, personality: str) -> bool:
        """äººæ ¼ã‚’åˆ‡ã‚Šæ›¿ãˆ"""
        if personality in self.personalities:
            self.current_personality = personality
            
            # Web Canvasã«äººæ ¼å¤‰æ›´ã‚’é€šçŸ¥
            if hasattr(self, 'web_canvas') and self.web_canvas:
                self.web_canvas.update_personality(personality)
            
            return True
        return False
    
    def get_current_personality(self) -> PersonalityState:
        """ç¾åœ¨ã®äººæ ¼ã‚’å–å¾—"""
        return self.personalities[self.current_personality]
    
    def search_knowledge(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """çŸ¥è­˜ã‚’æ¤œç´¢"""
        if not self.knowledge_sources:
            return []
        
        results = []
        
        # RAGæ¤œç´¢
        if self.embedding_model and self.rag_index and RAG_AVAILABLE:
            try:
                query_embedding = self.embedding_model.encode([query])
                distances, indices = self.rag_index.search(query_embedding, top_k)
                
                for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                    if idx < len(self.knowledge_sources):
                        source = self.knowledge_sources[idx]
                        chunk_idx = idx % len(source.chunks)
                        
                        results.append({
                            "source": source,
                            "chunk": source.chunks[chunk_idx],
                            "score": float(1 / (1 + distance)),
                            "source_type": source.source_type,
                            "title": source.title
                        })
            except Exception as e:
                st.warning(f"âš ï¸ RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        if not results:
            for source in self.knowledge_sources:
                if query.lower() in source.content.lower():
                    results.append({
                        "source": source,
                        "chunk": source.content[:500] + "..." if len(source.content) > 500 else source.content,
                        "score": 0.8,
                        "source_type": source.source_type,
                        "title": source.title
                    })
        
        return results[:top_k]
    
    def generate_expert_response(self, query: str) -> str:
        """å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ"""
        if self.current_personality != "expert":
            return "ã“ã®æ©Ÿèƒ½ã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆäººæ ¼ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚"
        
        # çŸ¥è­˜æ¤œç´¢
        search_results = self.search_knowledge(query)
        
        if not search_results:
            return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€æä¾›ã•ã‚ŒãŸè³‡æ–™ã«ã¯è©²å½“ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # å›ç­”ç”Ÿæˆ
        response_parts = ["æä¾›ã•ã‚ŒãŸè³‡æ–™ã«åŸºã¥ãã¨ã€ä»¥ä¸‹ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š\n"]
        
        for i, result in enumerate(search_results, 1):
            response_parts.append(f"\n{i}. {result['title']} ({result['source_type']})")
            response_parts.append(f"   {result['chunk']}")
        
        return "\n".join(response_parts)
    
    def get_knowledge_stats(self) -> Dict[str, Any]:
        """çŸ¥è­˜ã‚½ãƒ¼ã‚¹çµ±è¨ˆ"""
        stats = {
            "total_sources": len(self.knowledge_sources),
            "source_types": {},
            "total_chunks": 0,
            "rag_enabled": RAG_AVAILABLE and self.embedding_model is not None
        }
        
        for source in self.knowledge_sources:
            source_type = source.source_type
            stats["source_types"][source_type] = stats["source_types"].get(source_type, 0) + 1
            stats["total_chunks"] += len(source.chunks)
        
        return stats
    
    def reload_knowledge(self):
        """çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’å†èª­ã¿è¾¼ã¿"""
        self.knowledge_sources.clear()
        if self.rag_index:
            self.rag_index.reset()
        
        self._load_knowledge_sources()
    
    def run(self, command: str) -> str:
        """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ"""
        if command.startswith("switch "):
            personality = command[7:]
            if self.switch_personality(personality):
                current = self.get_current_personality()
                return f"äººæ ¼ã‚’ã€Œ{current.name}ã€ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ"
            else:
                return f"äººæ ¼ã€Œ{personality}ã€ã¯å­˜åœ¨ã—ã¾ã›ã‚“"
        
        elif command == "status":
            current = self.get_current_personality()
            stats = self.get_knowledge_stats()
            return f"ç¾åœ¨ã®äººæ ¼: {current.name}\nçŸ¥è­˜ã‚½ãƒ¼ã‚¹æ•°: {stats['total_sources']}\nRAGæœ‰åŠ¹: {stats['rag_enabled']}"
        
        elif command == "reload":
            self.reload_knowledge()
            return "çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ"
        
        elif command.startswith("search "):
            query = command[7:]
            results = self.search_knowledge(query)
            if results:
                response = f"æ¤œç´¢çµæœ ({len(results)}ä»¶):\n"
                for i, result in enumerate(results, 1):
                    response += f"{i}. {result['title']} - ã‚¹ã‚³ã‚¢: {result['score']:.2f}\n"
                return response
            else:
                return "æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        else:
            return "ã‚³ãƒãƒ³ãƒ‰å½¢å¼: switch [äººæ ¼], status, reload, search [ã‚¯ã‚¨ãƒª]"


class SpecialistPersonalityGUI:
    """ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼GUI"""
    
    def __init__(self, specialist: SpecialistPersonality):
        self.specialist = specialist
    
    def render(self):
        """GUIã‚’æç”»"""
        st.subheader("ğŸ§  ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼")
        
        # äººæ ¼é¸æŠ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ‘¥ è¦ªå‹", type="primary" if self.specialist.current_personality == "friend" else "secondary"):
                self.specialist.switch_personality("friend")
                st.rerun()
        
        with col2:
            if st.button("ğŸª åˆ†èº«", type="primary" if self.specialist.current_personality == "copy" else "secondary"):
                self.specialist.switch_personality("copy")
                st.rerun()
        
        with col3:
            if st.button("ğŸ§‘â€ğŸ« ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ", type="primary" if self.specialist.current_personality == "expert" else "secondary"):
                self.specialist.switch_personality("expert")
                st.rerun()
        
        # ç¾åœ¨ã®äººæ ¼è¡¨ç¤º
        current = self.specialist.get_current_personality()
        st.info(f"ğŸ­ ç¾åœ¨ã®äººæ ¼: **{current.name}**")
        
        # çŸ¥è­˜ã‚½ãƒ¼ã‚¹çµ±è¨ˆ
        stats = self.specialist.get_knowledge_stats()
        
        st.write("**ğŸ“š çŸ¥è­˜ã‚½ãƒ¼ã‚¹çµ±è¨ˆ:**")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·ã‚½ãƒ¼ã‚¹æ•°", stats["total_sources"])
        
        with col2:
            st.metric("ç·ãƒãƒ£ãƒ³ã‚¯æ•°", stats["total_chunks"])
        
        with col3:
            st.metric("RAGæœ‰åŠ¹", "âœ…" if stats["rag_enabled"] else "âŒ")
        
        with col4:
            st.metric("Excel", stats["source_types"].get("excel", 0))
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—è©³ç´°
        if stats["source_types"]:
            st.write("**ğŸ“‚ ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—å†…è¨³:**")
            for source_type, count in stats["source_types"].items():
                st.write(f"- {source_type}: {count}å€‹")
        
        # çŸ¥è­˜æ¤œç´¢
        st.write("**ğŸ” çŸ¥è­˜æ¤œç´¢:**")
        search_query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒª", key="specialist_search")
        
        if st.button("ğŸ” æ¤œç´¢") and search_query:
            with st.spinner("çŸ¥è­˜ã‚’æ¤œç´¢ä¸­..."):
                results = self.specialist.search_knowledge(search_query)
                
                if results:
                    st.success(f"âœ… {len(results)}ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    
                    for i, result in enumerate(results, 1):
                        with st.expander(f"çµæœ {i}: {result['title']} (ã‚¹ã‚³ã‚¢: {result['score']:.2f})", expanded=False):
                            st.write(f"**ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—:** {result['source_type']}")
                            st.write(f"**å†…å®¹:** {result['chunk']}")
                else:
                    st.warning("âš ï¸ æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # å†èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’å†èª­ã¿è¾¼ã¿"):
            with st.spinner("å†èª­ã¿è¾¼ã¿ä¸­..."):
                self.specialist.reload_knowledge()
                st.success("âœ… çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
                st.rerun()


def create_specialist_gui(specialist: SpecialistPersonality):
    """ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆGUIã‚’ä½œæˆ"""
    gui = SpecialistPersonalityGUI(specialist)
    gui.render()


# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def create_specialist_personality() -> SpecialistPersonality:
    """ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼ã‚’ä½œæˆ"""
    return SpecialistPersonality()


# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯"""
    missing = []
    
    if not EXCEL_AVAILABLE:
        missing.append("openpyxl")
    
    if not PDF_AVAILABLE:
        missing.append("PyMuPDF")
    
    if not RAG_AVAILABLE:
        missing.extend(["sentence-transformers", "faiss-cpu", "numpy"])
    
    return missing


if __name__ == "__main__":
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    missing_deps = check_dependencies()
    if missing_deps:
        print(f"âš ï¸ ä¸è¶³ã—ã¦ã„ã‚‹ä¾å­˜é–¢ä¿‚: {', '.join(missing_deps)}")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰:")
        print(f"pip install {' '.join(missing_deps)}")
    else:
        print("âœ… ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã™")
        
        # ãƒ†ã‚¹ãƒˆ
        specialist = create_specialist_personality()
        print(f"ğŸ§  ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆäººæ ¼åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“š çŸ¥è­˜ã‚½ãƒ¼ã‚¹æ•°: {len(specialist.knowledge_sources)}")
