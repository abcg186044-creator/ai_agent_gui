# AI Agent System - å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## ðŸš€ ã‚¼ãƒ­ã‹ã‚‰æ§‹ç¯‰æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒæ§‹ç¯‰ (15åˆ†)

#### 1.1 Pythonç’°å¢ƒæº–å‚™
```bash
# Python 3.10+ ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã‹ç¢ºèª
python --version

# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv ai_agent_env

# ç’°å¢ƒæœ‰åŠ¹åŒ–
# Windows
ai_agent_env\Scripts\activate
# macOS/Linux  
source ai_agent_env/bin/activate
```

#### 1.2 å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# requirements.txt ä½œæˆ
cat > requirements.txt << 'EOF'
streamlit==1.28.1
langchain==0.1.0
langchain-community==0.0.4
langchain-ollama==0.1.1
langchain-experimental==0.4.1
openai-whisper==20231117
faster-whisper==0.9.0
pydub==0.25.1
sounddevice==0.4.6
numpy==1.24.3
opencv-python==4.8.1.78
Pillow==10.4.0
python-dotenv==1.0.0
requests==2.32.5
beautifulsoup4==4.12.2
selenium==4.15.2
pyautogui==0.9.54
pynput==1.7.6
openpyxl==3.1.2
PyMuPDF==1.23.8
sentence-transformers==2.2.2
faiss-cpu==1.7.4
qrcode[pil]==7.4.2
fastapi==0.128.0
uvicorn==0.40.0
pyttsx3==2.99
pandas==2.1.0
torch==2.1.0
librosa==0.10.1
scipy==1.11.4
matplotlib==3.7.2
plotly==5.17.0
tiktoken==0.7.0
chromadb==0.4.22
transformers==4.36.0
pygame==2.5.2
psutil==5.9.6
EOF

# ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

#### 1.3 Ollamaã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# Windows (winget)
winget install Ollama.Ollama

# macOS (Homebrew)
brew install ollama

# Linux (curl)
curl -fsSL https://ollama.com/install.sh | sh

# Ollamaã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
ollama serve
```

#### 1.4 PHPã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# Windows (winget)
winget install PHP.PHP.8.4

# macOS (Homebrew)
brew install php

# Linux (apt)
sudo apt update && sudo apt install php-cli

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
php --version
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«æº–å‚™ (10åˆ†)

#### 2.1 LLMãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
```bash
# ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ« (4.9GB)
ollama pull llama3.1:8b

# åŸ‹ã‚è¾¼ã¿ç”¨ãƒ¢ãƒ‡ãƒ« (274MB)
ollama pull nomic-embed-text:latest

# ç¢ºèª
ollama list
```

#### 2.2 VRMã‚¢ãƒã‚¿ãƒ¼æº–å‚™
```bash
# staticãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p static

# VRMãƒ•ã‚¡ã‚¤ãƒ«é…ç½® (æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼)
# copy path/to/avatar.vrm static/avatar.vrm
```

### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹ç¯‰ (30åˆ†)

#### 3.1 åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
```bash
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
touch app.py

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
touch .env
touch memory_db.json

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ
mkdir -p knowledge_base/documents
mkdir -p logs
mkdir -p temp
mkdir -p backups
```

#### 3.2 ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…
```python
# 1. app.py åŸºæœ¬æ§‹é€ 
import streamlit as st
import os
import json
from datetime import datetime

# åŸºæœ¬è¨­å®š
st.set_page_config(
    page_title="AI Agent System",
    page_icon="ðŸ¤–",
    layout="wide"
)

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    st.title("ðŸ¤– AI Agent System")
    st.write("ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ä¸­...")

if __name__ == "__main__":
    main()
```

#### 3.3 åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ
```bash
# èµ·å‹•ãƒ†ã‚¹ãƒˆ
streamlit run app.py

# ã‚¨ãƒ©ãƒ¼ç¢ºèª
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8501 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

### ã‚¹ãƒ†ãƒƒãƒ—4: AIæ©Ÿèƒ½å®Ÿè£… (60åˆ†)

#### 4.1 Ollamaé€£æº
```python
# ollama_integration.py
import ollama

class OllamaManager:
    def __init__(self):
        self.client = ollama.Client()
        self.model = "llama3.1:8b"
    
    def generate_response(self, prompt: str) -> str:
        response = self.client.generate(
            model=self.model,
            prompt=prompt,
            options={
                "temperature": 0.7,
                "max_tokens": 4096
            }
        )
        return response['response']
```

#### 4.2 éŸ³å£°å‡¦ç†
```python
# voice_processor.py
import faster_whisper
import pyttsx3

class VoiceProcessor:
    def __init__(self):
        self.whisper_model = faster_whisper.WhisperModel("base")
        self.tts_engine = pyttsx3.init()
    
    def speech_to_text(self, audio_file: str) -> str:
        result = self.whisper_model.transcribe(audio_file)
        return result["text"]
    
    def text_to_speech(self, text: str):
        self.tts_engine.say(text)
        self.tts_engine.runAndWait()
```

#### 4.3 äººæ ¼ã‚·ã‚¹ãƒ†ãƒ 
```python
# personality_manager.py
from enum import Enum

class Personality(Enum):
    FRIEND = "friend"
    COPY = "copy" 
    EXPERT = "expert"

class PersonalityManager:
    def __init__(self):
        self.current = Personality.FRIEND
        self.traits = {
            Personality.FRIEND: {
                "name": "è¦ªå‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                "vrm_expression": "happy",
                "voice": "normal",
                "theme": {"primary": "#4CAF50"}
            },
            Personality.COPY: {
                "name": "åˆ†èº«",
                "vrm_expression": "joy", 
                "voice": "similar",
                "theme": {"primary": "#2196F3"}
            },
            Personality.EXPERT: {
                "name": "ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ",
                "vrm_expression": "neutral",
                "voice": "professional", 
                "theme": {"primary": "#9C27B0"}
            }
        }
```

### ã‚¹ãƒ†ãƒƒãƒ—5: é«˜åº¦æ©Ÿèƒ½å®Ÿè£… (45åˆ†)

#### 5.1 çŸ¥è­˜æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
```python
# knowledge_system.py
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class KnowledgeSystem:
    def __init__(self):
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        self.index = faiss.IndexFlatL2(384)
        self.documents = []
    
    def add_document(self, text: str, metadata: dict):
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = self.chunk_text(text)
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embeddings = self.encoder.encode(chunks)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
        for i, embedding in enumerate(embeddings):
            self.index.add(np.array([embedding]))
            self.documents.append({
                "text": chunks[i],
                "metadata": metadata
            })
    
    def search(self, query: str, top_k: int = 5):
        query_embedding = self.encoder.encode([query])
        distances, indices = self.index.search(query_embedding, top_k)
        
        results = []
        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
            results.append({
                "document": self.documents[idx],
                "score": float(1 / (1 + distance))
            })
        
        return results
```

#### 5.2 æ¤œè¨¼ãƒ—ãƒ­ãƒˆã‚³ãƒ«
```python
# verification_protocols.py
import ast
import subprocess
import tempfile

class VerificationProtocols:
    def __init__(self):
        self.max_iterations = 3
    
    def verify_code(self, code: str, language: str = "python"):
        current_code = code
        
        for iteration in range(self.max_iterations):
            # é™çš„è§£æž
            try:
                ast.parse(current_code)
            except SyntaxError as e:
                current_code = self.fix_syntax_error(current_code, str(e))
                continue
            
            # å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(current_code)
                temp_file = f.name
            
            result = subprocess.run(['python', temp_file], capture_output=True, text=True)
            
            if result.returncode == 0:
                return {
                    "success": True,
                    "final_code": current_code,
                    "iterations": iteration + 1,
                    "output": result.stdout
                }
            
            # ã‚¨ãƒ©ãƒ¼ä¿®æ­£
            current_code = self.fix_runtime_error(current_code, result.stderr)
        
        return {
            "success": False,
            "final_code": current_code,
            "iterations": self.max_iterations,
            "errors": ["æœ€å¤§åå¾©å›žæ•°åˆ°é”"]
        }
```

### ã‚¹ãƒ†ãƒƒãƒ—6: UIå®Ÿè£… (30åˆ†)

#### 6.1 Streamlitãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
```python
# app.py UIå®Ÿè£…
def main():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ðŸ¤– AI Agent Control")
        
        # äººæ ¼é¸æŠž
        personality = st.selectbox(
            "äººæ ¼é¸æŠž",
            ["è¦ªå‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "åˆ†èº«", "ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ"],
            key="personality"
        )
        
        # è¨ºæ–­ãƒœã‚¿ãƒ³
        if st.button("ðŸ” èµ·å‹•æ™‚è¨ºæ–­"):
            run_startup_diagnostic()
        
        if st.button("ðŸ”§ ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"):
            test_code_verification()
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ðŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        # ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…
        
    with col2:
        st.header("ðŸ¤– VRMã‚¢ãƒã‚¿ãƒ¼")
        # VRMè¡¨ç¤ºå®Ÿè£…
```

#### 6.2 Web Canvasãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
```python
# web_canvas.py
def render_web_canvas():
    st.subheader("ðŸŽ¨ Web Canvas Preview")
    
    # ã‚¨ãƒ‡ã‚£ã‚¿ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ‡ã‚£ã‚¿
        html_code = st.text_area("HTML", height=300, key="html")
        css_code = st.text_area("CSS", height=300, key="css") 
        js_code = st.text_area("JavaScript", height=300, key="js")
    
    with col2:
        # ãƒ©ã‚¤ãƒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if st.button("ðŸ”„ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°"):
            update_preview(html_code, css_code, js_code)
        
        st.components.v1.iframe(
            src="http://localhost:8001/preview",
            height=600,
            width=400
        )
```

### ã‚¹ãƒ†ãƒƒãƒ—7: çµ±åˆãƒ†ã‚¹ãƒˆ (20åˆ†)

#### 7.1 æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
```python
# test_integration.py
import unittest

class TestAIIntegration(unittest.TestCase):
    def test_ollama_connection(self):
        # OllamaæŽ¥ç¶šãƒ†ã‚¹ãƒˆ
        pass
    
    def test_voice_processing(self):
        # éŸ³å£°å‡¦ç†ãƒ†ã‚¹ãƒˆ
        pass
    
    def test_personality_switch(self):
        # äººæ ¼åˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ
        pass
    
    def test_knowledge_search(self):
        # çŸ¥è­˜æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        pass
    
    def test_code_verification(self):
        # ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
        pass

if __name__ == "__main__":
    unittest.main()
```

#### 7.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
```python
# performance_test.py
import time
import psutil

def measure_response_time():
    start_time = time.time()
    # LLMæŽ¨è«–ãƒ†ã‚¹ãƒˆ
    end_time = time.time()
    return end_time - start_time

def measure_memory_usage():
    return psutil.virtual_memory().percent

def run_performance_suite():
    tests = [
        ("LLMå¿œç­”æ™‚é–“", measure_response_time),
        ("ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŽ‡", measure_memory_usage),
        ("éŸ³å£°èªè­˜é€Ÿåº¦", measure_speech_processing),
        ("çŸ¥è­˜æ¤œç´¢é€Ÿåº¦", measure_search_performance)
    ]
    
    for test_name, test_func in tests:
        result = test_func()
        print(f"{test_name}: {result}")
```

### ã‚¹ãƒ†ãƒƒãƒ—8: æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ (15åˆ†)

#### 8.1 æœ¬ç•ªç’°å¢ƒè¨­å®š
```bash
# æœ¬ç•ªç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
cat > .env.production << 'EOF'
ENVIRONMENT=production
OLLAMA_MODEL=llama3.1:8b
LOG_LEVEL=INFO
MAX_CONCURRENT_USERS=10
EOF

# æœ¬ç•ªèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat > start_production.py << 'EOF'
import uvicorn
from app import app

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        workers=4,
        log_level="info"
    )
EOF
```

#### 8.2 ã‚µãƒ¼ãƒ“ã‚¹åŒ–
```bash
# Windowsã‚µãƒ¼ãƒ“ã‚¹
# sc create AI-Agent binPath=python start= start_production.py

# Linux systemd
sudo tee /etc/systemd/ai-agent.service > /dev/null <<EOF
[Unit]
Description=AI Agent Service
After=network.target

[Service]
Type=simple
User=ai-agent
WorkingDirectory=/path/to/ai-agent
ExecStart=/path/to/ai-agent/venv/bin/python start_production.py
Restart=always

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable ai-agent
sudo systemctl start ai-agent
```

---

## ðŸŽ¯ å®Œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### âœ… åŸºæœ¬æ©Ÿèƒ½
- [ ] Python 3.10+ ç’°å¢ƒ
- [ ] å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªå…¨ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- [ ] Ollama llama3.1:8b ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½
- [ ] PHP 8.5+ å®Ÿè¡Œç’°å¢ƒ
- [ ] Streamlit UI èµ·å‹•
- [ ] FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰èµ·å‹•

### âœ… AIæ©Ÿèƒ½
- [ ] LLMæŽ¨è«–æ©Ÿèƒ½
- [ ] éŸ³å£°èªè­˜æ©Ÿèƒ½
- [ ] éŸ³å£°åˆæˆæ©Ÿèƒ½
- [ ] 3äººæ ¼åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½
- [ ] çŸ¥è­˜æ¤œç´¢æ©Ÿèƒ½
- [ ] ã‚³ãƒ¼ãƒ‰è‡ªå‹•æ¤œè¨¼æ©Ÿèƒ½

### âœ… é«˜åº¦æ©Ÿèƒ½
- [ ] VRMã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤º
- [ ] Web Canvasãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] èµ·å‹•æ™‚è‡ªå·±è¨ºæ–­
- [ ] Excel/PDFè§£æžæ©Ÿèƒ½
- [ ] RAGæ¤œç´¢æ©Ÿèƒ½
- [ ] ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºæ©Ÿèƒ½

### âœ… å“è³ªä¿è¨¼
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆå®Ÿæ–½
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿæ–½
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ¸¬å®š
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
- [ ] ãƒ­ã‚°å‡ºåŠ›å®Ÿè£…
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–å®Ÿè£…

---

## ðŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

| å•é¡Œ | åŽŸå›  | è§£æ±ºç­– |
|------|------|--------|
| `ImportError` | ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | `pip install [ãƒ©ã‚¤ãƒ–ãƒ©ãƒª]` |
| `OllamaæŽ¥ç¶šã‚¨ãƒ©ãƒ¼` | ã‚µãƒ¼ãƒ“ã‚¹æœªèµ·å‹• | `ollama serve` å®Ÿè¡Œ |
| `éŸ³å£°èªè­˜ã•ã‚Œãªã„` | ãƒžã‚¤ã‚¯æœªè¨±å¯ | OSã®ãƒžã‚¤ã‚¯è¨­å®šç¢ºèª |
| `VRMè¡¨ç¤ºã•ã‚Œãªã„` | ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹é–“é•ã„ | `./static/avatar.vrm` ç¢ºèª |
| `ãƒ¡ãƒ¢ãƒªä¸è¶³` | å¤§å®¹é‡ãƒ¢ãƒ‡ãƒ« | llama3.1:8b ä½¿ç”¨ |
| `PHPå®Ÿè¡Œã‚¨ãƒ©ãƒ¼` | PATHæœªè¨­å®š | ç’°å¢ƒå¤‰æ•°PATHç¢ºèª |

---

## ðŸ“ž ã‚µãƒãƒ¼ãƒˆ

### ðŸ“§ æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«docstringå‚ç…§
- **ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°**: `./logs/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
- **ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰**: `DEBUG=True` ç’°å¢ƒå¤‰æ•°è¨­å®š

### ðŸ”§ é–‹ç™ºãƒ„ãƒ¼ãƒ«
- **IDE**: VS Code + Pythonæ‹¡å¼µæ©Ÿèƒ½
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: Git + GitHub
- **ãƒ†ã‚¹ãƒˆ**: pytest + unittest
- **ãƒ‡ãƒãƒƒã‚°**: pdb + logging

---

*ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã†ã“ã¨ã§ã€ç´„3æ™‚é–“ã§å®Œå…¨ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚*
