#!/usr/bin/env python3
"""
Voice-Fixed AI Agent - éŸ³å£°åˆæˆä¿®æ­£ç‰ˆ
"""

import streamlit as st
import time
import threading
import numpy as np
import requests
import json
import queue
import tempfile
import wave
import os
import sys
import importlib
import socket
import subprocess
from urllib.parse import urlparse

# ä¿®æ­£ç‰ˆå‹•çš„ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append('/app/scripts')
try:
    from dynamic_installer_fixed import install_package, auto_install_missing_packages, DynamicInstallerFixed
except ImportError:
    st.error("âŒ ä¿®æ­£ç‰ˆå‹•çš„ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    sys.exit(1)

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•çš„ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
def install_required_packages_fixed():
    pytorch_packages = {
        'torch': '2.1.0',
        'torchaudio': '2.1.0',
        'torchvision': '0.16.0'
    }
    
    other_packages = [
        'sounddevice',
        'faster-whisper',
        'pyttsx3'
    ]
    
    installer = DynamicInstallerFixed()
    
    # PyTorchãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç‰¹åˆ¥å‡¦ç† - ã¾ã¨ã‚ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    st.info("ğŸ”§ Checking PyTorch packages...")
    pytorch_success = True
    
    for package, version in pytorch_packages.items():
        try:
            import_name = package.replace('-', '_')
            importlib.import_module(import_name)
            st.success(f"âœ… {package} is already installed")
        except ImportError:
            st.info(f"ğŸ“¦ Installing {package}=={version}...")
            success, message = installer.install_package(package, version, force_version=True)
            if success:
                st.success(f"âœ… {message}")
            else:
                st.error(f"âŒ {message}")
                pytorch_success = False
    
    # PyTorchãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª
    if pytorch_success:
        st.info("ğŸ” Verifying PyTorch packages...")
        importlib.invalidate_caches()  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        
        for package in pytorch_packages.keys():
            try:
                import_name = package.replace('-', '_')
                importlib.import_module(import_name)
                st.success(f"âœ… {package} imported successfully")
            except ImportError as e:
                st.error(f"âŒ Failed to import {package}: {e}")
                # PyTorchç«¶åˆè§£æ±ºã‚’è©¦è¡Œ
                st.info("ğŸ”§ Attempting to resolve PyTorch conflicts...")
                success, module = installer.handle_pytorch_conflict(package)
                if success:
                    st.success(f"âœ… {package} conflict resolved")
                else:
                    st.error(f"âŒ Failed to resolve {package} conflict")
                    return False
    
    # ãã®ä»–ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    for package in other_packages:
        try:
            importlib.import_module(package)
            st.success(f"âœ… {package} is already installed")
        except ImportError:
            st.info(f"ğŸ“¦ Installing {package}...")
            success, message = installer.install_package(package)
            if success:
                st.success(f"âœ… {message}")
            else:
                st.error(f"âŒ {message}")
                return False
    
    return True

if not install_required_packages_fixed():
    st.error("âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
    st.stop()

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
def safe_import_with_retry(package_name, import_name=None, max_retries=3):
    if import_name is None:
        import_name = package_name.replace('-', '_')
    
    for attempt in range(max_retries):
        try:
            module = importlib.import_module(import_name)
            print(f"âœ… {package_name} imported successfully")
            return module
        except ImportError as e:
            if attempt < max_retries - 1:
                print(f"âš ï¸ {package_name} import failed, retrying... ({attempt + 1}/{max_retries})")
                time.sleep(1)
                importlib.invalidate_caches()
            else:
                st.error(f"âŒ {package_name}ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return None

try:
    sounddevice = safe_import_with_retry('sounddevice', 'sd')
    if sounddevice is None:
        st.error("âŒ sounddeviceã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
except Exception as e:
    st.error(f"âŒ sounddeviceã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

try:
    faster_whisper = safe_import_with_retry('faster-whisper', 'faster_whisper')
    if faster_whisper is None:
        st.error("âŒ faster-whisperã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
except Exception as e:
    st.error(f"âŒ faster-whisperã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

try:
    torch = safe_import_with_retry('torch', 'torch')
    if torch is None:
        st.error("âŒ torchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
except Exception as e:
    st.error(f"âŒ torchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

try:
    torchaudio = safe_import_with_retry('torchaudio', 'torchaudio')
    if torchaudio is None:
        st.error("âŒ torchaudioã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
except Exception as e:
    st.error(f"âŒ torchaudioã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

# è¨­å®š
class Config:
    MAIN_MODEL = "llama3.2"
    WHISPER_MODEL = "large-v3"
    AUDIO_SAMPLE_RATE = 16000
    AUDIO_CHANNELS = 1
    AUDIO_FORMAT = "int16"
    VAD_SILENCE_THRESHOLD = 0.5
    MIN_SPEECH_DURATION = 2.0
    MAX_PAUSE_DURATION = 2.0
    BUFFER_TIMEOUT = 5.0
    NODDING_INTERVAL = 1.0

class VoiceSynthesizer:
    """éŸ³å£°åˆæˆã‚¯ãƒ©ã‚¹ - è¤‡æ•°ã‚¨ãƒ³ã‚¸ãƒ³å¯¾å¿œ"""
    
    def __init__(self):
        self.engines = {}
        self.current_engine = None
        self._initialize_engines()
    
    def _initialize_engines(self):
        """éŸ³å£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–"""
        # pyttsx3ã‚¨ãƒ³ã‚¸ãƒ³
        try:
            import pyttsx3
            self.engines['pyttsx3'] = pyttsx3.init()
            self.engines['pyttsx3'].setProperty('rate', 150)
            self.engines['pyttsx3'].setProperty('volume', 0.9)
            print("âœ… pyttsx3 engine initialized")
        except Exception as e:
            print(f"âŒ pyttsx3 initialization failed: {e}")
        
        # VOICEVOXã‚¨ãƒ³ã‚¸ãƒ³
        try:
            self.engines['voicevox'] = {
                'url': 'http://voicevox:50021',
                'available': False
            }
            # VOICEVOXã®æ¥ç¶šãƒ†ã‚¹ãƒˆ
            response = requests.get(f"{self.engines['voicevox']['url']}/docs", timeout=5)
            if response.status_code == 200:
                self.engines['voicevox']['available'] = True
                print("âœ… VOICEVOX engine initialized")
            else:
                print("âŒ VOICEVOX not available")
        except Exception as e:
            print(f"âŒ VOICEVOX initialization failed: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’è¨­å®š
        if self.engines.get('voicevox', {}).get('available'):
            self.current_engine = 'voicevox'
        elif 'pyttsx3' in self.engines:
            self.current_engine = 'pyttsx3'
        else:
            self.current_engine = None
    
    def get_available_engines(self):
        """åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—"""
        available = {}
        for name, engine in self.engines.items():
            if name == 'voicevox':
                available[name] = engine.get('available', False)
            else:
                available[name] = engine is not None
        return available
    
    def set_engine(self, engine_name):
        """éŸ³å£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’è¨­å®š"""
        if engine_name in self.engines:
            if engine_name == 'voicevox':
                if self.engines['voicevox']['available']:
                    self.current_engine = engine_name
                    return True
            else:
                if self.engines[engine_name] is not None:
                    self.current_engine = engine_name
                    return True
        return False
    
    def synthesize(self, text):
        """éŸ³å£°ã‚’åˆæˆ"""
        if not self.current_engine:
            return False, "No available TTS engine"
        
        try:
            if self.current_engine == 'pyttsx3':
                return self._synthesize_pyttsx3(text)
            elif self.current_engine == 'voicevox':
                return self._synthesize_voicevox(text)
            else:
                return False, "Unknown TTS engine"
        except Exception as e:
            return False, f"TTS error: {str(e)}"
    
    def _synthesize_pyttsx3(self, text):
        """pyttsx3ã§éŸ³å£°åˆæˆ"""
        try:
            engine = self.engines['pyttsx3']
            engine.say(text)
            engine.runAndWait()
            return True, "pyttsx3 synthesis completed"
        except Exception as e:
            return False, f"pyttsx3 error: {str(e)}"
    
    def _synthesize_voicevox(self, text):
        """VOICEVOXã§éŸ³å£°åˆæˆ"""
        try:
            # éŸ³å£°åˆæˆã‚¯ã‚¨ãƒª
            query_response = requests.post(
                f"{self.engines['voicevox']['url']}/audio_query",
                params={
                    'text': text,
                    'speaker': 0
                },
                timeout=10
            )
            
            if query_response.status_code != 200:
                return False, f"VOICEVOX query failed: {query_response.status_code}"
            
            # éŸ³å£°åˆæˆ
            audio_response = requests.post(
                f"{self.engines['voicevox']['url']}/synthesis",
                json=query_response.json(),
                timeout=30
            )
            
            if audio_response.status_code != 200:
                return False, f"VOICEVOX synthesis failed: {audio_response.status_code}"
            
            # éŸ³å£°ã‚’å†ç”Ÿ
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_file.write(audio_response.content)
                tmp_file.flush()
                
                # éŸ³å£°å†ç”Ÿ
                try:
                    subprocess.run(['aplay', tmp_file.name], check=True, timeout=30)
                    return True, "VOICEVOX synthesis completed"
                except subprocess.CalledProcessError as e:
                    return False, f"Audio playback failed: {str(e)}"
                finally:
                    os.unlink(tmp_file.name)
                    
        except Exception as e:
            return False, f"VOICEVOX error: {str(e)}"

class NetworkAwareAIAgent:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯¾å¿œAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.base_urls = []
        self.current_url_index = 0
        self.timeout = 30
        self.max_retries = 3
        self._initialize_urls()
    
    def _initialize_urls(self):
        self.base_urls.append("http://ollama:11434")
        host_ip = os.getenv('HOST_IP', 'localhost')
        self.base_urls.append(f"http://{host_ip}:11434")
        self.base_urls.append("http://localhost:11434")
        
        try:
            host_ip = self._get_host_ip()
            if host_ip and host_ip not in [url.split('//')[1].split(':')[0] for url in self.base_urls]:
                self.base_urls.append(f"http://{host_ip}:11434")
        except:
            pass
    
    def _get_host_ip(self):
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            host_ip = s.getsockname()[0]
            s.close()
            return host_ip
        except:
            return None
    
    def _test_connection(self, url):
        try:
            response = requests.get(f"{url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _get_working_url(self):
        if hasattr(self, '_last_working_url') and self._test_connection(self._last_working_url):
            return self._last_working_url
        
        for url in self.base_urls:
            if self._test_connection(url):
                self._last_working_url = url
                return url
        
        return None
    
    def generate_response(self, prompt, model="llama3.2"):
        working_url = self._get_working_url()
        
        if not working_url:
            return "âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚"
        
        for attempt in range(self.max_retries):
            try:
                data = {
                    "model": model,
                    "prompt": prompt,
                    "stream": False
                }
                
                response = requests.post(
                    f"{working_url}/api/generate",
                    json=data,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result.get('response', '')
                else:
                    if attempt < self.max_retries - 1:
                        working_url = self._get_working_url()
                        if not working_url:
                            break
                    else:
                        return f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}"
                        
            except requests.exceptions.ConnectionError:
                if attempt < self.max_retries - 1:
                    working_url = self._get_working_url()
                    if not working_url:
                        break
                    time.sleep(1)
                else:
                    return "âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            except Exception as e:
                return f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        return "âŒ ã™ã¹ã¦ã®æ¥ç¶šè©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸã€‚"

class SmartVoiceBuffer:
    """ã‚¹ãƒãƒ¼ãƒˆéŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.is_active = False
        self.audio_buffer = []
        self.speech_segments = []
        self.last_speech_end = None
        self.current_segment_start = None
        self.total_duration = 0.0
        
    def start_segment(self):
        self.current_segment_start = time.time()
        
    def end_segment(self):
        if self.current_segment_start:
            duration = time.time() - self.current_segment_start
            if duration >= Config.MIN_SPEECH_DURATION:
                self.speech_segments.append({
                    "start": self.current_segment_start,
                    "end": time.time(),
                    "duration": duration,
                    "audio_data": self.audio_buffer.copy()
                })
                self.total_duration += duration
            
            self.last_speech_end = time.time()
            self.current_segment_start = None
            self.audio_buffer = []
    
    def add_audio_data(self, audio_data):
        self.audio_buffer.extend(audio_data)
    
    def should_process_speech(self):
        if not self.speech_segments:
            return False
        
        if self.last_speech_end:
            time_since_last_speech = time.time() - self.last_speech_end
            return time_since_last_speech >= Config.MAX_PAUSE_DURATION
        
        return False
    
    def get_combined_audio(self):
        if not self.speech_segments:
            return None
        
        combined_audio = []
        for segment in self.speech_segments:
            combined_audio.extend(segment["audio_data"])
        
        return combined_audio
    
    def reset(self):
        self.speech_segments = []
        self.audio_buffer = []
        self.last_speech_end = None
        self.current_segment_start = None
        self.total_duration = 0.0

class SmartVoiceInputHandler:
    """ã‚¹ãƒãƒ¼ãƒˆéŸ³å£°å…¥åŠ›ãƒãƒ³ãƒ‰ãƒ©"""
    
    def __init__(self):
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.whisper_model = None
        self.vad_model = None
        self.voice_buffer = SmartVoiceBuffer()
        self.processing_thread = None
        
    def initialize(self):
        try:
            self.whisper_model = faster_whisper.WhisperModel(
                Config.WHISPER_MODEL,
                device="cuda" if self._check_cuda() else "cpu",
                compute_type="float32"
            )
            
            try:
                self.vad_model, utils = torch.hub.load(
                    'snakers4/silero-vad',
                    'silero_vad',
                    force_reload=True
                )
                self.vad_utils = utils
            except Exception as vad_error:
                st.warning(f"âš ï¸ VADãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {vad_error}")
                self.vad_model = None
            
            return True
        except Exception as e:
            st.error(f"âŒ éŸ³å£°å…¥åŠ›ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _check_cuda(self):
        try:
            return torch.cuda.is_available()
        except:
            return False
    
    def start_recording(self):
        if self.is_recording:
            return False
        
        self.is_recording = True
        self.voice_buffer.reset()
        
        def audio_callback(indata, frame_count, time_info, status):
            if status:
                st.error(f"âŒ éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {status}")
            self.audio_queue.put(indata.copy())
        
        try:
            self.processing_thread = threading.Thread(
                target=self._smart_record_audio,
                args=(audio_callback,),
                daemon=True
            )
            self.processing_thread.start()
            return True
        except Exception as e:
            st.error(f"âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.is_recording = False
            return False
    
    def _smart_record_audio(self, callback):
        try:
            with sounddevice.InputStream(
                samplerate=Config.AUDIO_SAMPLE_RATE,
                channels=Config.AUDIO_CHANNELS,
                dtype=Config.AUDIO_FORMAT,
                blocksize=1024,
                callback=callback
            ) as stream:
                while self.is_recording:
                    try:
                        audio_data = self.audio_queue.get(timeout=1.0)
                        
                        if audio_data is not None and len(audio_data) > 0:
                            if self.vad_model is not None:
                                audio_tensor = torch.from_numpy(np.array(audio_data, dtype=np.float32))
                                speech_prob = self.vad_model(audio_tensor, Config.AUDIO_SAMPLE_RATE).item()
                            else:
                                audio_array = np.array(audio_data)
                                energy = np.sqrt(np.mean(audio_array**2))
                                speech_prob = 1.0 if energy > 0.01 else 0.0
                            
                            if speech_prob > Config.VAD_SILENCE_THRESHOLD:
                                if not self.voice_buffer.current_segment_start:
                                    self.voice_buffer.start_segment()
                                
                                self.voice_buffer.add_audio_data(audio_data)
                            else:
                                if self.voice_buffer.current_segment_start:
                                    self.voice_buffer.end_segment()
                                
                                if self.voice_buffer.should_process_speech():
                                    self._process_buffered_speech()
                    
                    except queue.Empty:
                        continue
                    except Exception as e:
                        st.error(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        continue
                        
        except Exception as e:
            st.error(f"âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.is_recording = False
    
    def _process_buffered_speech(self):
        try:
            combined_audio = self.voice_buffer.get_combined_audio()
            
            if combined_audio and self.whisper_model:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                    with wave.open(tmp_file.name, 'wb') as wf:
                        wf.setnchannels(Config.AUDIO_CHANNELS)
                        wf.setsampwidth(2)
                        wf.setframerate(Config.AUDIO_SAMPLE_RATE)
                        wf.writeframes(combined_audio)
                        wf.close()
                    
                    result = self.whisper_model.transcribe(
                        tmp_file.name,
                        language="ja",
                        word_timestamps=True,
                        temperature=0.0,
                        beam_size=5
                    )
                    
                    os.unlink(tmp_file.name)
                    
                    st.session_state.last_transcription = result
                    self.voice_buffer.reset()
                    
                    return result
            
        except Exception as e:
            st.error(f"âŒ ãƒãƒƒãƒ•ã‚¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def stop_recording(self):
        if not self.is_recording:
            return False
        
        self.is_recording = False
        
        if self.voice_buffer.current_segment_start:
            self.voice_buffer.end_segment()
        
        if self.voice_buffer.speech_segments:
            self._process_buffered_speech()
        
        if self.processing_thread:
            self.processing_thread.join(timeout=5)
            self.processing_thread = None
        
        return True
    
    def get_status(self):
        return {
            "is_recording": self.is_recording,
            "buffer_segments": len(self.voice_buffer.speech_segments),
            "total_duration": self.voice_buffer.total_duration,
            "last_speech_end": self.voice_buffer.last_speech_end
        }

class VoiceFixedAIAgent:
    """éŸ³å£°ä¿®æ­£ç‰ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.ai_agent = NetworkAwareAIAgent()
        self.voice_input = SmartVoiceInputHandler()
        self.voice_synthesizer = VoiceSynthesizer()
        
    def initialize(self):
        try:
            if not self.voice_input.initialize():
                return False
            return True
        except Exception as e:
            return False
    
    def generate_response(self, transcription_text):
        try:
            if not transcription_text:
                return "éŸ³å£°ãŒèªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            
            prompt = f"""ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒˆéŸ³å£°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°å…¥åŠ›ã«åŸºã¥ã„ã¦ã€è‡ªç„¶ã§ä¸å¯§ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°å…¥åŠ›: {transcription_text}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒšãƒ¼ã‚¹ã‚’å°Šé‡ã—ã€é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚è‡ªç„¶ãªå¯¾è©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
            
            response = self.ai_agent.generate_response(prompt)
            return response
            
        except Exception as e:
            return f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def speak_response(self, text):
        """å¿œç­”ã‚’éŸ³å£°ã§å‡ºåŠ›"""
        success, message = self.voice_synthesizer.synthesize(text)
        return success, message

def render_voice_status(voice_synthesizer):
    """éŸ³å£°åˆæˆçŠ¶æ…‹è¡¨ç¤º"""
    st.subheader("ğŸ”Š éŸ³å£°åˆæˆçŠ¶æ…‹")
    
    available_engines = voice_synthesizer.get_available_engines()
    current_engine = voice_synthesizer.current_engine
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³**:")
        for engine, available in available_engines.items():
            if available:
                st.success(f"âœ… {engine}")
            else:
                st.error(f"âŒ {engine}")
    
    with col2:
        st.write("**ç¾åœ¨ã®ã‚¨ãƒ³ã‚¸ãƒ³**:")
        if current_engine:
            st.success(f"ğŸ¯ {current_engine}")
        else:
            st.error("âŒ åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡ã‚Šæ›¿ãˆ
    engine_options = [name for name, available in available_engines.items() if available]
    if engine_options:
        selected_engine = st.selectbox(
            "éŸ³å£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠ",
            engine_options,
            index=engine_options.index(current_engine) if current_engine in engine_options else 0
        )
        
        if selected_engine != current_engine:
            if voice_synthesizer.set_engine(selected_engine):
                st.success(f"âœ… {selected_engine} ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
                st.rerun()
            else:
                st.error(f"âŒ {selected_engine} ã¸ã®åˆ‡ã‚Šæ›¿ãˆã«å¤±æ•—ã—ã¾ã—ãŸ")

def render_voice_interface(ai_agent):
    """éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.header("ğŸ¤ï¸ éŸ³å£°ä¿®æ­£ç‰ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    
    # éŸ³å£°åˆæˆçŠ¶æ…‹è¡¨ç¤º
    render_voice_status(ai_agent.voice_synthesizer)
    
    # å…¥åŠ›æ–¹æ³•ã®é¸æŠ
    input_method = st.radio(
        "ğŸ¯ å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
        ["ğŸ¤ï¸ éŸ³å£°å…¥åŠ›", "âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›"],
        horizontal=True
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if input_method == "ğŸ¤ï¸ éŸ³å£°å…¥åŠ›":
            st.subheader("ğŸ¤ï¸ éŸ³å£°éŒ²éŸ³")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ¤ï¸ éŒ²éŸ³é–‹å§‹", key="start_voice_recording"):
                    if ai_agent.voice_input.start_recording():
                        st.success("âœ… éŒ²éŸ³é–‹å§‹")
                        st.session_state.recording_status = "recording"
                    else:
                        st.error("âŒ éŒ²éŸ³é–‹å§‹å¤±æ•—")
            
            with col2:
                if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢", key="stop_voice_recording"):
                    if ai_agent.voice_input.stop_recording():
                        st.success("âœ… éŒ²éŸ³åœæ­¢")
                        st.session_state.recording_status = "stopped"
                    else:
                        st.error("âŒ éŒ²éŸ³åœæ­¢å¤±æ•—")
            
            # éŒ²éŸ³çŠ¶æ…‹è¡¨ç¤º
            if st.session_state.get("recording_status") == "recording":
                st.info("ğŸ”´ éŒ²éŸ³ä¸­...")
                
                status = ai_agent.voice_input.get_status()
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°", status["buffer_segments"])
                
                with col2:
                    st.metric("ç·æ™‚é–“", f"{status['total_duration']:.1f}ç§’")
                
                with col3:
                    if status["last_speech_end"]:
                        time_since = time.time() - status["last_speech_end"]
                        st.metric("å‰å›ç™ºè©±ã‹ã‚‰", f"{time_since:.1f}ç§’å‰")
                    else:
                        st.metric("çŠ¶æ…‹", "ç™ºè©±ä¸­")
            
            # è»¢è¨˜çµæœè¡¨ç¤º
            if st.session_state.get("last_transcription"):
                transcription = st.session_state.last_transcription
                
                st.subheader("ğŸ“ éŸ³å£°è»¢è¨˜çµæœ")
                st.write(f"**èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ**: {transcription['text']}")
                st.write(f"**å‡¦ç†æ™‚é–“**: {transcription.get('time', 'N/A')}ç§’")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ¤– AIå¿œç­”ç”Ÿæˆ", key="generate_ai_response_voice"):
                        with st.spinner("ğŸ¤– AIå¿œç­”ç”Ÿæˆä¸­..."):
                            ai_response = ai_agent.generate_response(transcription['text'])
                            st.session_state.ai_response = ai_response
                            st.success("âœ… AIå¿œç­”ç”Ÿæˆå®Œäº†")
                
                with col2:
                    if st.session_state.get("ai_response"):
                        if st.button("ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’", key="speak_response"):
                            with st.spinner("ğŸ”Š éŸ³å£°åˆæˆä¸­..."):
                                success, message = ai_agent.speak_response(st.session_state.ai_response)
                                if success:
                                    st.success("âœ… éŸ³å£°èª­ã¿ä¸Šã’å®Œäº†")
                                else:
                                    st.error(f"âŒ éŸ³å£°èª­ã¿ä¸Šã’å¤±æ•—: {message}")
                
                # AIå¿œç­”è¡¨ç¤º
                if st.session_state.get("ai_response"):
                    st.subheader("ğŸ¤– AIå¿œç­”")
                    st.write(st.session_state.ai_response)
        
        elif input_method == "âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
            st.subheader("âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›")
            
            user_input = st.text_area(
                "ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                key="text_input",
                height=100,
                placeholder="ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ“¤ é€ä¿¡", key="send_text", type="primary"):
                    if user_input.strip():
                        with st.spinner("ğŸ¤– AIå¿œç­”ç”Ÿæˆä¸­..."):
                            ai_response = ai_agent.generate_response(user_input)
                            st.session_state.text_ai_response = ai_response
                            st.session_state.last_text_input = user_input
                            st.success("âœ… AIå¿œç­”ç”Ÿæˆå®Œäº†")
                    else:
                        st.warning("âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            
            with col2:
                if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="clear_text"):
                    st.session_state.text_input = ""
                    st.session_state.text_ai_response = ""
                    st.success("âœ… å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            
            # ãƒ†ã‚­ã‚¹ãƒˆAIå¿œç­”è¡¨ç¤º
            if st.session_state.get("text_ai_response"):
                st.subheader("ğŸ¤– AIå¿œç­”")
                st.write(st.session_state.text_ai_response)
                
                if st.button("ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’", key="speak_text_response"):
                    with st.spinner("ğŸ”Š éŸ³å£°åˆæˆä¸­..."):
                        success, message = ai_agent.speak_response(st.session_state.text_ai_response)
                        if success:
                            st.success("âœ… éŸ³å£°èª­ã¿ä¸Šã’å®Œäº†")
                        else:
                            st.error(f"âŒ éŸ³å£°èª­ã¿ä¸Šã’å¤±æ•—: {message}")
    
    with col2:
        st.subheader("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
        st.write("**PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±**:")
        st.write(f"- torch: {torch.__version__}")
        st.write(f"- torchaudio: {torchaudio.__version__}")
        
        # CUDAæƒ…å ±
        if torch.cuda.is_available():
            st.write(f"- CUDA: åˆ©ç”¨å¯èƒ½")
            st.write(f"- GPUæ•°: {torch.cuda.device_count()}")
        else:
            st.write("- CUDA: åˆ©ç”¨ä¸å¯")
        
        # éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
        try:
            devices = sounddevice.query_devices()
            st.write("**éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹**:")
            for i, device in enumerate(devices):
                if device['max_input_channels'] > 0:
                    st.write(f"- å…¥åŠ› {i}: {device['name']}")
                if device['max_output_channels'] > 0:
                    st.write(f"- å‡ºåŠ› {i}: {device['name']}")
        except Exception as e:
            st.write(f"- éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    st.set_page_config(
        page_title="ğŸ”Š Voice-Fixed AI Agent",
        page_icon="ğŸ”Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ”Š Voice-Fixed AI Agent")
    st.markdown("### éŸ³å£°åˆæˆä¿®æ­£ç‰ˆ - eSpeak/VOICEVOXå¯¾å¿œ")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    if 'agent' not in st.session_state:
        st.session_state.agent = VoiceFixedAIAgent()
        
        # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
        with st.spinner("ğŸ¤– AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­..."):
            if st.session_state.agent.initialize():
                st.success("âœ… AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            else:
                st.error("âŒ AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–å¤±æ•—")
                st.stop()
    
    # ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    render_voice_interface(st.session_state.agent)

if __name__ == "__main__":
    main()
